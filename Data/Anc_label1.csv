id,Label,Annotated Positive Document,Correct Annotated Positive Document,Annotated Negative Document,Correct Annotated Negative Document,summary,Document
0,,,,,,"We propose an architecture for VQA which utilizes recurrent layers togenerate visual and textual attention. The memory characteristic of theproposed recurrent attention units offers a rich joint embedding of visual andtextual features and enables the model to reason relations between severalparts of the image and question. Our single model outperforms the first placewinner on the VQA 1.0 dataset, performs within margin to the currentstate-of-the-art ensemble model. We also experiment with replacing attentionmechanisms in other state-of-the-art models with our implementation and showincreased accuracy. In both cases, our recurrent attention mechanism improvesperformance in tasks requiring sequential or relational reasoning on the VQAdataset.",Dual Recurrent Attention Units for Visual Question Answering
1,,,,,,"Recent approaches based on artificial neural networks (ANNs) have shownpromising results for short-text classification. However, many short textsoccur in sequences (e.g., sentences in a document or utterances in a dialog),and most existing ANN-based systems do not leverage the preceding short textswhen classifying a subsequent one. In this work, we present a model based onrecurrent neural networks and convolutional neural networks that incorporatesthe preceding short texts. Our model achieves state-of-the-art results on threedifferent datasets for dialog act prediction.",Sequential Short-Text Classification with Recurrent and Convolutional  Neural Networks
2,Nuclear,,Nuclear,,,"We introduce the multiresolution recurrent neural network, which extends thesequence-to-sequence framework to model natural language generation as twoparallel discrete stochastic processes: a sequence of high-level coarse tokens,and a sequence of natural language tokens. There are many ways to estimate orlearn the high-level coarse tokens, but we argue that a simple extractionprocedure is sufficient to capture a wealth of high-level discourse semantics.Such procedure allows training the multiresolution recurrent neural network bymaximizing the exact joint log-likelihood over both sequences. In contrast tothe standard log- likelihood objective w.r.t. natural language tokens (wordperplexity), optimizing the joint log-likelihood biases the model towardsmodeling high-level abstractions. We apply the proposed model to the task ofdialogue response generation in two challenging domains: the Ubuntu technicalsupport domain, and Twitter conversations. On Ubuntu, the model outperformscompeting approaches by a substantial margin, achieving state-of-the-artresults according to both automatic evaluation metrics and a human evaluationstudy. On Twitter, the model appears to generate more relevant and on-topicresponses according to automatic evaluation metrics. Finally, our experimentsdemonstrate that the proposed model is more adept at overcoming the sparsity ofnatural language and is better able to capture long-term structure.",Multiresolution Recurrent Neural Networks: An Application to Dialogue  Response Generation
3,Physics,Physics,,,,"Multi-task learning is motivated by the observation that humans bring to bearwhat they know about related problems when solving new ones. Similarly, deepneural networks can profit from related tasks by sharing parameters with othernetworks. However, humans do not consciously decide to transfer knowledgebetween tasks. In Natural Language Processing (NLP), it is hard to predict ifsharing will lead to improvements, particularly if tasks are only looselyrelated. To overcome this, we introduce Sluice Networks, a general frameworkfor multi-task learning where trainable parameters control the amount ofsharing. Our framework generalizes previous proposals in enabling sharing ofall combinations of subspaces, layers, and skip connections. We performexperiments on three task pairs, and across seven different domains, using datafrom OntoNotes 5.0, and achieve up to 15% average error reductions over commonapproaches to multi-task learning. We show that a) label entropy is predictiveof gains in sluice networks, confirming findings for hard parameter sharing andb) while sluice networks easily fit noise, they are robust across domains inpractice.",Learning what to share between loosely related tasks
4,Chemistry,Chemistry,,,,"We present MILABOT: a deep reinforcement learning chatbot developed by theMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prizecompetition. MILABOT is capable of conversing with humans on popular small talktopics through both speech and text. The system consists of an ensemble ofnatural language generation and retrieval models, including template-basedmodels, bag-of-words models, sequence-to-sequence neural network and latentvariable neural network models. By applying reinforcement learning tocrowdsourced data and real-world user interactions, the system has been trainedto select an appropriate response from the models in its ensemble. The systemhas been evaluated through A/B testing with real-world users, where itperformed significantly better than many competing systems. Due to its machinelearning architecture, the system is likely to improve with additional data.",A Deep Reinforcement Learning Chatbot
5,Chemistry,,Chemistry,,,"We propose a new generative model of sentences that first samples a prototypesentence from the training corpus and then edits it into a new sentence.Compared to traditional models that generate from scratch either left-to-rightor by first sampling a latent sentence vector, our prototype-then-edit modelimproves perplexity on language modeling and generates higher quality outputsaccording to human evaluation. Furthermore, the model gives rise to a latentedit vector that captures interpretable semantics such as sentence similarityand sentence-level analogies.",Generating Sentences by Editing Prototypes
6,Chemistry,,,,Chemistry,"We present MILABOT: a deep reinforcement learning chatbot developed by theMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prizecompetition. MILABOT is capable of conversing with humans on popular small talktopics through both speech and text. The system consists of an ensemble ofnatural language generation and retrieval models, including neural network andtemplate-based models. By applying reinforcement learning to crowdsourced dataand real-world user interactions, the system has been trained to select anappropriate response from the models in its ensemble. The system has beenevaluated through A/B testing with real-world users, where it performedsignificantly better than other systems. The results highlight the potential ofcoupling ensemble systems with deep reinforcement learning as a fruitful pathfor developing real-world, open-domain conversational agents.",A Deep Reinforcement Learning Chatbot (Short Version)
7,DV,DV,,,,"The paper introduces a new method for discrimination of documents given indifferent scripts. The document is mapped into a uniformly coded text ofnumerical values. It is derived from the position of the letters in the textline, based on their typographical characteristics. Each code is considered asa gray level. Accordingly, the coded text determines a 1-D image, on whichtexture analysis by run-length statistics and local binary pattern isperformed. It defines feature vectors representing the script content of thedocument. A modified clustering approach employed on document feature vectorgroups documents written in the same script. Experimentation performed on twocustom oriented databases of historical documents in old Cyrillic, angular andround Glagolitic as well as Antiqua and Fraktur scripts demonstrates thesuperiority of the proposed method with respect to well-known methods in thestate-of-the-art.",Document Image Coding and Clustering for Script Discrimination
8,,,,,,"Together with the development of more accurate methods in Computer Vision andNatural Language Understanding, holistic architectures that answer on questionsabout the content of real-world images have emerged. In this tutorial, we builda neural-based approach to answer questions about images. We base our tutorialon two datasets: (mostly on) DAQUAR, and (a bit on) VQA. With small tweaks themodels that we present here can achieve a competitive performance on bothdatasets, in fact, they are among the best methods that use a combination ofLSTM with a global, full frame CNN representation of an image. We hope thatafter reading this tutorial, the reader will be able to use Deep Learningframeworks, such as Keras and introduced Kraino, to build various architecturesthat will lead to a further performance improvement on this challenging task.",Tutorial on Answering Questions about Images with Deep Learning
9,Chemistry,Chemistry,,,,"Transforming a graphical user interface screenshot created by a designer intocomputer code is a typical task conducted by a developer in order to buildcustomized software, websites, and mobile applications. In this paper, we showthat deep learning methods can be leveraged to train a model end-to-end toautomatically generate code from a single input image with over 77% of accuracyfor three different platforms (i.e. iOS, Android and web-based technologies).",pix2code: Generating Code from a Graphical User Interface Screenshot
10,Data,Data,,,,Learned feature representations and sub-phoneme posteriors from Deep NeuralNetworks (DNNs) have been used separately to produce significant performancegains for speaker and language recognition tasks. In this work we show howthese gains are possible using a single DNN for both speaker and languagerecognition. The unified DNN approach is shown to yield substantial performanceimprovements on the the 2013 Domain Adaptation Challenge speaker recognitiontask (55% reduction in EER for the out-of-domain condition) and on the NIST2011 Language Recognition Evaluation (48% reduction in EER for the 30s testcondition).,A Unified Deep Neural Network for Speaker and Language Recognition
11,Physics,Physics,,,,"We propose Efficient Neural Architecture Search (ENAS), a fast andinexpensive approach for automatic model design. In ENAS, a controller learnsto discover neural network architectures by searching for an optimal subgraphwithin a large computational graph. The controller is trained with policygradient to select a subgraph that maximizes the expected reward on thevalidation set. Meanwhile the model corresponding to the selected subgraph istrained to minimize a canonical cross entropy loss. Thanks to parameter sharingbetween child models, ENAS is fast: it delivers strong empirical performancesusing much fewer GPU-hours than all existing automatic model design approaches,and notably, 1000x less expensive than standard Neural Architecture Search. Onthe Penn Treebank dataset, ENAS discovers a novel architecture that achieves atest perplexity of 55.8, establishing a new state-of-the-art among all methodswithout post-training processing. On the CIFAR-10 dataset, ENAS designs novelarchitectures that achieve a test error of 2.89%, which is on par with NASNet(Zoph et al., 2018), whose test error is 2.65%.",Efficient Neural Architecture Search via Parameter Sharing
12,Chemistry,,,Chemistry,,"Recent progress in artificial intelligence (AI) has renewed interest inbuilding systems that learn and think like people. Many advances have come fromusing deep neural networks trained end-to-end in tasks such as objectrecognition, video games, and board games, achieving performance that equals oreven beats humans in some respects. Despite their biological inspiration andperformance achievements, these systems differ from human intelligence incrucial ways. We review progress in cognitive science suggesting that trulyhuman-like learning and thinking machines will have to reach beyond currentengineering trends in both what they learn, and how they learn it.Specifically, we argue that these machines should (a) build causal models ofthe world that support explanation and understanding, rather than merelysolving pattern recognition problems; (b) ground learning in intuitive theoriesof physics and psychology, to support and enrich the knowledge that is learned;and (c) harness compositionality and learning-to-learn to rapidly acquire andgeneralize knowledge to new tasks and situations. We suggest concretechallenges and promising routes towards these goals that can combine thestrengths of recent neural network advances with more structured cognitivemodels.",Building Machines That Learn and Think Like People
13,,,,,,"While perception tasks such as visual object recognition and textunderstanding play an important role in human intelligence, the subsequenttasks that involve inference, reasoning and planning require an even higherlevel of intelligence. The past few years have seen major advances in manyperception tasks using deep learning models. For higher-level inference,however, probabilistic graphical models with their Bayesian nature are stillmore powerful and flexible. To achieve integrated intelligence that involvesboth perception and inference, it is naturally desirable to tightly integratedeep learning and Bayesian models within a principled probabilistic framework,which we call Bayesian deep learning. In this unified framework, the perceptionof text or images using deep learning can boost the performance of higher-levelinference and in return, the feedback from the inference process is able toenhance the perception of text or images. This survey provides a generalintroduction to Bayesian deep learning and reviews its recent applications onrecommender systems, topic models, and control. In this survey, we also discussthe relationship and differences between Bayesian deep learning and otherrelated topics like Bayesian treatment of neural networks.",Towards Bayesian Deep Learning: A Survey
14,,,,,,"Learning goal-directed behavior in environments with sparse feedback is amajor challenge for reinforcement learning algorithms. The primary difficultyarises due to insufficient exploration, resulting in an agent being unable tolearn robust value functions. Intrinsically motivated agents can explore newbehavior for its own sake rather than to directly solve problems. Suchintrinsic behaviors could eventually help the agent solve tasks posed by theenvironment. We present hierarchical-DQN (h-DQN), a framework to integratehierarchical value functions, operating at different temporal scales, withintrinsically motivated deep reinforcement learning. A top-level value functionlearns a policy over intrinsic goals, and a lower-level function learns apolicy over atomic actions to satisfy the given goals. h-DQN allows forflexible goal specifications, such as functions over entities and relations.This provides an efficient space for exploration in complicated environments.We demonstrate the strength of our approach on two problems with very sparse,delayed feedback: (1) a complex discrete stochastic decision process, and (2)the classic ATARI game `Montezuma's Revenge'.",Hierarchical Deep Reinforcement Learning: Integrating Temporal  Abstraction and Intrinsic Motivation
15,,,,,,"This paper presents a novel yet intuitive approach to unsupervised featurelearning. Inspired by the human visual system, we explore whether low-levelmotion-based grouping cues can be used to learn an effective visualrepresentation. Specifically, we use unsupervised motion-based segmentation onvideos to obtain segments, which we use as 'pseudo ground truth' to train aconvolutional network to segment objects from a single frame. Given theextensive evidence that motion plays a key role in the development of the humanvisual system, we hope that this straightforward approach to unsupervisedlearning will be more effective than cleverly designed 'pretext' tasks studiedin the literature. Indeed, our extensive experiments show that this is thecase. When used for transfer learning on object detection, our representationsignificantly outperforms previous unsupervised approaches across multiplesettings, especially when training data for the target task is scarce.",Learning Features by Watching Objects Move
16,,,,,,"We propose a simple neural network model to deal with the domain adaptationproblem in object recognition. Our model incorporates the Maximum MeanDiscrepancy (MMD) measure as a regularization in the supervised learning toreduce the distribution mismatch between the source and target domains in thelatent space. From experiments, we demonstrate that the MMD regularization isan effective tool to provide good domain adaptation models on both SURFfeatures and raw image pixels of a particular image data set. We also show thatour proposed model, preceded by the denoising auto-encoder pretraining,achieves better performance than recent benchmark models on the same data sets.This work represents the first study of MMD measure in the context of neuralnetworks.",Domain Adaptive Neural Networks for Object Recognition
17,Data,Data,,,,"Recent studies have demonstrated the power of recurrent neural networks formachine translation, image captioning and speech recognition. For the task ofcapturing temporal structure in video, however, there still remain numerousopen research questions. Current research suggests using a simple temporalfeature pooling strategy to take into account the temporal aspect of video. Wedemonstrate that this method is not sufficient for gesture recognition, wheretemporal information is more discriminative compared to general videoclassification tasks. We explore deep architectures for gesture recognition invideo and propose a new end-to-end trainable neural network architectureincorporating temporal convolutions and bidirectional recurrence. Our maincontributions are twofold; first, we show that recurrence is crucial for thistask; second, we show that adding temporal convolutions leads to significantimprovements. We evaluate the different approaches on the Montalbano gesturerecognition dataset, where we achieve state-of-the-art results.",Beyond Temporal Pooling: Recurrence and Temporal Convolutions for  Gesture Recognition in Video
18,Data,Data,,,,"In this paper, we address the task of Optical Character Recognition(OCR) forthe Telugu script. We present an end-to-end framework that segments the textimage, classifies the characters and extracts lines using a language model. Thesegmentation is based on mathematical morphology. The classification module,which is the most challenging task of the three, is a deep convolutional neuralnetwork. The language is modelled as a third degree markov chain at the glyphlevel. Telugu script is a complex alphasyllabary and the language isagglutinative, making the problem hard. In this paper we apply the latestadvances in neural networks to achieve state-of-the-art error rates. We alsoreview convolutional neural networks in great detail and expound thestatistical justification behind the many tricks needed to make Deep Learningwork.",Telugu OCR Framework using Deep Learning
19,,,,,,"The ability of the Generative Adversarial Networks (GANs) framework to learngenerative models mapping from simple latent distributions to arbitrarilycomplex data distributions has been demonstrated empirically, with compellingresults showing that the latent space of such generators captures semanticvariation in the data distribution. Intuitively, models trained to predictthese semantic latent representations given data may serve as useful featurerepresentations for auxiliary problems where semantics are relevant. However,in their existing form, GANs have no means of learning the inverse mapping --projecting data back into the latent space. We propose Bidirectional GenerativeAdversarial Networks (BiGANs) as a means of learning this inverse mapping, anddemonstrate that the resulting learned feature representation is useful forauxiliary supervised discrimination tasks, competitive with contemporaryapproaches to unsupervised and self-supervised feature learning.",Adversarial Feature Learning
20,Data,,,Data,,"Supervised machine learning models boast remarkable predictive capabilities.But can you trust your model? Will it work in deployment? What else can it tellyou about the world? We want models to be not only good, but interpretable. Andyet the task of interpretation appears underspecified. Papers provide diverseand sometimes non-overlapping motivations for interpretability, and offermyriad notions of what attributes render models interpretable. Despite thisambiguity, many papers proclaim interpretability axiomatically, absent furtherexplanation. In this paper, we seek to refine the discourse oninterpretability. First, we examine the motivations underlying interest ininterpretability, finding them to be diverse and occasionally discordant. Then,we address model properties and techniques thought to confer interpretability,identifying transparency to humans and post-hoc explanations as competingnotions. Throughout, we discuss the feasibility and desirability of differentnotions, and question the oft-made assertions that linear models areinterpretable and that deep neural networks are not.",The Mythos of Model Interpretability
21,Physics,Physics,,,,"In this paper, we focus on online representation learning in non-stationaryenvironments which may require continuous adaptation of model architecture. Wepropose a novel online dictionary-learning (sparse-coding) framework whichincorporates the addition and deletion of hidden units (dictionary elements),and is inspired by the adult neurogenesis phenomenon in the dentate gyrus ofthe hippocampus, known to be associated with improved cognitive function andadaptation to new environments. In the online learning setting, where new inputinstances arrive sequentially in batches, the neuronal-birth is implemented byadding new units with random initial weights (random dictionary elements); thenumber of new units is determined by the current performance (representationerror) of the dictionary, higher error causing an increase in the birth rate.Neuronal-death is implemented by imposing l1/l2-regularization (group sparsity)on the dictionary within the block-coordinate descent optimization at eachiteration of our online alternating minimization scheme, which iterates betweenthe code and dictionary updates. Finally, hidden unit connectivity adaptationis facilitated by introducing sparsity in dictionary elements. Our empiricalevaluation on several real-life datasets (images and language) as well as onsynthetic data demonstrates that the proposed approach can considerablyoutperform the state-of-art fixed-size (nonadaptive) online sparse coding ofMairal et al. (2009) in the presence of nonstationary data. Moreover, weidentify certain properties of the data (e.g., sparse inputs with nearlynon-overlapping supports) and of the model (e.g., dictionary sparsity)associated with such improvements.",Neurogenesis-Inspired Dictionary Learning: Online Model Adaption in a  Changing World
22,,,,,,"Deep neural networks require a large amount of labeled training data duringsupervised learning. However, collecting and labeling so much data might beinfeasible in many cases. In this paper, we introduce a source-target selectivejoint fine-tuning scheme for improving the performance of deep learning taskswith insufficient training data. In this scheme, a target learning task withinsufficient training data is carried out simultaneously with another sourcelearning task with abundant training data. However, the source learning taskdoes not use all existing training data. Our core idea is to identify and use asubset of training images from the original source learning task whoselow-level characteristics are similar to those from the target learning task,and jointly fine-tune shared convolutional layers for both tasks. Specifically,we compute descriptors from linear or nonlinear filter bank responses ontraining images from both tasks, and use such descriptors to search for adesired subset of training samples for the source learning task.  Experiments demonstrate that our selective joint fine-tuning scheme achievesstate-of-the-art performance on multiple visual classification tasks withinsufficient training data for deep learning. Such tasks include Caltech 256,MIT Indoor 67, Oxford Flowers 102 and Stanford Dogs 120. In comparison tofine-tuning without a source domain, the proposed method can improve theclassification accuracy by 2% - 10% using a single model.",Borrowing Treasures from the Wealthy: Deep Transfer Learning through  Selective Joint Fine-tuning
23,Data,,,Data,,"An important goal of computer vision is to build systems that learn visualrepresentations over time that can be applied to many tasks. In this paper, weinvestigate a vision-language embedding as a core representation and show thatit leads to better cross-task transfer than standard multi-task learning. Inparticular, the task of visual recognition is aligned to the task of visualquestion answering by forcing each to use the same word-region embeddings. Weshow this leads to greater inductive transfer from recognition to VQA thanstandard multitask learning. Visual recognition also improves, especially forcategories that have relatively few recognition training labels but appearoften in the VQA setting. Thus, our paper takes a small step towards creatingmore general vision systems by showing the benefit of interpretable, flexible,and trainable core representations.",Aligned Image-Word Representations Improve Inductive Transfer Across  Vision-Language Tasks
24,,,,,,"While deep learning is remarkably successful on perceptual tasks, it was alsoshown to be vulnerable to adversarial perturbations of the input. Theseperturbations denote noise added to the input that was generated specificallyto fool the system while being quasi-imperceptible for humans. More severely,there even exist universal perturbations that are input-agnostic but fool thenetwork on the majority of inputs. While recent work has focused on imageclassification, this work proposes attacks against semantic image segmentation:we present an approach for generating (universal) adversarial perturbationsthat make the network yield a desired target segmentation as output. We showempirically that there exist barely perceptible universal noise patterns whichresult in nearly the same predicted segmentation for arbitrary inputs.Furthermore, we also show the existence of universal noise which removes atarget class (e.g., all pedestrians) from the segmentation while leaving thesegmentation mostly unchanged otherwise.",Universal Adversarial Perturbations Against Semantic Image Segmentation
25,Nuclear,,,Nuclear,,"While the optimization problem behind deep neural networks is highlynon-convex, it is frequently observed in practice that training deep networksseems possible without getting stuck in suboptimal points. It has been arguedthat this is the case as all local minima are close to being globally optimal.We show that this is (almost) true, in fact almost all local minima areglobally optimal, for a fully connected network with squared loss and analyticactivation function given that the number of hidden units of one layer of thenetwork is larger than the number of training points and the network structurefrom this layer on is pyramidal.",The loss surface of deep and wide neural networks
26,Physics,Physics,,,,"We propose a new algorithm for training generative adversarial networks thatjointly learns latent codes for both identities (e.g. individual humans) andobservations (e.g. specific photographs). By fixing the identity portion of thelatent codes, we can generate diverse images of the same subject, and by fixingthe observation portion, we can traverse the manifold of subjects whilemaintaining contingent aspects such as lighting and pose. Our algorithmfeatures a pairwise training scheme in which each sample from the generatorconsists of two images with a common identity code. Corresponding samples fromthe real dataset consist of two distinct photographs of the same subject. Inorder to fool the discriminator, the generator must produce pairs that arephotorealistic, distinct, and appear to depict the same individual. We augmentboth the DCGAN and BEGAN approaches with Siamese discriminators to facilitatepairwise training. Experiments with human judges and an off-the-shelf faceverification system demonstrate our algorithm's ability to generate convincing,identity-matched photographs.",Semantically Decomposing the Latent Spaces of Generative Adversarial  Networks
27,,,,,,"Adaptive gradient methods have become recently very popular, in particular asthey have been shown to be useful in the training of deep neural networks. Inthis paper we have analyzed RMSProp, originally proposed for the training ofdeep neural networks, in the context of online convex optimization and show$\sqrt{T}$-type regret bounds. Moreover, we propose two variants SC-Adagrad andSC-RMSProp for which we show logarithmic regret bounds for strongly convexfunctions. Finally, we demonstrate in the experiments that these new variantsoutperform other adaptive gradient techniques or stochastic gradient descent inthe optimization of strongly convex functions as well as in training of deepneural networks.",Variants of RMSProp and Adagrad with Logarithmic Regret Bounds
28,Data,Data,,,,"We investigate the non-identifiability issues associated with bidirectionaladversarial training for joint distribution matching. Within a framework ofconditional entropy, we propose both adversarial and non-adversarial approachesto learn desirable matched joint distributions for unsupervised and supervisedtasks. We unify a broad family of adversarial models as joint distributionmatching problems. Our approach stabilizes learning of unsupervisedbidirectional adversarial learning methods. Further, we introduce an extensionfor semi-supervised learning tasks. Theoretical results are validated insynthetic data and real-world applications.",ALICE: Towards Understanding Adversarial Learning for Joint Distribution  Matching
29,Nuclear,,,Nuclear,,"In this study, we systematically investigate the impact of class imbalance onclassification performance of convolutional neural networks (CNNs) and comparefrequently used methods to address the issue. Class imbalance is a commonproblem that has been comprehensively studied in classical machine learning,yet very limited systematic research is available in the context of deeplearning. In our study, we use three benchmark datasets of increasingcomplexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects ofimbalance on classification and perform an extensive comparison of severalmethods to address the issue: oversampling, undersampling, two-phase training,and thresholding that compensates for prior class probabilities. Our mainevaluation metric is area under the receiver operating characteristic curve(ROC AUC) adjusted to multi-class tasks since overall accuracy metric isassociated with notable difficulties in the context of imbalanced data. Basedon results from our experiments we conclude that (i) the effect of classimbalance on classification performance is detrimental; (ii) the method ofaddressing class imbalance that emerged as dominant in almost all analyzedscenarios was oversampling; (iii) oversampling should be applied to the levelthat totally eliminates the imbalance, whereas undersampling can perform betterwhen the imbalance is only removed to some extent; (iv) as opposed to someclassical machine learning models, oversampling does not necessarily causeoverfitting of CNNs; (v) thresholding should be applied to compensate for priorclass probabilities when overall number of properly classified cases is ofinterest.",A systematic study of the class imbalance problem in convolutional  neural networks
30,Physics,Physics,,,,"Regularization is one of the crucial ingredients of deep learning, yet theterm regularization has various definitions, and regularization methods areoften studied separately from each other. In our work we present a systematic,unifying taxonomy to categorize existing methods. We distinguish methods thataffect data, network architectures, error terms, regularization terms, andoptimization procedures. We do not provide all details about the listedmethods; instead, we present an overview of how the methods can be sorted intomeaningful categories and sub-categories. This helps revealing links andfundamental similarities between them. Finally, we include practicalrecommendations both for users and for developers of new regularizationmethods.",Regularization for Deep Learning: A Taxonomy
31,,,,,,"Clustering is a fundamental machine learning method. The quality of itsresults is dependent on the data distribution. For this reason, deep neuralnetworks can be used for learning better representations of the data. In thispaper, we propose a systematic taxonomy for clustering with deep learning, inaddition to a review of methods from the field. Based on our taxonomy, creatingnew methods is more straightforward. We also propose a new approach which isbuilt on the taxonomy and surpasses some of the limitations of some previouswork. Our experimental evaluation on image datasets shows that the methodapproaches state-of-the-art clustering quality, and performs better in somecases.",Clustering with Deep Learning: Taxonomy and New Methods
32,DV,DV,,,,"We tackle here the problem of multimodal image non-rigid registration, whichis of prime importance in remote sensing and medical imaging. The difficultiesencountered by classical registration approaches include feature design andslow optimization by gradient descent. By analyzing these methods, we note thesignificance of the notion of scale. We design easy-to-train,fully-convolutional neural networks able to learn scale-specific features. Oncechained appropriately, they perform global registration in linear time, gettingrid of gradient descent schemes by predicting directly the deformation.We showtheir performance in terms of quality and speed through various tasks of remotesensing multimodal image alignment. In particular, we are able to registercorrectly cadastral maps of buildings as well as road polylines onto RGBimages, and outperform current keypoint matching methods.",Coarse to fine non-rigid registration: a chain of scale-specific neural  networks for multimodal image alignment with application to remote sensing
33,Chemistry,,,Chemistry,,"Recent progress in using recurrent neural networks (RNNs) for imagedescription has motivated the exploration of their application for videodescription. However, while images are static, working with videos requiresmodeling their dynamic temporal structure and then properly integrating thatinformation into a natural language description. In this context, we propose anapproach that successfully takes into account both the local and globaltemporal structure of videos to produce descriptions. First, our approachincorporates a spatial temporal 3-D convolutional neural network (3-D CNN)representation of the short temporal dynamics. The 3-D CNN representation istrained on video action recognition tasks, so as to produce a representationthat is tuned to human motion and behavior. Second we propose a temporalattention mechanism that allows to go beyond local temporal modeling and learnsto automatically select the most relevant temporal segments given thetext-generating RNN. Our approach exceeds the current state-of-art for bothBLEU and METEOR metrics on the Youtube2Text dataset. We also present results ona new, larger and more challenging dataset of paired video and natural languagedescriptions.",Describing Videos by Exploiting Temporal Structure
34,DV,DV,,,,"Hybrid methods that utilize both content and rating information are commonlyused in many recommender systems. However, most of them use either handcraftedfeatures or the bag-of-words representation as a surrogate for the contentinformation but they are neither effective nor natural enough. To address thisproblem, we develop a collaborative recurrent autoencoder (CRAE) which is adenoising recurrent autoencoder (DRAE) that models the generation of contentsequences in the collaborative filtering (CF) setting. The model generalizesrecent advances in recurrent deep learning from i.i.d. input to non-i.i.d.(CF-based) input and provides a new denoising scheme along with a novellearnable pooling scheme for the recurrent autoencoder. To do this, we firstdevelop a hierarchical Bayesian model for the DRAE and then generalize it tothe CF setting. The synergy between denoising and CF enables CRAE to makeaccurate recommendations while learning to fill in the blanks in sequences.Experiments on real-world datasets from different domains (CiteULike andNetflix) show that, by jointly modeling the order-aware generation of sequencesfor the content information and performing CF for the ratings, CRAE is able tosignificantly outperform the state of the art on both the recommendation taskbased on ratings and the sequence generation task based on content information.",Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in  the Blanks
35,,,,,,"In this project we analysed how much semantic information images carry, andhow much value image data can add to sentiment analysis of the text associatedwith the images. To better understand the contribution from images, we comparedmodels which only made use of image data, models which only made use of textdata, and models which combined both data types. We also analysed if thisapproach could help sentiment classifiers generalize to unknown sentiments.",Sentiment Classification using Images and Label Embeddings
36,Data,,,Data,,"Neural networks (NN) have achieved state-of-the-art performance in variousapplications. Unfortunately in applications where training data isinsufficient, they are often prone to overfitting. One effective way toalleviate this problem is to exploit the Bayesian approach by using Bayesianneural networks (BNN). Another shortcoming of NN is the lack of flexibility tocustomize different distributions for the weights and neurons according to thedata, as is often done in probabilistic graphical models. To address theseproblems, we propose a class of probabilistic neural networks, dubbednatural-parameter networks (NPN), as a novel and lightweight Bayesian treatmentof NN. NPN allows the usage of arbitrary exponential-family distributions tomodel the weights and neurons. Different from traditional NN and B, NPN takesdistributions as input and goes through layers of transformation beforeproducing distributions to match the target output distributions. As a Bayesiantreatment, efficient backpropagation (BP) is performed to learn the naturalparameters for the distributions over both the weights and neurons. The outputdistributions of each layer, as byproducts, may be used as second-orderrepresentations for the associated tasks such as link prediction. Experimentson real-world datasets show that NPN can achieve state-of-the-art performance.",Natural-Parameter Networks: A Class of Probabilistic Neural Networks
37,Physics,,,Physics,,"When encountering novel objects, humans are able to infer a wide range ofphysical properties such as mass, friction and deformability by interactingwith them in a goal driven way. This process of active interaction is in thesame spirit as a scientist performing experiments to discover hidden facts.Recent advances in artificial intelligence have yielded machines that canachieve superhuman performance in Go, Atari, natural language processing, andcomplex control problems; however, it is not clear that these systems can rivalthe scientific intuition of even a young child. In this work we introduce abasic set of tasks that require agents to estimate properties such as mass andcohesion of objects in an interactive simulated environment where they canmanipulate the objects and observe the consequences. We found that state of artdeep reinforcement learning methods can learn to perform the experimentsnecessary to discover such hidden properties. By systematically manipulatingthe problem difficulty and the cost incurred by the agent for performingexperiments, we found that agents learn different strategies that balance thecost of gathering information against the cost of making mistakes in differentsituations.",Learning to Perform Physics Experiments via Deep Reinforcement Learning
38,,,,,,"Teaching machines to accomplish tasks by conversing naturally with humans ischallenging. Currently, developing task-oriented dialogue systems requirescreating multiple components and typically this involves either a large amountof handcrafting, or acquiring costly labelled datasets to solve a statisticallearning problem for each component. In this work we introduce a neuralnetwork-based text-in, text-out end-to-end trainable goal-oriented dialoguesystem along with a new way of collecting dialogue data based on a novelpipe-lined Wizard-of-Oz framework. This approach allows us to develop dialoguesystems easily and without making too many assumptions about the task at hand.The results show that the model can converse with human subjects naturallywhilst helping them to accomplish tasks in a restaurant search domain.",A Network-based End-to-End Trainable Task-oriented Dialogue System
39,,,,,,"Embedding-based Knowledge Base Completion models have so far mostly combineddistributed representations of individual entities or relations to computetruth scores of missing links. Facts can however also be represented usingpairwise embeddings, i.e. embeddings for pairs of entities and relations. Inthis paper we explore such bigram embeddings with a flexible FactorizationMachine model and several ablations from it. We investigate the relevance ofvarious bigram types on the fb15k237 dataset and find relative improvementscompared to a compositional model.",A Factorization Machine Framework for Testing Bigram Embeddings in  Knowledgebase Completion
40,,,,,,"Existing models based on artificial neural networks (ANNs) for sentenceclassification often do not incorporate the context in which sentences appear,and classify sentences individually. However, traditional sentenceclassification approaches have been shown to greatly benefit from jointlyclassifying subsequent sentences, such as with conditional random fields. Inthis work, we present an ANN architecture that combines the effectiveness oftypical ANN models to classify sentences in isolation, with the strength ofstructured prediction. Our model achieves state-of-the-art results on twodifferent datasets for sequential sentence classification in medical abstracts.",Neural Networks for Joint Sentence Classification in Medical Paper  Abstracts
41,Physics,Physics,,,,"Objective: Patient notes in electronic health records (EHRs) may containcritical information for medical investigations. However, the vast majority ofmedical investigators can only access de-identified notes, in order to protectthe confidentiality of patients. In the United States, the Health InsurancePortability and Accountability Act (HIPAA) defines 18 types of protected healthinformation (PHI) that needs to be removed to de-identify patient notes. Manualde-identification is impractical given the size of EHR databases, the limitednumber of researchers with access to the non-de-identified notes, and thefrequent mistakes of human annotators. A reliable automated de-identificationsystem would consequently be of high value.  Materials and Methods: We introduce the first de-identification system basedon artificial neural networks (ANNs), which requires no handcrafted features orrules, unlike existing systems. We compare the performance of the system withstate-of-the-art systems on two datasets: the i2b2 2014 de-identificationchallenge dataset, which is the largest publicly available de-identificationdataset, and the MIMIC de-identification dataset, which we assembled and istwice as large as the i2b2 2014 dataset.  Results: Our ANN model outperforms the state-of-the-art systems. It yields anF1-score of 97.85 on the i2b2 2014 dataset, with a recall 97.38 and a precisionof 97.32, and an F1-score of 99.23 on the MIMIC de-identification dataset, witha recall 99.25 and a precision of 99.06.  Conclusion: Our findings support the use of ANNs for de-identification ofpatient notes, as they show better performance than previously publishedsystems while requiring no feature engineering.",De-identification of Patient Notes with Recurrent Neural Networks
42,,,,,,"Hypothesis testing is an important cognitive process that supports humanreasoning. In this paper, we introduce a computational hypothesis testingapproach based on memory augmented neural networks. Our approach involves ahypothesis testing loop that reconsiders and progressively refines a previouslyformed hypothesis in order to generate new hypotheses to test. We apply theproposed approach to language comprehension task by using Neural SemanticEncoders (NSE). Our NSE models achieve the state-of-the-art results showing anabsolute improvement of 1.2% to 2.6% accuracy over previous results obtained bysingle and ensemble systems on standard machine comprehension benchmarks suchas the Children's Book Test (CBT) and Who-Did-What (WDW) news article datasets.",Reasoning with Memory Augmented Neural Networks for Language  Comprehension
43,Physics,Physics,,,,"Although deep learning models have proven effective at solving problems innatural language processing, the mechanism by which they come to theirconclusions is often unclear. As a result, these models are generally treatedas black boxes, yielding no insight of the underlying learned patterns. In thispaper we consider Long Short Term Memory networks (LSTMs) and demonstrate a newapproach for tracking the importance of a given input to the LSTM for a givenoutput. By identifying consistently important patterns of words, we are able todistill state of the art LSTMs on sentiment analysis and question answeringinto a set of representative phrases. This representation is thenquantitatively validated by using the extracted phrases to construct a simple,rule-based classifier which approximates the output of the LSTM.",Automatic Rule Extraction from Long Short Term Memory Networks
44,DV,DV,,,,"Objective: We investigate whether deep learning techniques for naturallanguage processing (NLP) can be used efficiently for patient phenotyping.Patient phenotyping is a classification task for determining whether a patienthas a medical condition, and is a crucial part of secondary analysis ofhealthcare data. We assess the performance of deep learning algorithms andcompare them with classical NLP approaches.  Materials and Methods: We compare convolutional neural networks (CNNs),n-gram models, and approaches based on cTAKES that extract pre-defined medicalconcepts from clinical notes and use them to predict patient phenotypes. Theperformance is tested on 10 different phenotyping tasks using 1,610 dischargesummaries extracted from the MIMIC-III database.  Results: CNNs outperform other phenotyping algorithms in all 10 tasks. Theaverage F1-score of our model is 76 (PPV of 83, and sensitivity of 71) with ourmodel having an F1-score up to 37 points higher than alternative approaches. Weadditionally assess the interpretability of our model by presenting a methodthat extracts the most salient phrases for a particular prediction.  Conclusion: We show that NLP methods based on deep learning improve theperformance of patient phenotyping. Our CNN-based algorithm automaticallylearns the phrases associated with each patient phenotype. As such, it reducesthe annotation complexity for clinical domain experts, who are normallyrequired to develop task-specific annotation rules and identify relevantphrases. Our method performs well in terms of both performance andinterpretability, which indicates that deep learning is an effective approachto patient phenotyping based on clinicians' notes.",Comparing Rule-Based and Deep Learning Models for Patient Phenotyping
45,Nuclear,,,Nuclear,,"Over 50 million scholarly articles have been published: they constitute aunique repository of knowledge. In particular, one may infer from themrelations between scientific concepts, such as synonyms and hyponyms.Artificial neural networks have been recently explored for relation extraction.In this work, we continue this line of work and present a system based on aconvolutional neural network to extract relations. Our model ranked first inthe SemEval-2017 task 10 (ScienceIE) for relation extraction in scientificarticles (subtask C).",MIT at SemEval-2017 Task 10: Relation Extraction with Convolutional  Neural Networks
46,,,,,,"Recent approaches based on artificial neural networks (ANNs) have shownpromising results for named-entity recognition (NER). In order to achieve highperformances, ANNs need to be trained on a large labeled dataset. However,labels might be difficult to obtain for the dataset on which the user wants toperform NER: label scarcity is particularly pronounced for patient notede-identification, which is an instance of NER. In this work, we analyze towhat extent transfer learning may address this issue. In particular, wedemonstrate that transferring an ANN model trained on a large labeled datasetto another dataset with a limited number of labels improves upon thestate-of-the-art results on two different datasets for patient notede-identification.",Transfer Learning for Named-Entity Recognition with Neural Networks
47,Data,Data,,,,"Generative Adversarial Networks (GANs) have gathered a lot of attention fromthe computer vision community, yielding impressive results for imagegeneration. Advances in the adversarial generation of natural language fromnoise however are not commensurate with the progress made in generating images,and still lag far behind likelihood based methods. In this paper, we take astep towards generating natural language with a GAN objective alone. Weintroduce a simple baseline that addresses the discrete output space problemwithout relying on gradient estimators and show that it is able to achievestate-of-the-art results on a Chinese poem generation dataset. We presentquantitative results on generating sentences from context-free andprobabilistic context-free grammars, and qualitative language modeling results.A conditional version is also described that can generate sequences conditionedon sentence characteristics.",Adversarial Generation of Natural Language
48,,,,,,"Recently, a technique called Layer-wise Relevance Propagation (LRP) was shownto deliver insightful explanations in the form of input space relevances forunderstanding feed-forward neural network classification decisions. In thepresent work, we extend the usage of LRP to recurrent neural networks. Wepropose a specific propagation rule applicable to multiplicative connections asthey arise in recurrent network architectures such as LSTMs and GRUs. We applyour technique to a word-based bi-directional LSTM model on a five-classsentiment prediction task, and evaluate the resulting LRP relevances bothqualitatively and quantitatively, obtaining better results than agradient-based related method which was used in previous work.",Explaining Recurrent Neural Network Predictions in Sentiment Analysis
49,,,,,,"Can textual data be compressed intelligently without losing accuracy inevaluating sentiment? In this study, we propose a novel evolutionarycompression algorithm, PARSEC (PARts-of-Speech for sEntiment Compression),which makes use of Parts-of-Speech tags to compress text in a way thatsacrifices minimal classification accuracy when used in conjunction withsentiment analysis algorithms. An analysis of PARSEC with eight commercial andnon-commercial sentiment analysis algorithms on twelve English sentiment datasets reveals that accurate compression is possible with (0%, 1.3%, 3.3%) lossin sentiment classification accuracy for (20%, 50%, 75%) data compression withPARSEC using LingPipe, the most accurate of the sentiment algorithms. Othersentiment analysis algorithms are more severely affected by compression. Weconclude that significant compression of text data is possible for sentimentanalysis depending on the accuracy demands of the specific application and thespecific sentiment analysis algorithm used.",Text Compression for Sentiment Analysis via Evolutionary Algorithms
50,,,,,,"Direct acoustics-to-word (A2W) models in the end-to-end paradigm havereceived increasing attention compared to conventional sub-word based automaticspeech recognition models using phones, characters, or context-dependent hiddenMarkov model states. This is because A2W models recognize words from speechwithout any decoder, pronunciation lexicon, or externally-trained languagemodel, making training and decoding with such models simple. Prior work hasshown that A2W models require orders of magnitude more training data in orderto perform comparably to conventional models. Our work also showed thisaccuracy gap when using the English Switchboard-Fisher data set. This paperdescribes a recipe to train an A2W model that closes this gap and is at-parwith state-of-the-art sub-word based models. We achieve a word error rate of8.8%/13.9% on the Hub5-2000 Switchboard/CallHome test sets without any decoderor language model. We find that model initialization, training data order, andregularization have the most impact on the A2W model performance. Next, wepresent a joint word-character A2W model that learns to first spell the wordand then recognize it. This model provides a rich output to the user instead ofsimple word hypotheses, making it especially useful in the case of words unseenor rarely-seen during training.",Building competitive direct acoustics-to-word models for English  conversational speech recognition
51,,,,,,"We address the problem of Visual Question Answering (VQA), which requiresjoint image and language understanding to answer a question about a givenphotograph. Recent approaches have applied deep image captioning methods basedon convolutional-recurrent networks to this problem, but have failed to modelspatial inference. To remedy this, we propose a model we call the SpatialMemory Network and apply it to the VQA task. Memory networks are recurrentneural networks with an explicit attention mechanism that selects certain partsof the information stored in memory. Our Spatial Memory Network stores neuronactivations from different spatial regions of the image in its memory, and usesthe question to choose relevant regions for computing the answer, a process ofwhich constitutes a single ""hop"" in the network. We propose a novel spatialattention architecture that aligns words with image patches in the first hop,and obtain improved results by adding a second attention hop which considersthe whole question to choose visual evidence based on the results of the firsthop. To better understand the inference process learned by the network, wedesign synthetic questions that specifically require spatial inference andvisualize the attention weights. We evaluate our model on two published visualquestion answering datasets, DAQUAR [1] and VQA [2], and obtain improvedresults compared to a strong deep baseline model (iBOWIMG) which concatenatesimage and question features to predict the answer [3].","Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for  Visual Question Answering"
52,,,,,,"Visual question answering (VQA) has witnessed great progress since May, 2015as a classic problem unifying visual and textual data into a system. Manyenlightening VQA works explore deep into the image and question encodings andfusing methods, of which attention is the most effective and infusivemechanism. Current attention based methods focus on adequate fusion of visualand textual features, but lack the attention to where people focus to askquestions about the image. Traditional attention based methods attach a singlevalue to the feature at each spatial location, which losses many usefulinformation. To remedy these problems, we propose a general method to performsaliency-like pre-selection on overlapped region features by the interrelationof bidirectional LSTM (BiLSTM), and use a novel element-wise multiplicationbased attention method to capture more competent correlation informationbetween visual and textual features. We conduct experiments on the large-scaleCOCO-VQA dataset and analyze the effectiveness of our model demonstrated bystrong empirical results.",Task-driven Visual Saliency and Attention-based Visual Question  Answering
53,Nuclear,,,Nuclear,,"We present a systematic analysis on the performance of a phonetic recogniserwhen the window of input features is not symmetric with respect to the currentframe. The recogniser is based on Context Dependent Deep Neural Networks(CD-DNNs) and Hidden Markov Models (HMMs). The objective is to reduce thelatency of the system by reducing the number of future feature frames requiredto estimate the current output. Our tests performed on the TIMIT database showthat the performance does not degrade when the input window is shifted up to 5frames in the past compared to common practice (no future frame). Thiscorresponds to improving the latency by 50 ms in our settings. Our tests alsoshow that the best results are not obtained with the symmetric window commonlyemployed, but with an asymmetric window with eight past and two future contextframes, although this observation should be confirmed on other data sets. Thereduction in latency suggested by our results is critical for specificapplications such as real-time lip synchronisation for tele-presence, but mayalso be beneficial in general applications to improve the lag in human-machinespoken interaction.",Optimising The Input Window Alignment in CD-DNN Based Phoneme  Recognition for Low Latency Processing
54,,,,,,"Recently, the long short-term memory neural network (LSTM) has attracted wideinterest due to its success in many tasks. LSTM architecture consists of amemory cell and three gates, which looks similar to the neuronal networks inthe brain. However, there still lacks the evidence of the cognitiveplausibility of LSTM architecture as well as its working mechanism. In thispaper, we study the cognitive plausibility of LSTM by aligning its internalarchitecture with the brain activity observed via fMRI when the subjects read astory. Experiment results show that the artificial memory vector in LSTM canaccurately predict the observed sequential brain activities, indicating thecorrelation between LSTM architecture and the cognitive process of storyreading.",Bridging LSTM Architecture and the Neural Dynamics during Reading
55,Chemistry,Chemistry,,,,"This paper addresses how a recursive neural network model can automaticallyleave out useless information and emphasize important evidence, in other words,to perform ""weight tuning"" for higher-level representation acquisition. Wepropose two models, Weighted Neural Network (WNN) and Binary-Expectation NeuralNetwork (BENN), which automatically control how much one specific unitcontributes to the higher-level representation. The proposed model can beviewed as incorporating a more powerful compositional function for embeddingacquisition in recursive neural networks. Experimental results demonstrate thesignificant improvement over standard neural models.",Feature Weight Tuning for Recursive Neural Networks
56,,,,,,"One essential task in information extraction from the medical corpus is drugname recognition. Compared with text sources come from other domains, themedical text is special and has unique characteristics. In addition, themedical text mining poses more challenges, e.g., more unstructured text, thefast growing of new terms addition, a wide range of name variation for the samedrug. The mining is even more challenging due to the lack of labeled datasetsources and external knowledge, as well as multiple token representations for asingle drug name that is more common in the real application setting. Althoughmany approaches have been proposed to overwhelm the task, some problemsremained with poor F-score performance (less than 0.75). This paper presents anew treatment in data representation techniques to overcome some of thosechallenges. We propose three data representation techniques based on thecharacteristics of word distribution and word similarities as a result of wordembedding training. The first technique is evaluated with the standard NNmodel, i.e., MLP (Multi-Layer Perceptrons). The second technique involves twodeep network classifiers, i.e., DBN (Deep Belief Networks), and SAE (StackedDenoising Encoders). The third technique represents the sentence as a sequencethat is evaluated with a recurrent NN model, i.e., LSTM (Long Short TermMemory). In extracting the drug name entities, the third technique gives thebest F-score performance compared to the state of the art, with its averageF-score being 0.8645.",A New Data Representation Based on Training Data Characteristics to  Extract Drug Named-Entity in Medical Text
57,Physics,,,Physics,,"Writing rap lyrics requires both creativity to construct a meaningful,interesting story and lyrical skills to produce complex rhyme patterns, whichform the cornerstone of good flow. We present a rap lyrics generation methodthat captures both of these aspects. First, we develop a prediction model toidentify the next line of existing lyrics from a set of candidate next lines.This model is based on two machine-learning techniques: the RankSVM algorithmand a deep neural network model with a novel structure. Results show that theprediction model can identify the true next line among 299 randomly selectedlines with an accuracy of 17%, i.e., over 50 times more likely than by random.Second, we employ the prediction model to combine lines from existing songs,producing lyrics with rhyme and a meaning. An evaluation of the produced lyricsshows that in terms of quantitative rhyme density, the method outperforms thebest human rappers by 21%. The rap lyrics generator has been deployed as anonline tool called DeepBeat, and the performance of the tool has been assessedby analyzing its usage logs. This analysis shows that machine-learned rankingscorrelate with user preferences.",DopeLearning: A Computational Approach to Rap Lyrics Generation
58,,,,,,"Semantic matching, which aims to determine the matching degree between twotexts, is a fundamental problem for many NLP applications. Recently, deeplearning approach has been applied to this problem and significant improvementshave been achieved. In this paper, we propose to view the generation of theglobal interaction between two texts as a recursive process: i.e. theinteraction of two texts at each position is a composition of the interactionsbetween their prefixes as well as the word level interaction at the currentposition. Based on this idea, we propose a novel deep architecture, namelyMatch-SR, to model the recursive matching structure. Firstly, a tensor isconstructed to capture the word level interactions. Then a spatial RNN isapplied to integrate the local interactions recursively, with importancedetermined by four types of gates. Finally, the matching score is calculatedbased on the global interaction. We show that, after degenerated to the exactmatching scenario, Match-SRNN can approximate the dynamic programming processof longest common subsequence. Thus, there exists a clear interpretation forMatch-SRNN. Our experiments on two semantic matching tasks showed theeffectiveness of Match-SR, and its ability of visualizing the learnedmatching structure.",Match-SRNN: Modeling the Recursive Matching Structure with Spatial RNN
59,,,,,,"Advances in neural variational inference have facilitated the learning ofpowerful directed graphical models with continuous latent variables, such asvariational autoencoders. The hope is that such models will learn to representrich, multi-modal latent factors in real-world data, such as natural languagetext. However, current models often assume simplistic priors on the latentvariables - such as the uni-modal Gaussian distribution - which are incapableof representing complex latent factors efficiently. To overcome thisrestriction, we propose the simple, but highly flexible, piecewise constantdistribution. This distribution has the capacity to represent an exponentialnumber of modes of a latent target distribution, while remaining mathematicallytractable. Our results demonstrate that incorporating this new latentdistribution into different models yields substantial improvements in naturallanguage processing tasks such as document modeling and natural languagegeneration for dialogue.",Piecewise Latent Variables for Neural Variational Text Processing
60,DV,DV,,,,"Recurrent Neural Networks (RNNs) have become increasingly popular for thetask of language understanding. In this task, a semantic tagger is deployed toassociate a semantic label to each word in an input sequence. The success ofRNN may be attributed to its ability to memorize long-term dependence thatrelates the current-time semantic label prediction to the observations manytime instances away. However, the memory capacity of simple RNNs is limitedbecause of the gradient vanishing and exploding problem. We propose to use anexternal memory to improve memorization capability of RNNs. We conductedexperiments on the ATIS dataset, and observed that the proposed model was ableto achieve the state-of-the-art results. We compare our proposed model withalternative models and report analysis results that may provide insights forfuture research.",Recurrent Neural Networks with External Memory for Language  Understanding
61,,,,,,"We present a novel response generation system that can be trained end to endon large quantities of unstructured Twitter conversations. A neural networkarchitecture is used to address sparsity issues that arise when integratingcontextual information into classic statistical models, allowing the system totake into account previous dialog utterances. Our dynamic-context generativemodels show consistent gains over both context-sensitive andnon-context-sensitive Machine Translation and Information Retrieval baselines.",A Neural Network Approach to Context-Sensitive Generation of  Conversational Responses
62,,,,,,"This paper introduces the Ubuntu Dialogue Corpus, a dataset containing almost1 million multi-turn dialogues, with a total of over 7 million utterances and100 million words. This provides a unique resource for research into buildingdialogue managers based on neural language models that can make use of largeamounts of unlabeled data. The dataset has both the multi-turn property ofconversations in the Dialog State Tracking Challenge datasets, and theunstructured nature of interactions from microblog services such as Twitter. Wealso describe two neural learning architectures suitable for analyzing thisdataset, and provide benchmark performance on the task of selecting the bestnext response.",The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured  Multi-Turn Dialogue Systems
63,,,,,,"We investigate the task of building open domain, conversational dialoguesystems based on large dialogue corpora using generative models. Generativemodels produce system responses that are autonomously generated word-by-word,opening up the possibility for realistic, flexible interactions. In support ofthis goal, we extend the recently proposed hierarchical recurrentencoder-decoder neural network to the dialogue domain, and demonstrate thatthis model is competitive with state-of-the-art neural language models andback-off n-gram models. We investigate the limitations of this and similarapproaches, and show how its performance can be improved by bootstrapping thelearning from a larger question-answer pair corpus and from pretrained wordembeddings.",Building End-To-End Dialogue Systems Using Generative Hierarchical  Neural Network Models
64,,,,,,"Many of the current state-of-the-art Large Vocabulary Continuous SpeechRecognition Systems (LVCSR) are hybrids of neural networks and Hidden MarkovModels (HMMs). Most of these systems contain separate components that deal withthe acoustic modelling, language modelling and sequence decoding. Weinvestigate a more direct approach in which the HMM is replaced with aRecurrent Neural Network (RNN) that performs sequence prediction directly atthe character level. Alignment between the input features and the desiredcharacter sequence is learned automatically by an attention mechanism builtinto the RNN. For each predicted character, the attention mechanism scans theinput sequence and chooses relevant frames. We propose two methods to speed upthis operation: limiting the scan to a subset of most promising frames andpooling over time the information contained in neighboring frames, therebyreducing source sequence length. Integrating an n-gram language model into thedecoding process yields recognition accuracies similar to other HMM-freeRNN-based approaches.",End-to-End Attention-based Large Vocabulary Speech Recognition
65,Chemistry,,,Chemistry,,"We propose Neural Reasoner, a framework for neural network-based reasoningover natural language sentences. Given a question, Neural Reasoner can inferover multiple supporting facts and find an answer to the question in specificforms. Neural Reasoner has 1) a specific interaction-pooling mechanism,allowing it to examine multiple facts, and 2) a deep architecture, allowing itto model the complicated logical relations in reasoning tasks. Assuming noparticular structure exists in the question and facts, Neural Reasoner is ableto accommodate different types of reasoning and different forms of languageexpressions. Despite the model complexity, Neural Reasoner can still be trainedeffectively in an end-to-end manner. Our empirical studies show that NeuralReasoner can outperform existing neural reasoning systems with remarkablemargins on two difficult artificial tasks (Positional Reasoning and PathFinding) proposed in [8]. For example, it improves the accuracy on PathFinding(10K) from 33.4% [6] to over 98%.",Towards Neural Network-based Reasoning
66,,,,,,"We propose an end-to-end, domain-independent neural encoder-aligner-decodermodel for selective generation, i.e., the joint task of content selection andsurface realization. Our model first encodes a full set of over-determineddatabase event records via an LSTM-based recurrent neural network, thenutilizes a novel coarse-to-fine aligner to identify the small subset of salientrecords to talk about, and finally employs a decoder to generate free-formdescriptions of the aligned, selected records. Our model achieves the bestselection and generation results reported to-date (with 59% relativeimprovement in generation) on the benchmark WeatherGov dataset, despite usingno specialized features or linguistic resources. Using an improved k-nearestneighbor beam filter helps further. We also perform a series of ablations andvisualizations to elucidate the contributions of our key model components.Lastly, we evaluate the generalizability of our model on the RoboCup dataset,and get results that are competitive with or better than the state-of-the-art,despite being severely data-starved.",What to talk about and how? Selective Generation using LSTMs with  Coarse-to-Fine Alignment
67,,,,,,"While most approaches to automatically recognizing entailment relations haveused classifiers employing hand engineered features derived from complexnatural language processing pipelines, in practice their performance has beenonly slightly better than bag-of-word pair classifiers using only lexicalsimilarity. The only attempt so far to build an end-to-end differentiableneural network for entailment failed to outperform such a simple similarityclassifier. In this paper, we propose a neural model that reads two sentencesto determine entailment using long short-term memory units. We extend thismodel with a word-by-word neural attention mechanism that encourages reasoningover entailments of pairs of words and phrases. Furthermore, we present aqualitative analysis of attention weights produced by this model, demonstratingsuch reasoning capabilities. On a large entailment dataset this modeloutperforms the previous best neural model and a classifier with engineeredfeatures by a substantial margin. It is the first generic end-to-enddifferentiable system that achieves state-of-the-art accuracy on a textualentailment dataset.",Reasoning about Entailment with Neural Attention
68,,,,,,"In this paper, we extend the deep long short-term memory (DLSTM) recurrentneural networks by introducing gated direct connections between memory cells inadjacent layers. These direct links, called highway connections, enableunimpeded information flow across different layers and thus alleviate thegradient vanishing problem when building deeper LSTMs. We further introduce thelatency-controlled bidirectional LSTMs (BLSTMs) which can exploit the wholehistory while keeping the latency under control. Efficient algorithms areproposed to train these novel networks using both frame and sequencediscriminative criteria. Experiments on the AMI distant speech recognition(DSR) task indicate that we can train deeper LSTMs and achieve betterimprovement from sequence training with highway LSTMs (HLSTMs). Our novel modelobtains $43.9/47.7\%$ WER on AMI (SDM) dev and eval sets, outperforming allprevious works. It beats the strong DNN and DLSTM baselines with $15.7\%$ and$5.3\%$ relative improvement respectively.",Highway Long Short-Term Memory RNNs for Distant Speech Recognition
69,Nuclear,,,Nuclear,,"We proposed Neural Enquirer as a neural network architecture to execute anatural language (NL) query on a knowledge-base (KB) for answers. Basically,Neural Enquirer finds the distributed representation of a query and thenexecutes it on knowledge-base tables to obtain the answer as one of the valuesin the tables. Unlike similar efforts in end-to-end training of semanticparsers, Neural Enquirer is fully ""neuralized"": it not only givesdistributional representation of the query and the knowledge-base, but alsorealizes the execution of compositional queries as a series of differentiableoperations, with intermediate results (consisting of annotations of the tablesat different levels) saved on multiple layers of memory. Neural Enquirer can betrained with gradient descent, with which not only the parameters of thecontrolling components and semantic parsing component, but also the embeddingsof the tables and query words can be learned from scratch. The training can bedone in an end-to-end fashion, but it can take stronger guidance, e.g., thestep-by-step supervision for complicated queries, and benefit from it. NeuralEnquirer is one step towards building neural network systems which seek tounderstand language by executing it on real-world. Our experiments show thatNeural Enquirer can learn to execute fairly complicated NL queries on tableswith rich structures.",Neural Enquirer: Learning to Query Tables with Natural Language
70,Data,Data,,,,"We review the task of Sentence Pair Scoring, popular in the literature invarious forms - viewed as Answer Sentence Selection, Semantic Text Scoring,Next Utterance Ranking, Recognizing Textual Entailment, Paraphrasing or e.g. acomponent of Memory Networks.  We argue that all such tasks are similar from the model perspective andpropose new baselines by comparing the performance of common IR metrics andpopular convolutional, recurrent and attention-based neural models across manySentence Pair Scoring tasks and datasets. We discuss the problem of evaluatingrandomized models, propose a statistically grounded methodology, and attempt toimprove comparisons by releasing new datasets that are much harder than some ofthe currently used well explored benchmarks. We introduce a unified open sourcesoftware framework with easily pluggable models and tasks, which enables us toexperiment with multi-task reusability of trained sentence model. We set a newstate-of-art in performance on the Ubuntu Dialogue dataset.",Sentence Pair Scoring: Towards Unified Framework for Text Comprehension
71,,,,,,"We address an important problem in sequence-to-sequence (Seq2Seq) learningreferred to as copying, in which certain segments in the input sequence areselectively replicated in the output sequence. A similar phenomenon isobservable in human language communication. For example, humans tend to repeatentity names or even long phrases in conversation. The challenge with regard tocopying in Seq2Seq is that new machinery is needed to decide when to performthe operation. In this paper, we incorporate copying into neural network-basedSeq2Seq learning and propose a new model called CopyNet with encoder-decoderstructure. CopyNet can nicely integrate the regular way of word generation inthe decoder with the new copying mechanism which can choose sub-sequences inthe input sequence and put them at proper places in the output sequence. Ourempirical study on both synthetic data sets and real world data setsdemonstrates the efficacy of CopyNet. For example, CopyNet can outperformregular RNN-based model with remarkable margins on text summarization tasks.",Incorporating Copying Mechanism in Sequence-to-Sequence Learning
72,DV,DV,,,,"Over the past decade, large-scale supervised learning corpora have enabledmachine learning researchers to make substantial advances. However, to thisdate, there are no large-scale question-answer corpora available. In this paperwe present the 30M Factoid Question-Answer Corpus, an enormous question answerpair corpus produced by applying a novel neural network architecture on theknowledge base Freebase to transduce facts into natural language questions. Theproduced question answer pairs are evaluated both by human evaluators and usingautomatic evaluation metrics, including well-established machine translationand sentence similarity metrics. Across all evaluation criteria thequestion-generation model outperforms the competing template-based baseline.Furthermore, when presented to human evaluators, the generated questions appearcomparable in quality to real human-generated questions.",Generating Factoid Questions With Recurrent Neural Networks: The 30M  Factoid Question-Answer Corpus
73,Data,,,Data,,"We investigate evaluation metrics for dialogue response generation systemswhere supervised labels, such as task completion, are not available. Recentworks in response generation have adopted metrics from machine translation tocompare a model's generated response to a single target response. We show thatthese metrics correlate very weakly with human judgements in the non-technicalTwitter domain, and not at all in the technical Ubuntu domain. We providequantitative and qualitative results highlighting specific weaknesses inexisting metrics, and provide recommendations for future development of betterautomatic evaluation metrics for dialogue systems.",How NOT To Evaluate Your Dialogue System: An Empirical Study of  Unsupervised Evaluation Metrics for Dialogue Response Generation
74,,,,,,"Sequential data often possesses a hierarchical structure with complexdependencies between subsequences, such as found between the utterances in adialogue. In an effort to model this kind of generative process, we propose aneural network-based generative architecture, with latent stochastic variablesthat span a variable number of time steps. We apply the proposed model to thetask of dialogue response generation and compare it with recent neural networkarchitectures. We evaluate the model performance through automatic evaluationmetrics and by carrying out a human evaluation. The experiments demonstratethat our model improves upon recently proposed models and that the latentvariables facilitate the generation of long outputs and maintain the context.",A Hierarchical Latent Variable Encoder-Decoder Model for Generating  Dialogues
75,Physics,,,Physics,,"Many important NLP problems can be posed as dual-sequence orsequence-to-sequence modeling tasks. Recent advances in building end-to-endneural architectures have been highly successful in solving such tasks. In thiswork we propose a new architecture for dual-sequence modeling that is based onassociative memory. We derive AM-RNNs, a recurrent associative memory (AM)which augments generic recurrent neural networks (RNN). This architecture isextended to the Dual AM-RNN which operates on two AMs at once. Our modelsachieve very competitive results on textual entailment. A qualitative analysisdemonstrates that long range dependencies between source and target-sequencecan be bridged effectively using Dual AM-RNNs. However, an initial experimenton auto-encoding reveals that these benefits are not exploited by the systemwhen learning to solve sequence-to-sequence tasks which indicates thatadditional supervision or regularization is needed.",Neural Associative Memory for Dual-Sequence Modeling
76,Data,Data,,,,"We introduce LL-RNNs (Log-Linear RNNs), an extension of Recurrent NeuralNetworks that replaces the softmax output layer by a log-linear output layer,of which the softmax is a special case. This conceptually simple move has twomain advantages. First, it allows the learner to combat training data sparsityby allowing it to model words (or more generally, output symbols) as complexcombinations of attributes without requiring that each combination is directlyobserved in the training data (as the softmax does). Second, it permits theinclusion of flexible prior knowledge in the form of a priori specified modularfeatures, where the neural network component learns to dynamically control theweights of a log-linear distribution exploiting these features.  We conduct experiments in the domain of language modelling of French, thatexploit morphological prior knowledge and show an important decrease inperplexity relative to a baseline RNN.  We provide other motivating iillustrations, and finally argue that thelog-linear and the neural-network components contribute complementary strengthsto the LL-RNN: the LL aspect allows the model to incorporate rich priorknowledge, while the NN aspect, according to the ""representation learning""paradigm, allows the model to discover novel combination of characteristics.",Log-Linear RNNs: Towards Recurrent Neural Networks with Flexible Prior  Knowledge
77,,,,,,"There is a practically unlimited amount of natural language data available.Still, recent work in text comprehension has focused on datasets which aresmall relative to current computing possibilities. This article is making acase for the community to move to larger data and as a step in that directionit is proposing the BookTest, a new dataset similar to the popular Children'sBook Test (CBT), however more than 60 times larger. We show that training onthe new data improves the accuracy of our Attention-Sum Reader model on theoriginal CBT test data by a much larger margin than many recent attempts toimprove the model architecture. On one version of the dataset our ensemble evenexceeds the human baseline provided by Facebook. We then show in our own humanstudy that there is still space for further improvement.",Embracing data abundance: BookTest Dataset for Reading Comprehension
78,Chemistry,Chemistry,,,,"Recurrent neural networks are a powerful tool for modeling sequential data,but the dependence of each timestep's computation on the previous timestep'soutput limits parallelism and makes RNNs unwieldy for very long sequences. Weintroduce quasi-recurrent neural networks (QRNNs), an approach to neuralsequence modeling that alternates convolutional layers, which apply in parallelacross timesteps, and a minimalist recurrent pooling function that applies inparallel across channels. Despite lacking trainable recurrent layers, stackedQRNNs have better predictive accuracy than stacked LSTMs of the same hiddensize. Due to their increased parallelism, they are up to 16 times faster attrain and test time. Experiments on language modeling, sentimentclassification, and character-level neural machine translation demonstratethese advantages and underline the viability of QRNNs as a basic building blockfor a variety of sequence tasks.",Quasi-Recurrent Neural Networks
79,,,,,,"There exist many problem domains where the interpretability of neural networkmodels is essential for deployment. Here we introduce a recurrent architecturecomposed of input-switched affine transformations - in other words an RNNwithout any explicit nonlinearities, but with input-dependent recurrentweights. This simple form allows the RNN to be analyzed via straightforwardlinear methods: we can exactly characterize the linear contribution of eachinput to the model predictions; we can use a change-of-basis to disentangleinput, output, and computational hidden unit subspaces; we can fullyreverse-engineer the architecture's solution to a simple task. Despite thisease of interpretation, the input switched affine network achieves reasonableperformance on a text modeling tasks, and allows greater computationalefficiency than networks with standard nonlinearities.",Input Switched Affine Networks: An RNN Architecture Designed for  Interpretability
80,,,,,,"Neural language models predict the next token using a latent representationof the immediate token history. Recently, various methods for augmenting neurallanguage models with an attention mechanism over a differentiable memory havebeen proposed. For predicting the next token, these models query informationfrom a memory of the recent history which can facilitate learning mid- andlong-range dependencies. However, conventional attention mechanisms used inmemory-augmented neural language models produce a single output vector per timestep. This vector is used both for predicting the next token as well as for thekey and value of a differentiable memory of a token history. In this paper, wepropose a neural language model with a key-value attention mechanism thatoutputs separate representations for the key and value of a differentiablememory, as well as for encoding the next-word distribution. This modeloutperforms existing memory-augmented neural language models on two corpora.Yet, we found that our method mainly utilizes a memory of the five most recentoutput representations. This led to the unexpected main finding that a muchsimpler model based only on the concatenation of recent output representationsfrom previous time steps is on par with more sophisticated memory-augmentedneural language models.",Frustratingly Short Attention Spans in Neural Language Modeling
81,Physics,,,Physics,,"This paper proposes a new model for extracting an interpretable sentenceembedding by introducing self-attention. Instead of using a vector, we use a2-D matrix to represent the embedding, with each row of the matrix attending ona different part of the sentence. We also propose a self-attention mechanismand a special regularization term for the model. As a side effect, theembedding comes with an easy way of visualizing what specific parts of thesentence are encoded into the embedding. We evaluate our model on 3 differenttasks: author profiling, sentiment classification, and textual entailment.Results show that our model yields a significant performance gain compared toother sentence embedding methods in all of the 3 tasks.",A Structured Self-attentive Sentence Embedding
82,Physics,Physics,,,,"We introduce an attention-based Bi-LSTM for Chinese implicit discourserelations and demonstrate that modeling argument pairs as a joint sequence canoutperform word order-agnostic approaches. Our model benefits from a partialsampling scheme and is conceptually simple, yet achieves state-of-the-artperformance on the Chinese Discourse Treebank. We also visualize its attentionactivity to illustrate the model's ability to selectively focus on the relevantparts of an input sequence.",A Recurrent Neural Model with Attention for the Recognition of Chinese  Implicit Discourse Relations
83,Data,Data,,,,"Automated story generation is the problem of automatically selecting asequence of events, actions, or words that can be told as a story. We seek todevelop a system that can generate stories by learning everything it needs toknow from textual story corpora. To date, recurrent neural networks that learnlanguage models at character, word, or sentence levels have had little successgenerating coherent stories. We explore the question of event representationsthat provide a mid-level of abstraction between words and sentences in order toretain the semantic information of the original data while minimizing eventsparsity. We present a technique for preprocessing textual story data intoevent sequences. We then present a technique for automated story generationwhereby we decompose the problem into the generation of successive events(event2event) and the generation of natural language sentences from events(event2sentence). We give empirical results comparing different eventrepresentations and their effects on event successor generation and thetranslation of events to natural language.",Event Representations for Automated Story Generation with Deep Neural  Nets
84,Physics,Physics,,,,"We propose a generative machine comprehension model that learns jointly toask and answer questions based on documents. The proposed model uses asequence-to-sequence framework that encodes the document and generates aquestion (answer) given an answer (question). Significant improvement in modelperformance is observed empirically on the SQuAD corpus, confirming ourhypothesis that the model benefits from jointly learning to perform both tasks.We believe the joint model's novelty offers a new perspective on machinecomprehension beyond architectural engineering, and serves as a first steptowards autonomous information seeking.",A Joint Model for Question Answering and Question Generation
85,,,,,,"Model compression is significant for the wide adoption of Recurrent NeuralNetworks (RNNs) in both user devices possessing limited resources and businessclusters requiring quick responses to large-scale service requests. This workaims to learn structurally-sparse Long Short-Term Memory (LSTM) by reducing thesizes of basic structures within LSTM units, including input updates, gates,hidden states, cell states and outputs. Independently reducing the sizes ofbasic structures can result in inconsistent dimensions among them, andconsequently, end up with invalid LSTM units. To overcome the problem, wepropose Intrinsic Sparse Structures (ISS) in LSTMs. Removing a component of ISSwill simultaneously decrease the sizes of all basic structures by one andthereby always maintain the dimension consistency. By learning ISS within LSTMunits, the obtained LSTMs remain regular while having much smaller basicstructures. Based on group Lasso regularization, our method achieves 10.59xspeedup without losing any perplexity of a language modeling of Penn TreeBankdataset. It is also successfully evaluated through a compact model with only2.69M weights for machine Question Answering of SQuAD dataset. Our approach issuccessfully extended to non- LSTM RNNs, like Recurrent Highway Networks(RHNs). Our source code is publicly available athttps://github.com/wenwei202/iss-rnns",Learning Intrinsic Sparse Structures within Long Short-Term Memory
86,,,,,,"Representing the semantic relations that exist between two given words (orentities) is an important first step in a wide-range of NLP applications suchas analogical reasoning, knowledge base completion and relational informationretrieval. A simple, yet surprisingly accurate method for representing arelation between two words is to compute the vector offset (\PairDiff) betweentheir corresponding word embeddings. Despite the empirical success, it remainsunclear as to whether \PairDiff is the best operator for obtaining a relationalrepresentation from word embeddings. We conduct a theoretical analysis ofgeneralised bilinear operators that can be used to measure the $\ell_{2}$relational distance between two word-pairs. We show that, if the wordembeddings are standardised and uncorrelated, such an operator will beindependent of bilinear terms, and can be simplified to a linear form, where\PairDiff is a special case. For numerous word embedding types, we empiricallyverify the uncorrelation assumption, demonstrating the general applicability ofour theoretical result. Moreover, we experimentally discover \PairDiff from thebilinear relation composition operator on several benchmark analogy datasets.",Why PairDiff works? -- A Mathematical Analysis of Bilinear Relational  Compositional Operators for Analogy Detection
87,Physics,,,Physics,,"We propose Object-oriented Neural Programming (OONP), a framework forsemantically parsing documents in specific domains. Basically, OONP reads adocument and parses it into a predesigned object-oriented data structure(referred to as ontology in this paper) that reflects the domain-specificsemantics of the document. An OONP parser models semantic parsing as a decisionprocess: a neural net-based Reader sequentially goes through the document, andduring the process it builds and updates an intermediate ontology to summarizeits partial understanding of the text it covers. OONP supports a rich family ofoperations (both symbolic and differentiable) for composing the ontology, and abig variety of forms (both symbolic and differentiable) for representing thestate and the document. An OONP parser can be trained with supervision ofdifferent forms and strength, including supervised learning (SL) ,reinforcement learning (RL) and hybrid of the two. Our experiments on bothsynthetic and real-world document parsing tasks have shown that OONP can learnto handle fairly complicated ontology with training data of modest sizes.",Object-oriented Neural Programming (OONP) for Document Understanding
88,Chemistry,Chemistry,,,,"This paper proposes a novel neural machine reading model for open-domainquestion answering at scale. Existing machine comprehension models typicallyassume that a short piece of relevant text containing answers is alreadyidentified and given to the models, from which the models are designed toextract answers. This assumption, however, is not realistic for building alarge-scale open-domain question answering system which requires both deep textunderstanding and identifying relevant text from corpus simultaneously.  In this paper, we introduce Neural Comprehensive Ranker (NCR) that integratesboth passage ranking and answer extraction in one single framework. A Q&Asystem based on this framework allows users to issue an open-domain questionwithout needing to provide a piece of text that must contain the answer.Experiments show that the unified NCR model is able to outperform thestates-of-the-art in both retrieval of relevant text and answer extraction.",A Neural Comprehensive Ranker (NCR) for Open-Domain Question Answering
89,,,,,,"Speech recognition is largely taking advantage of deep learning, showing thatsubstantial benefits can be obtained by modern Recurrent Neural Networks(RNNs). The most popular RNNs are Long Short-Term Memory (LSTMs), whichtypically reach state-of-the-art performance in many tasks thanks to theirability to learn long-term dependencies and robustness to vanishing gradients.Nevertheless, LSTMs have a rather complex design with three multiplicativegates, that might impair their efficient implementation. An attempt to simplifyLSTMs has recently led to Gated Recurrent Units (GRUs), which are based on justtwo multiplicative gates.  This paper builds on these efforts by further revising GRUs and proposing asimplified architecture potentially more suitable for speech recognition. Thecontribution of this work is two-fold. First, we suggest to remove the resetgate in the GRU design, resulting in a more efficient single-gate architecture.Second, we propose to replace tanh with ReLU activations in the state updateequations. Results show that, in our implementation, the revised architecturereduces the per-epoch training time with more than 30% and consistentlyimproves recognition performance across different tasks, input features, andnoisy conditions when compared to a standard GRU.",Improving speech recognition by revising gated recurrent units
90,,,,,,"Training a task-completion dialogue agent with real users via reinforcementlearning (RL) could be prohibitively expensive, because it requires manyinteractions with users. One alternative is to resort to a user simulator,while the discrepancy of between simulated and real users makes the learnedpolicy unreliable in practice. This paper addresses these challenges byintegrating planning into the dialogue policy learning based on Dyna-Qframework, and provides a more sample-efficient approach to learn the dialoguepolices. The proposed agent consists of a planner trained on-line with limitedreal user experience that can generate large amounts of simulated experience tosupplement with limited real user experience, and a policy model trained onthese hybrid experiences. The effectiveness of our approach is validated on amovie-booking task in both a simulation setting and a human-in-the-loopsetting.",Integrating planning for task-completion dialogue policy learning
91,Physics,Physics,,,,"Deep neural networks (DNNs) are now a central component of nearly allstate-of-the-art speech recognition systems. Building neural network acousticmodels requires several design decisions including network architecture, size,and training loss function. This paper offers an empirical investigation onwhich aspects of DNN acoustic model design are most important for speechrecognition system performance. We report DNN classifier performance and finalspeech recognizer word error rates, and compare DNNs using several metrics toquantify factors influencing differences in task performance. Our first set ofexperiments use the standard Switchboard benchmark corpus, which containsapproximately 300 hours of conversational telephone speech. We compare standardDNNs to convolutional networks, and present the first experiments usinglocally-connected, untied neural networks for acoustic modeling. Weadditionally build systems on a corpus of 2,100 hours of training data bycombining the Switchboard and Fisher corpora. This larger corpus allows us tomore thoroughly examine performance of large DNN models -- with up to ten timesmore parameters than those typically used in speech recognition systems. Ourresults suggest that a relatively simple DNN architecture and optimizationtechnique produces strong results. These findings, along with previous work,help establish a set of best practices for building DNN hybrid speechrecognition systems with maximum likelihood training. Our experiments in DNNoptimization additionally serve as a case study for training DNNs withdiscriminative loss functions for speech tasks, as well as DNN classifiers moregenerally.",Building DNN Acoustic Models for Large Vocabulary Speech Recognition
92,DV,DV,,,,"We present a novel deep Recurrent Neural Network (RNN) model for acousticmodelling in Automatic Speech Recognition (ASR). We term our contribution as aTC-DNN-BLSTM-DNN model, the model combines a Deep Neural Network (DNN) withTime Convolution (TC), followed by a Bidirectional Long Short-Term Memory(BLSTM), and a final DNN. The first DNN acts as a feature processor to ourmodel, the BLSTM then generates a context from the sequence acoustic signal,and the final DNN takes the context and models the posterior probabilities ofthe acoustic states. We achieve a 3.47 WER on the Wall Street Journal (WSJ)eval92 task or more than 8% relative improvement over the baseline DNN models.",Deep Recurrent Neural Networks for Acoustic Modelling
93,Physics,,,Physics,,"We stabilize the activations of Recurrent Neural Networks (RNNs) bypenalizing the squared distance between successive hidden states' norms.  This penalty term is an effective regularizer for RNNs including LSTMs andIRNNs, improving performance on character-level language modeling and phonemerecognition, and outperforming weight noise and dropout.  We achieve competitive performance (18.6\% PER) on the TIMIT phonemerecognition task for RNNs evaluated without beam search or an RNN transducer.  With this penalty term, IRNN can achieve similar performance to LSTM onlanguage modeling, although adding the penalty term to the LSTM results insuperior performance.  Our penalty term also prevents the exponential growth of IRNN's activationsoutside of their training horizon, allowing them to generalize to much longersequences.",Regularizing RNNs by Stabilizing Activations
94,,,,,,"The capacity of a neural network to absorb information is limited by itsnumber of parameters. Conditional computation, where parts of the network areactive on a per-example basis, has been proposed in theory as a way ofdramatically increasing model capacity without a proportional increase incomputation. In practice, however, there are significant algorithmic andperformance challenges. In this work, we address these challenges and finallyrealize the promise of conditional computation, achieving greater than 1000ximprovements in model capacity with only minor losses in computationalefficiency on modern GPU clusters. We introduce a Sparsely-GatedMixture-of-Experts layer (MoE), consisting of up to thousands of feed-forwardsub-networks. A trainable gating network determines a sparse combination ofthese experts to use for each example. We apply the MoE to the tasks oflanguage modeling and machine translation, where model capacity is critical forabsorbing the vast quantities of knowledge available in the training corpora.We present model architectures in which a MoE with up to 137 billion parametersis applied convolutionally between stacked LSTM layers. On large languagemodeling and machine translation benchmarks, these models achieve significantlybetter results than state-of-the-art at lower computational cost.",Outrageously Large Neural Networks: The Sparsely-Gated  Mixture-of-Experts Layer
95,Nuclear,,,Nuclear,,"This work presents a novel objective function for the unsupervised trainingof neural network sentence encoders. It exploits signals from paragraph-leveldiscourse coherence to train these models to understand text. Our objective ispurely discriminative, allowing us to train models many times faster than waspossible under prior methods, and it yields models which perform well inextrinsic evaluations.",Discourse-Based Objectives for Fast Unsupervised Sentence Representation  Learning
96,,,,,,"Visual question answering is a recently proposed artificial intelligence taskthat requires a deep understanding of both images and texts. In deep learning,images are typically modeled through convolutional neural networks, and textsare typically modeled through recurrent neural networks. While the requirementfor modeling images is similar to traditional computer vision tasks, such asobject recognition and image classification, visual question answering raises adifferent need for textual representation as compared to other natural languageprocessing tasks. In this work, we perform a detailed analysis on naturallanguage questions in visual question answering. Based on the analysis, wepropose to rely on convolutional neural networks for learning textualrepresentations. By exploring the various properties of convolutional neuralnetworks specialized for text data, such as width and depth, we present our""CNN Inception + Gate"" model. We show that our model improves questionrepresentations and thus the overall accuracy of visual question answeringmodels. We also show that the text representation requirement in visualquestion answering is more complicated and comprehensive than that inconventional natural language processing tasks, making it a better task toevaluate textual representation methods. Shallow models like fastText, whichcan obtain comparable results with deep learning models in tasks like textclassification, are not suitable in visual question answering.",Learning Convolutional Text Representations for Visual Question  Answering
97,,,,,,"In this paper, we propose a novel neural network model called RNNEncoder-Decoder that consists of two recurrent neural networks (RNN). One RNNencodes a sequence of symbols into a fixed-length vector representation, andthe other decodes the representation into another sequence of symbols. Theencoder and decoder of the proposed model are jointly trained to maximize theconditional probability of a target sequence given a source sequence. Theperformance of a statistical machine translation system is empirically found toimprove by using the conditional probabilities of phrase pairs computed by theRNN Encoder-Decoder as an additional feature in the existing log-linear model.Qualitatively, we show that the proposed model learns a semantically andsyntactically meaningful representation of linguistic phrases.",Learning Phrase Representations using RNN Encoder-Decoder for  Statistical Machine Translation
98,,,,,,"Recurrent neural networks (RNNs), particularly long short-term memory (LSTM),have gained much attention in automatic speech recognition (ASR). Although somesuccessful stories have been reported, training RNNs remains highlychallenging, especially with limited training data. Recent research found thata well-trained model can be used as a teacher to train other child models, byusing the predictions generated by the teacher model as supervision. Thisknowledge transfer learning has been employed to train simple neural nets witha complex one, so that the final performance can reach a level that isinfeasible to obtain by regular training. In this paper, we employ theknowledge transfer learning approach to train RNNs (precisely LSTM) using adeep neural network (DNN) model as the teacher. This is different from most ofthe existing research on knowledge transfer learning, since the teacher (DNN)is assumed to be weaker than the child (RNN); however, our experiments on anASR task showed that it works fairly well: without applying any tricks on thelearning scheme, this approach can train RNNs successfully even with limitedtraining data.",Recurrent Neural Network Training with Dark Knowledge Transfer
99,,,,,,"Long Short-Term Memory (LSTM) is a recurrent neural network (RNN)architecture that has been designed to address the vanishing and explodinggradient problems of conventional RNNs. Unlike feedforward neural networks,RNNs have cyclic connections making them powerful for modeling sequences. Theyhave been successfully used for sequence labeling and sequence predictiontasks, such as handwriting recognition, language modeling, phonetic labeling ofacoustic frames. However, in contrast to the deep neural networks, the use ofRNNs in speech recognition has been limited to phone recognition in small scaletasks. In this paper, we present novel LSTM based RNN architectures which makemore effective use of model parameters to train acoustic models for largevocabulary speech recognition. We train and compare LSTM, RNN and DNN models atvarious numbers of parameters and configurations. We show that LSTM modelsconverge quickly and give state of the art speech recognition performance forrelatively small sized models.",Long Short-Term Memory Based Recurrent Neural Network Architectures for  Large Vocabulary Speech Recognition
100,Physics,,,Physics,,"Based on the Aristotelian concept of potentiality vs. actuality allowing forthe study of energy and dynamics in language, we propose a field approach tolexical analysis. Falling back on the distributional hypothesis tostatistically model word meaning, we used evolving fields as a metaphor toexpress time-dependent changes in a vector space model by a combination ofrandom indexing and evolving self-organizing maps (ESOM). To monitor semanticdrifts within the observation period, an experiment was carried out on the termspace of a collection of 12.8 million Amazon book reviews. For evaluation, thesemantic consistency of ESOM term clusters was compared with their respectiveneighbourhoods in WordNet, and contrasted with distances among term vectors byrandom indexing. We found that at 0.05 level of significance, the terms in theclusters showed a high level of semantic consistency. Tracking the drift ofdistributional patterns in the term space across time periods, we found thatconsistency decreased, but not at a statistically significant level. Our methodis highly scalable, with interpretations in philosophy.",Monitoring Term Drift Based on Semantic Consistency in an Evolving  Vector Field
101,,,,,,"The recently proposed Sequence-to-Sequence (seq2seq) framework advocatesreplacing complex data processing pipelines, such as an entire automatic speechrecognition system, with a single neural network trained in an end-to-endfashion. In this contribution, we analyse an attention-based seq2seq speechrecognition system that directly transcribes recordings into characters. Weobserve two shortcomings: overconfidence in its predictions and a tendency toproduce incomplete transcriptions when language models are used. We proposepractical solutions to both problems achieving competitive speaker independentword error rates on the Wall Street Journal dataset: without separate languagemodels we reach 10.6% WER, while together with a trigram language model, wereach 6.7% WER.",Towards better decoding and language model integration in sequence to  sequence models
102,,,,,,"Neural machine translation is a recently proposed approach to machinetranslation. Unlike the traditional statistical machine translation, the neuralmachine translation aims at building a single neural network that can bejointly tuned to maximize the translation performance. The models proposedrecently for neural machine translation often belong to a family ofencoder-decoders and consists of an encoder that encodes a source sentence intoa fixed-length vector from which a decoder generates a translation. In thispaper, we conjecture that the use of a fixed-length vector is a bottleneck inimproving the performance of this basic encoder-decoder architecture, andpropose to extend this by allowing a model to automatically (soft-)search forparts of a source sentence that are relevant to predicting a target word,without having to form these parts as a hard segment explicitly. With this newapproach, we achieve a translation performance comparable to the existingstate-of-the-art phrase-based system on the task of English-to-Frenchtranslation. Furthermore, qualitative analysis reveals that the(soft-)alignments found by the model agree well with our intuition.",Neural Machine Translation by Jointly Learning to Align and Translate
103,,,,,,"The authors of (Cho et al., 2014a) have shown that the recently introducedneural network translation systems suffer from a significant drop intranslation quality when translating long sentences, unlike existingphrase-based translation systems. In this paper, we propose a way to addressthis issue by automatically segmenting an input sentence into phrases that canbe easily translated by the neural network translation model. Once each segmenthas been independently translated by the neural machine translation model, thetranslated clauses are concatenated to form a final translation. Empiricalresults show a significant improvement in translation quality for longsentences.",Overcoming the Curse of Sentence Length for Neural Machine Translation  using Automatic Segmentation
104,,,,,,"Deep Neural Network (DNN) acoustic models have yielded many state-of-the-artresults in Automatic Speech Recognition (ASR) tasks. More recently, RecurrentNeural Network (RNN) models have been shown to outperform DNNs counterparts.However, state-of-the-art DNN and RNN models tend to be impractical to deployon embedded systems with limited computational capacity. Traditionally, theapproach for embedded platforms is to either train a small DNN directly, or totrain a small DNN that learns the output distribution of a large DNN. In thispaper, we utilize a state-of-the-art RNN to transfer knowledge to small DNN. Weuse the RNN model to generate soft alignments and minimize the Kullback-Leiblerdivergence against the small DNN. The small DNN trained on the soft RNNalignments achieved a 3.93 WER on the Wall Street Journal (WSJ) eval92 taskcompared to a baseline 4.54 WER or more than 13% relative improvement.",Transferring Knowledge from a RNN to a DNN
105,,,,,,"Common Representation Learning (CRL), wherein different descriptions (orviews) of the data are embedded in a common subspace, is receiving a lot ofattention recently. Two popular paradigms here are Canonical CorrelationAnalysis (CCA) based approaches and Autoencoder (AE) based approaches. CCAbased approaches learn a joint representation by maximizing correlation of theviews when projected to the common subspace. AE based methods learn a commonrepresentation by minimizing the error of reconstructing the two views. Each ofthese approaches has its own advantages and disadvantages. For example, whileCCA based approaches outperform AE based approaches for the task of transferlearning, they are not as scalable as the latter. In this work we propose an AEbased approach called Correlational Neural Network (CorrNet), that explicitlymaximizes correlation among the views when projected to the common subspace.Through a series of experiments, we demonstrate that the proposed CorrNet isbetter than the above mentioned approaches with respect to its ability to learncorrelated common representations. Further, we employ CorrNet for several crosslanguage tasks and show that the representations learned using CorrNet performbetter than the ones learned using other state of the art approaches.",Correlational Neural Networks
106,Chemistry,Chemistry,,,,"Recurrent sequence generators conditioned on input data through an attentionmechanism have recently shown very good performance on a range of tasks in-cluding machine translation, handwriting synthesis and image caption gen-eration. We extend the attention-mechanism with features needed for speechrecognition. We show that while an adaptation of the model used for machinetranslation in reaches a competitive 18.7% phoneme error rate (PER) on theTIMIT phoneme recognition task, it can only be applied to utterances which areroughly as long as the ones it was trained on. We offer a qualitativeexplanation of this failure and propose a novel and generic method of addinglocation-awareness to the attention mechanism to alleviate this issue. The newmethod yields a model that is robust to long inputs and achieves 18% PER insingle utterances and 20% in 10-times longer (repeated) utterances. Finally, wepropose a change to the at- tention mechanism that prevents it fromconcentrating too much on single frames, which further reduces PER to 17.6%level.",Attention-Based Models for Speech Recognition
107,Nuclear,,,Nuclear,,"We have recently shown that deep Long Short-Term Memory (LSTM) recurrentneural networks (RNNs) outperform feed forward deep neural networks (DNNs) asacoustic models for speech recognition. More recently, we have shown that theperformance of sequence trained context dependent (CD) hidden Markov model(HMM) acoustic models using such LSTM RNNs can be equaled by sequence trainedphone models initialized with connectionist temporal classification (CTC). Inthis paper, we present techniques that further improve performance of LSTM RNNacoustic models for large vocabulary speech recognition. We show that framestacking and reduced frame rate lead to more accurate models and fasterdecoding. CD phone modeling leads to further improvements. We also presentinitial results for LSTM RNN models outputting words directly.",Fast and Accurate Recurrent Neural Network Acoustic Models for Speech  Recognition
108,Data,,,Data,,"We present Listen, Attend and Spell (LAS), a neural network that learns totranscribe speech utterances to characters. Unlike traditional DNN-HMM models,this model learns all the components of a speech recognizer jointly. Our systemhas two components: a listener and a speller. The listener is a pyramidalrecurrent network encoder that accepts filter bank spectra as inputs. Thespeller is an attention-based recurrent network decoder that emits charactersas outputs. The network produces character sequences without making anyindependence assumptions between the characters. This is the key improvement ofLAS over previous end-to-end CTC models. On a subset of the Google voice searchtask, LAS achieves a word error rate (WER) of 14.1% without a dictionary or alanguage model, and 10.3% with language model rescoring over the top 32 beams.By comparison, the state-of-the-art CLDNN-HMM model achieves a WER of 8.0%.","Listen, Attend and Spell"
109,,,,,,"We propose BlackOut, an approximation algorithm to efficiently train massiverecurrent neural network language models (RNNLMs) with million wordvocabularies. BlackOut is motivated by using a discriminative loss, and wedescribe a new sampling strategy which significantly reduces computation whileimproving stability, sample efficiency, and rate of convergence. One way tounderstand BlackOut is to view it as an extension of the DropOut strategy tothe output layer, wherein we use a discriminative training loss and a weightedsampling scheme. We also establish close connections between BlackOut,importance sampling, and noise contrastive estimation (NCE). Our experiments,on the recently released one billion word language modeling benchmark,demonstrate scalability and accuracy of BlackOut; we outperform thestate-of-the art, and achieve the lowest perplexity scores on this dataset.Moreover, unlike other established methods which typically require GPUs or CPUclusters, we show that a carefully implemented version of BlackOut requiresonly 1-10 days on a single machine to train a RNNLM with a million wordvocabulary and billions of parameters on one billion words. Although wedescribe BlackOut in the context of RNNLM training, it can be used to anynetworks with large softmax output layers.",BlackOut: Speeding up Recurrent Neural Network Language Models With Very  Large Vocabularies
110,,,,,,"Neural Machine Translation (MT) has reached state-of-the-art results.However, one of the main challenges that neural MT still faces is dealing withvery large vocabularies and morphologically rich languages. In this paper, wepropose a neural MT system using character-based embeddings in combination withconvolutional and highway layers to replace the standard lookup-based wordrepresentations. The resulting unlimited-vocabulary and affix-aware source wordembeddings are tested in a state-of-the-art neural MT based on anattention-based bidirectional recurrent neural network. The proposed MT schemeprovides improved results even when the source language is not morphologicallyrich. Improvements up to 3 BLEU points are obtained in the German-English WMTtask.",Character-based Neural Machine Translation
111,,,,,,"This paper presents a novel latent variable recurrent neural networkarchitecture for jointly modeling sequences of words and (possibly latent)discourse relations between adjacent sentences. A recurrent neural networkgenerates individual words, thus reaping the benefits ofdiscriminatively-trained vector representations. The discourse relations arerepresented with a latent variable, which can be predicted or marginalized,depending on the task. The resulting model can therefore employ a trainingobjective that includes not only discourse relation classification, but alsoword prediction. As a result, it outperforms state-of-the-art alternatives fortwo tasks: implicit discourse relation classification in the Penn DiscourseTreebank, and dialog act classification in the Switchboard corpus. Furthermore,by marginalizing over latent discourse relations at test time, we obtain adiscourse informed language model, which improves over a strong LSTM baseline.",A Latent Variable Recurrent Neural Network for Discourse Relation  Language Models
112,DV,DV,,,,"Although highly correlated, speech and speaker recognition have been regardedas two independent tasks and studied by two communities. This is certainly notthe way that people behave: we decipher both speech content and speaker traitsat the same time. This paper presents a unified model to perform speech andspeaker recognition simultaneously and altogether. The model is based on aunified neural network where the output of one task is fed to the input of theother, leading to a multi-task recurrent network. Experiments show that thejoint model outperforms the task-specific models on both the two tasks.",Multi-task Recurrent Model for Speech and Speaker Recognition
113,,,,,,"Memory networks are neural networks with an explicit memory component thatcan be both read and written to by the network. The memory is often addressedin a soft way using a softmax function, making end-to-end training withbackpropagation possible. However, this is not computationally scalable forapplications which require the network to read from extremely large memories.On the other hand, it is well known that hard attention mechanisms based onreinforcement learning are challenging to train successfully. In this paper, weexplore a form of hierarchical memory network, which can be considered as ahybrid between hard and soft attention memory networks. The memory is organizedin a hierarchical structure such that reading from it is done with lesscomputation than soft attention over a flat memory, while also being easier totrain than hard attention over a flat memory. Specifically, we propose toincorporate Maximum Inner Product Search (MIPS) in the training and inferenceprocedures for our hierarchical memory network. We explore the use of variousstate-of-the art approximate MIPS techniques and report results onSimpleQuestions, a challenging large scale factoid question answering task.",Hierarchical Memory Networks
114,,,,,,"Sequence-to-Sequence (seq2seq) modeling has rapidly become an importantgeneral-purpose NLP tool that has proven effective for many text-generation andsequence-labeling tasks. Seq2seq builds on deep neural language modeling andinherits its remarkable accuracy in estimating local, next-word distributions.In this work, we introduce a model and beam-search training scheme, based onthe work of Daume III and Marcu (2005), that extends seq2seq to learn globalsequence scores. This structured approach avoids classical biases associatedwith local training and unifies the training loss with the test-time usage,while preserving the proven model architecture of seq2seq and its efficienttraining approach. We show that our system outperforms a highly-optimizedattention-based seq2seq system and other baselines on three different sequenceto sequence tasks: word ordering, parsing, and machine translation.",Sequence-to-Sequence Learning as Beam-Search Optimization
115,,,,,,"In this work, we present the Grounded Recurrent Neural Network (GRNN), arecurrent neural network architecture for multi-label prediction whichexplicitly ties labels to specific dimensions of the recurrent hidden state (wecall this process ""grounding""). The approach is particularly well-suited forextracting large numbers of concepts from text. We apply the new model toaddress an important problem in healthcare of understanding what medicalconcepts are discussed in clinical text. Using a publicly available datasetderived from Intensive Care Units, we learn to label a patient's diagnoses andprocedures from their discharge summary. Our evaluation shows a clear advantageto using our proposed architecture over a variety of strong baselines.",Grounded Recurrent Neural Networks
116,Nuclear,,,Nuclear,,"Developing a dialogue agent that is capable of making autonomous decisionsand communicating by natural language is one of the long-term goals of machinelearning research. Traditional approaches either rely on hand-crafting a smallstate-action set for applying reinforcement learning that is not scalable orconstructing deterministic models for learning dialogue sentences that fail tocapture natural conversational variability. In this paper, we propose a LatentIntention Dialogue Model (LIDM) that employs a discrete latent variable tolearn underlying dialogue intentions in the framework of neural variationalinference. In a goal-oriented dialogue scenario, these latent intentions can beinterpreted as actions guiding the generation of machine responses, which canbe further refined autonomously by reinforcement learning. The experimentalevaluation of LIDM shows that the model out-performs published benchmarks forboth corpus-based and human evaluation, demonstrating the effectiveness ofdiscrete latent variable models for learning goal-oriented dialogues.",Latent Intention Dialogue Models
117,,,,,,"End-to-end training of automated speech recognition (ASR) systems requiresmassive data and compute resources. We explore transfer learning based on modeladaptation as an approach for training ASR models under constrained GPU memory,throughput and training data. We conduct several systematic experimentsadapting a Wav2Letter convolutional neural network originally trained forEnglish ASR to the German language. We show that this technique allows fastertraining on consumer-grade resources while requiring less training data inorder to achieve the same accuracy, thereby lowering the cost of training ASRmodels in other languages. Model introspection revealed that small adaptationsto the network's weights were sufficient for good performance, especially forinner layers.",Transfer Learning for Speech Recognition on a Budget
118,Physics,,,Physics,,"State-level minimum Bayes risk (sMBR) training has become the de factostandard for sequence-level training of speech recognition acoustic models. Ithas an elegant formulation using the expectation semiring, and gives largeimprovements in word error rate (WER) over models trained solely usingcross-entropy (CE) or connectionist temporal classification (CTC). sMBRtraining optimizes the expected number of frames at which the reference andhypothesized acoustic states differ. It may be preferable to optimize theexpected WER, but WER does not interact well with the expectation semiring, andprevious approaches based on computing expected WER exactly involve expandingthe lattices used during training. In this paper we show how to performoptimization of the expected WER by sampling paths from the lattices usedduring conventional sMBR training. The gradient of the expected WER is itselfan expectation, and so may be approximated using Monte Carlo sampling. We showexperimentally that optimizing WER during acoustic model training gives 5%relative improvement in WER over a well-tuned sMBR baseline on a 2-channelquery recognition task (Google Home).",Optimizing expected word error rate via sampling for speech recognition
119,DV,DV,,,,"In this paper, we consider several compression techniques for the languagemodeling problem based on recurrent neural networks (RNNs). It is known thatconventional RNNs, e.g, LSTM-based networks in language modeling, arecharacterized with either high space complexity or substantial inference time.This problem is especially crucial for mobile applications, in which theconstant interaction with the remote server is inappropriate. By using the PennTreebank (PTB) dataset we compare pruning, quantization, low-rankfactorization, tensor train decomposition for LSTM networks in terms of modelsize and suitability for fast inference.",Neural Networks Compression for Language Modeling
120,Physics,Physics,,,,"Training deep neural networks requires massive amounts of training data, butfor many tasks only limited labeled data is available. This makes weaksupervision attractive, using weak or noisy signals like the output ofheuristic methods or user click-through data for training. In a semi-supervisedsetting, we can use a large set of data with weak labels to pretrain a neuralnetwork and then fine-tune the parameters with a small amount of data with truelabels. This feels intuitively sub-optimal as these two independent stagesleave the model unaware about the varying label quality. What if we couldsomehow inform the model about the label quality? In this paper, we propose asemi-supervised learning method where we train two neural networks in amulti-task fashion: a ""target network"" and a ""confidence network"". The targetnetwork is optimized to perform a given task and is trained using a large setof unlabeled data that are weakly annotated. We propose to weight the gradientupdates to the target network using the scores provided by the secondconfidence network, which is trained on a small amount of supervised data. Thuswe avoid that the weight updates computed from noisy labels harm the quality ofthe target network model. We evaluate our learning strategy on two differenttasks: document ranking and sentiment classification. The results demonstratethat our approach not only enhances the performance compared to the baselinesbut also speeds up the learning process from weak labels.",Avoiding Your Teacher's Mistakes: Training Neural Networks with  Controlled Weak Supervision
121,Chemistry,Chemistry,,,,"In statistical dialogue management, the dialogue manager learns a policy thatmaps a belief state to an action for the system to perform. Efficientexploration is key to successful policy optimisation. Current deepreinforcement learning methods are very promising but rely on epsilon-greedyexploration, thus subjecting the user to a random choice of action duringlearning. Alternative approaches such as Gaussian Process SARSA (GPSARSA)estimate uncertainties and are sample efficient, leading to better userexperience, but on the expense of a greater computational complexity. Thispaper examines approaches to extract uncertainty estimates from deep Q-networks(DQN) in the context of dialogue management. We perform an extensive benchmarkof deep Bayesian methods to extract uncertainty estimates, namelyBayes-By-Backprop, dropout, its concrete variation, bootstrapped ensemble andalpha-divergences, combining it with DQN algorithm.",Uncertainty Estimates for Efficient Neural Network-based Dialogue Policy  Optimisation
122,Physics,Physics,,,,"In this work, we investigate the memory capability of recurrent neuralnetworks (RNNs), where this capability is defined as a function that maps anelement in a sequence to the current output. We first analyze the systemfunction of a recurrent neural network (RNN) cell, and provide analyticalresults for three RNNs. They are the simple recurrent neural network (SRN), thelong short-term memory (LSTM), and the gated recurrent unit (GRU). Based on theanalysis, we propose a new design to extend the memory length of a cell, andcall it the extended long short-term memory (ELSTM). Next, we present adependent bidirectional recurrent neural network (DBRNN) for thesequence-in-sequence-out (SISO) problem, which is more robust to previouserroneous predictions. Extensive experiments are carried out on differentlanguage tasks to demonstrate the superiority of our proposed ELSTM and DBRNNsolutions.",On Extended Long Short-term Memory and Dependent Bidirectional Recurrent  Neural Network
123,,,,,,"In this paper, we propose to employ the convolutional neural network (CNN)for the image question answering (QA). Our proposed CNN provides an end-to-endframework with convolutional architectures for learning not only the image andquestion representations, but also their inter-modal interactions to producethe answer. More specifically, our model consists of three CNNs: one image CNNto encode the image content, one sentence CNN to compose the words of thequestion, and one multimodal convolution layer to learn their jointrepresentation for the classification in the space of candidate answer words.We demonstrate the efficacy of our proposed model on the DAQUAR and COCO-QAdatasets, which are two benchmark datasets for the image QA, with theperformances significantly outperforming the state-of-the-art.",Learning to Answer Questions From Image Using Convolutional Neural  Network
124,,,,,,"This paper presents stacked attention networks (SANs) that learn to answernatural language questions from images. SANs use semantic representation of aquestion as query to search for the regions in an image that are related to theanswer. We argue that image question answering (QA) often requires multiplesteps of reasoning. Thus, we develop a multiple-layer SAN in which we query animage multiple times to infer the answer progressively. Experiments conductedon four image QA data sets demonstrate that the proposed SANs significantlyoutperform previous state-of-the-art approaches. The visualization of theattention layers illustrates the progress that the SAN locates the relevantvisual clues that lead to the answer of the question layer-by-layer.",Stacked Attention Networks for Image Question Answering
125,Physics,Physics,,,,"Visual question answering is fundamentally compositional in nature---aquestion like ""where is the dog?"" shares substructure with questions like ""whatcolor is the dog?"" and ""where is the cat?"" This paper seeks to simultaneouslyexploit the representational capacity of deep networks and the compositionallinguistic structure of questions. We describe a procedure for constructing andlearning *neural module networks*, which compose collections of jointly-trainedneural ""modules"" into deep networks for question answering. Our approachdecomposes questions into their linguistic substructures, and uses thesestructures to dynamically instantiate modular networks (with reusablecomponents for recognizing dogs, classifying colors, etc.). The resultingcompound networks are jointly trained. We evaluate our approach on twochallenging datasets for visual question answering, achieving state-of-the-artresults on both the VQA natural image dataset and a new dataset of complexquestions about abstract shapes.",Neural Module Networks
126,Physics,Physics,,,,"In this paper, we extend a symbolic association framework for being able tohandle missing elements in multimodal sequences. The general scope of the workis the symbolic associations of object-word mappings as it happens in languagedevelopment in infants. In other words, two different representations of thesame abstract concepts can associate in both directions. This scenario has beenlong interested in Artificial Intelligence, Psychology, and Neuroscience. Inthis work, we extend a recent approach for multimodal sequences (visual andaudio) to also cope with missing elements in one or both modalities. Our methoduses two parallel Long Short-Term Memories (LSTMs) with a learning rule basedon EM-algorithm. It aligns both LSTM outputs via Dynamic Time Warping (DTW). Wepropose to include an extra step for the combination with the max operation forexploiting the common elements between both sequences. The motivation behind isthat the combination acts as a condition selector for choosing the bestrepresentation from both LSTMs. We evaluated the proposed extension in thefollowing scenarios: missing elements in one modality (visual or audio) andmissing elements in both modalities (visual and sound). The performance of ourextension reaches better results than the original model and similar results toindividual LSTM trained in each modality.",Symbol Grounding Association in Multimodal Sequences with Missing  Elements
127,Nuclear,,,Nuclear,,"The growing importance of massive datasets with the advent of deep learningmakes robustness to label noise a critical property for classifiers to have.Sources of label noise include automatic labeling for large datasets,non-expert labeling, and label corruption by data poisoning adversaries. In thelatter case, corruptions may be arbitrarily bad, even so bad that a classifierpredicts the wrong labels with high confidence. To protect against such sourcesof noise, we leverage the fact that a small set of clean labels is often easyto procure. We demonstrate that robustness to label noise up to severestrengths can be achieved by using a set of trusted data with clean labels, andpropose a loss correction that utilizes trusted examples in a data-efficientmanner to mitigate the effects of label noise on deep neural networkclassifiers. Across vision and natural language processing tasks, we experimentwith various label noises at several strengths, and show that our methodsignificantly outperforms existing methods.",Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe  Noise
128,Physics,Physics,,,,"Whereas deep neural networks were first mostly used for classification tasks,they are rapidly expanding in the realm of structured output problems, wherethe observed target is composed of multiple random variables that have a richjoint distribution, given the input. We focus in this paper on the case wherethe input also has a rich structure and the input and output structures aresomehow related. We describe systems that learn to attend to different placesin the input, for each element of the output, for a variety of tasks: machinetranslation, image caption generation, video clip description and speechrecognition. All these systems are based on a shared set of building blocks:gated recurrent neural networks and convolutional neural networks, along withtrained attention mechanisms. We report on experimental results with thesesystems, showing impressively good performance and the advantage of theattention mechanism.",Describing Multimedia Content using Attention-based Encoder--Decoder  Networks
129,,,,,,"In this paper we present an approach to multi-language image descriptionbringing together insights from neural machine translation and neural imagedescription. To create a description of an image for a given target language,our sequence generation models condition on feature vectors from the image, thedescription from the source language, and/or a multimodal vector computed overthe image and a description in the source language. In image descriptionexperiments on the IAPR-TC12 dataset of images aligned with English and Germansentences, we find significant and substantial improvements in BLEU4 and Meteorscores for models trained over multiple languages, compared to a monolingualbaseline.",Multilingual Image Description with Neural Sequence Models
130,Nuclear,,,Nuclear,,"This paper introduces the visually informed embedding of word (VIEW), acontinuous vector representation for a word extracted from a deep neural modeltrained using the Microsoft COCO data set to forecast the spatial arrangementsbetween visual objects, given a textual description. The model is composed of adeep multilayer perceptron (MLP) stacked on the top of a Long Short Term Memory(LSTM) network, the latter being preceded by an embedding layer. The VIEW isapplied to transferring multimodal background knowledge to Spatial RoleLabeling (SpRL) algorithms, which recognize spatial relations between objectsmentioned in the text. This work also contributes with a new method to selectcomplementary features and a fine-tuning method for MLP that improves the $F1$measure in classifying the words into spatial roles. The VIEW is evaluated withthe Task 3 of SemEval-2013 benchmark data set, SpaceEval.",Deep Embedding for Spatial Role Labeling
131,Chemistry,,,Chemistry,,"We present a neural encoder-decoder model to convert images intopresentational markup based on a scalable coarse-to-fine attention mechanism.Our method is evaluated in the context of image-to-LaTeX generation, and weintroduce a new dataset of real-world rendered mathematical expressions pairedwith LaTeX markup. We show that unlike neural OCR techniques using CTC-basedmodels, attention-based approaches can tackle this non-standard OCR task. Ourapproach outperforms classical mathematical OCR systems by a large margin onin-domain rendered data, and, with pretraining, also performs well onout-of-domain handwritten data. To reduce the inference complexity associatedwith the attention-based approaches, we introduce a new coarse-to-fineattention layer that selects a support region before applying attention.",Image-to-Markup Generation with Coarse-to-Fine Attention
132,DV,DV,,,,"We present a deep recurrent neural network model with soft visual attentionthat learns to generate LaTeX markup of real-world math formulas given theirimages. Applying neural sequence generation techniques that have been verysuccessful in the fields of machine translation and image/handwriting/speechcaptioning, recognition, transcription and synthesis, we construct animage-to-markup model that learns to produce syntactically and semanticallycorrect LaTeX markup code of over 150 words long and achieves a BLEU score of89%; the best reported so far for the Im2Latex problem. We also visuallydemonstrate that the model learns to scan the image left-right / up-down muchas a human would read it.",Teaching Machines to Code: Neural Markup Generation with Visual  Attention
133,,,,,,"A promising paradigm for achieving highly efficient deep neural networks isthe idea of evolutionary deep intelligence, which mimics biological evolutionprocesses to progressively synthesize more efficient networks. A crucial designfactor in evolutionary deep intelligence is the genetic encoding scheme used tosimulate heredity and determine the architectures of offspring networks. Inthis study, we take a deeper look at the notion of synaptic cluster-drivenevolution of deep neural networks which guides the evolution process towardsthe formation of a highly sparse set of synaptic clusters in offspringnetworks. Utilizing a synaptic cluster-driven genetic encoding, theprobabilistic encoding of synaptic traits considers not only individualsynaptic properties but also inter-synaptic relationships within a deep neuralnetwork. This process results in highly sparse offspring networks which areparticularly tailored for parallel computational devices such as GPUs and deepneural network accelerator chips. Comprehensive experimental results using fourwell-known deep neural network architectures (LeNet-5, AlexNet, ResNet-56, andDetectNet) on two different tasks (object categorization and object detection)demonstrate the efficiency of the proposed method. Cluster-driven geneticencoding scheme synthesizes networks that can achieve state-of-the-artperformance with significantly smaller number of synapses than that of theoriginal ancestor network. ($\sim$125-fold decrease in synapses for MNIST).Furthermore, the improved cluster efficiency in the generated offspringnetworks ($\sim$9.71-fold decrease in clusters for MNIST and a $\sim$8.16-folddecrease in clusters for KITTI) is particularly useful for acceleratedperformance on parallel computing hardware architectures such as those in GPUsand deep neural network accelerator chips.",Evolution in Groups: A deeper look at synaptic cluster driven evolution  of deep neural networks
134,,,,,,"A relatively recent advance in cognitive neuroscience has been multi-voxelpattern analysis (MVPA), which enables researchers to decode brain statesand/or the type of information represented in the brain during a cognitiveoperation. MVPA methods utilize machine learning algorithms to distinguishamong types of information or cognitive states represented in the brain, basedon distributed patterns of neural activity. In the current investigation, wepropose a new approach for representation of neural data for pattern analysis,namely a Mesh Learning Model. In this approach, at each time instant, a starmesh is formed around each voxel, such that the voxel corresponding to thecenter node is surrounded by its p-nearest neighbors. The arc weights of eachmesh are estimated from the voxel intensity values by least squares method. Theestimated arc weights of all the meshes, called Mesh Arc Descriptors (MADs),are then used to train a classifier, such as Neural Networks, k-NearestNeighbor, Na\""ive Bayes and Support Vector Machines. The proposed Mesh Modelwas tested on neuroimaging data acquired via functional magnetic resonanceimaging (fMRI) during a recognition memory experiment using categorized wordlists, employing a previously established experimental paradigm (\""Oztekin &Badre, 2011). Results suggest that the proposed Mesh Learning approach canprovide an effective algorithm for pattern analysis of brain activity duringcognitive processing.",Mesh Learning for Classifying Cognitive Processes
135,,,,,,"In this work, we perform an exploratory study on synthesizing deep neuralnetworks using biological synaptic strength distributions, and the potentialinfluence of different distributions on modelling performance particularly forthe scenario associated with small data sets. Surprisingly, a CNN withconvolutional layer synaptic strengths drawn from biologically-inspireddistributions such as log-normal or correlated center-surround distributionsperformed relatively well suggesting a possibility for designing deep neuralnetwork architectures that do not require many data samples to learn, and cansidestep current training procedures while maintaining or boosting modellingperformance.",Synthesizing Deep Neural Network Architectures using Biological Synaptic  Strength Distributions
136,,,,,,"Addressing the issue of SVMs parameters optimization, this study proposes anefficient memetic algorithm based on Particle Swarm Optimization algorithm(PSO) and Pattern Search (PS). In the proposed memetic algorithm, PSO isresponsible for exploration of the search space and the detection of thepotential regions with optimum solutions, while pattern search (PS) is used toproduce an effective exploitation on the potential regions obtained by PSO.Moreover, a novel probabilistic selection strategy is proposed to select theappropriate individuals among the current population to undergo localrefinement, keeping a well balance between exploration and exploitation.Experimental results confirm that the local refinement with PS and our proposedselection strategy are effective, and finally demonstrate effectiveness androbustness of the proposed PSO-PS based MA for SVMs parameters optimization.",A PSO and Pattern Search based Memetic Algorithm for SVMs Parameters  Optimization
137,,,,,,"Unsupervised learning of probabilistic models is a central yet challengingproblem in machine learning. Specifically, designing models with tractablelearning, sampling, inference and evaluation is crucial in solving this task.We extend the space of such models using real-valued non-volume preserving(real NVP) transformations, a set of powerful invertible and learnabletransformations, resulting in an unsupervised learning algorithm with exactlog-likelihood computation, exact sampling, exact inference of latentvariables, and an interpretable latent space. We demonstrate its ability tomodel natural images on four datasets through sampling, log-likelihoodevaluation and latent variable manipulations.",Density estimation using Real NVP
138,,,,,,"We explore the use of Evolution Strategies (ES), a class of black boxoptimization algorithms, as an alternative to popular MDP-based RL techniquessuch as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari showthat ES is a viable solution strategy that scales extremely well with thenumber of CPUs available: By using a novel communication strategy based oncommon random numbers, our ES implementation only needs to communicate scalars,making it possible to scale to over a thousand parallel workers. This allows usto solve 3D humanoid walking in 10 minutes and obtain competitive results onmost Atari games after one hour of training. In addition, we highlight severaladvantages of ES as a black box optimization technique: it is invariant toaction frequency and delayed rewards, tolerant of extremely long horizons, anddoes not need temporal discounting or value function approximation.",Evolution Strategies as a Scalable Alternative to Reinforcement Learning
139,Physics,Physics,,,,"This paper introduces the QMDP-net, a neural network architecture forplanning under partial observability. The QMDP-net combines the strengths ofmodel-free learning and model-based planning. It is a recurrent policy network,but it represents a policy for a parameterized set of tasks by connecting amodel with a planning algorithm that solves the model, thus embedding thesolution structure of planning in a network learning architecture. The QMDP-netis fully differentiable and allows for end-to-end training. We train a QMDP-neton different tasks so that it can generalize to new ones in the parameterizedtask set and ""transfer"" to other similar tasks beyond the set. In preliminaryexperiments, QMDP-net showed strong performance on several robotic tasks insimulation. Interestingly, while QMDP-net encodes the QMDP algorithm, itsometimes outperforms the QMDP algorithm in the experiments, as a result ofend-to-end learning.",QMDP-Net: Deep Learning for Planning under Partial Observability
140,,,,,,"Combining deep model-free reinforcement learning with on-line planning is apromising approach to building on the successes of deep RL. On-line planningwith look-ahead trees has proven successful in environments where transitionmodels are known a priori. However, in complex environments where transitionmodels need to be learned from data, the deficiencies of learned models havelimited their utility for planning. To address these challenges, we proposeTreeQN, a differentiable, recursive, tree-structured model that serves as adrop-in replacement for any value function network in deep RL with discreteactions. TreeQN dynamically constructs a tree by recursively applying atransition model in a learned abstract state space and then aggregatingpredicted rewards and state-values using a tree backup to estimate Q-values. Wealso propose ATreeC, an actor-critic variant that augments TreeQN with asoftmax layer to form a stochastic policy network. Both approaches are trainedend-to-end, such that the learned model is optimised for its actual use in thetree. We show that TreeQN and ATreeC outperform n-step DQN and A2C on abox-pushing task, as well as n-step DQN and value prediction networks (Oh etal. 2017) on multiple Atari games. Furthermore, we present ablation studiesthat demonstrate the effect of different auxiliary losses on learningtransition models.",TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep  Reinforcement Learning
141,Chemistry,Chemistry,,,,"A major drawback of backpropagation through time (BPTT) is the difficulty oflearning long-term dependencies, coming from having to propagate creditinformation backwards through every single step of the forward computation.This makes BPTT both computationally impractical and biologically implausible.For this reason, full backpropagation through time is rarely used on longsequences, and truncated backpropagation through time is used as a heuristic.However, this usually leads to biased estimates of the gradient in which longerterm dependencies are ignored. Addressing this issue, we propose an alternativealgorithm, Sparse Attentive Backtracking, which might also be related toprinciples used by brains to learn long-term dependencies. Sparse AttentiveBacktracking learns an attention mechanism over the hidden states of the pastand selectively backpropagates through paths with high attention weights. Thisallows the model to learn long term dependencies while only backtracking for asmall number of time steps, not just from the recent past but also fromattended relevant past states.",Sparse Attentive Backtracking: Long-Range Credit Assignment in Recurrent  Networks
142,Chemistry,Chemistry,,,,"We study the performance of stochastically trained deep neural networks(DNNs) whose synaptic weights are implemented using emerging memristive devicesthat exhibit limited dynamic range, resolution, and variability in theirprogramming characteristics. We show that a key device parameter to optimizethe learning efficiency of DNNs is the variability in its programmingcharacteristics. DNNs with such memristive synapses, even with dynamic range aslow as $15$ and only $32$ discrete levels, when trained based on stochasticupdates suffer less than $3\%$ loss in accuracy compared to floating pointsoftware baseline. We also study the performance of stochastic memristive DNNswhen used as inference engines with noise corrupted data and find that if thedevice variability can be minimized, the relative degradation in performancefor the Stochastic DNN is better than that of the software baseline. Hence, ourstudy presents a new optimization corner for memristive devices for buildinglarge noise-immune deep learning systems.",Stochastic Deep Learning in Memristive Networks
143,,,,,,"Multi-step-ahead time series prediction is one of the most challengingresearch topics in the field of time series modeling and prediction, and iscontinually under research. Recently, the multiple-input severalmultiple-outputs (MISMO) modeling strategy has been proposed as a promisingalternative for multi-step-ahead time series prediction, exhibiting advantagescompared with the two currently dominating strategies, the iterated and thedirect strategies. Built on the established MISMO strategy, this study proposesa particle swarm optimization (PSO)-based MISMO modeling strategy, which iscapable of determining the number of sub-models in a self-adaptive mode, withvarying prediction horizons. Rather than deriving crisp divides with equal-sizes prediction horizons from the established MISMO, the proposed PSO-MISMOstrategy, implemented with neural networks, employs a heuristic to createflexible divides with varying sizes of prediction horizons and to generatecorresponding sub-models, providing considerable flexibility in modelconstruction, which has been validated with simulated and real datasets.",PSO-MISMO Modeling Strategy for Multi-Step-Ahead Time Series Prediction
144,,,,,,"We investigate the capacity, convexity and characterization of a generalfamily of norm-constrained feed-forward networks.",Norm-Based Capacity Control in Neural Networks
145,,,,,,"The method presented extends a given regression neural network to make itsperformance improve. The modification affects the learning procedure only,hence the extension may be easily omitted during evaluation without any changein prediction. It means that the modified model may be evaluated as quickly asthe original one but tends to perform better.  This improvement is possible because the modification gives better expressivepower, provides better behaved gradients and works as a regularization. Theknowledge gained by the temporarily extended neural network is contained in theparameters shared with the original neural network.  The only cost is an increase in learning time.",Improving the Performance of Neural Networks in Regression Tasks Using  Drawering
146,,,,,,"A key element in transfer learning is representation learning; ifrepresentations can be developed that expose the relevant factors underlyingthe data, then new tasks and domains can be learned readily based on mappingsof these salient factors. We propose that an important aim for theserepresentations are to be unbiased. Different forms of representation learningcan be derived from alternative definitions of unwanted bias, e.g., bias toparticular tasks, domains, or irrelevant underlying data dimensions. One veryuseful approach to estimating the amount of bias in a representation comes frommaximum mean discrepancy (MMD) [5], a measure of distance between probabilitydistributions. We are not the first to suggest that MMD can be a usefulcriterion in developing representations that apply across multiple domains ortasks [1]. However, in this paper we describe a number of novel applications ofthis criterion that we have devised, all based on the idea of developingunbiased representations. These formulations include: a standard domainadaptation framework; a method of learning invariant representations; anapproach based on noise-insensitive autoencoders; and a novel form ofgenerative model.",Learning unbiased features
147,DV,DV,,,,"This paper proposes GProp, a deep reinforcement learning algorithm forcontinuous policies with compatible function approximation. The algorithm isbased on two innovations. Firstly, we present a temporal-difference basedmethod for learning the gradient of the value-function. Secondly, we presentthe deviator-actor-critic (DAC) model, which comprises three neural networksthat estimate the value function, its gradient, and determine the actor'spolicy respectively. We evaluate GProp on two challenging tasks: a contextualbandit problem constructed from nonparametric regression datasets that isdesigned to probe the ability of reinforcement learning algorithms toaccurately estimate gradients; and the octopus arm, a challenging reinforcementlearning benchmark. GProp is competitive with fully supervised methods on thebandit task and achieves the best performance to date on the octopus arm.",Compatible Value Gradients for Reinforcement Learning of Continuous Deep  Policies
148,,,,,,"We propose a particularly structured Boltzmann machine, which we refer to asa dynamic Boltzmann machine (DyBM), as a stochastic model of amulti-dimensional time-series. The DyBM can have infinitely many layers ofunits but allows exact and efficient inference and learning when its parametershave a proposed structure. This proposed structure is motivated by postulatesand observations, from biological neural networks, that the synaptic weight isstrengthened or weakened, depending on the timing of spikes (i.e., spike-timingdependent plasticity or STDP). We show that the learning rule of updating theparameters of the DyBM in the direction of maximizing the likelihood of giventime-series can be interpreted as STDP with long term potentiation and longterm depression. The learning rule has a guarantee of convergence and can beperformed in a distributed matter (i.e., local in space) with limited memory(i.e., local in time).",Learning dynamic Boltzmann machines with spike-timing dependent  plasticity
149,Data,Data,,,,"Graph-structured data appears frequently in domains including chemistry,natural language semantics, social networks, and knowledge bases. In this work,we study feature learning techniques for graph-structured inputs. Our startingpoint is previous work on Graph Neural Networks (Scarselli et al., 2009), whichwe modify to use gated recurrent units and modern optimization techniques andthen extend to output sequences. The result is a flexible and broadly usefulclass of neural network models that has favorable inductive biases relative topurely sequence-based models (e.g., LSTMs) when the problem isgraph-structured. We demonstrate the capabilities on some simple AI (bAbI) andgraph algorithm learning tasks. We then show it achieves state-of-the-artperformance on a problem from program verification, in which subgraphs need tobe matched to abstract data structures.",Gated Graph Sequence Neural Networks
150,,,,,,"Being able to reason in an environment with a large number of discreteactions is essential to bringing reinforcement learning to a larger class ofproblems. Recommender systems, industrial plants and language models are onlysome of the many real-world tasks involving large numbers of discrete actionsfor which current methods are difficult or even often impossible to apply. Anability to generalize over the set of actions as well as sub-linear complexityrelative to the size of the set are both necessary to handle such tasks.Current approaches are not able to provide both of these, which motivates thework in this paper. Our proposed approach leverages prior information about theactions to embed them in a continuous space upon which it can generalize.Additionally, approximate nearest-neighbor methods allow for logarithmic-timelookup complexity relative to the number of actions, which is necessary fortime-wise tractable training. This combined approach allows reinforcementlearning methods to be applied to large-scale learning problems previouslyintractable with current methods. We demonstrate our algorithm's abilities on aseries of tasks having up to one million actions.",Deep Reinforcement Learning in Large Discrete Action Spaces
151,DV,DV,,,,"We introduce the value iteration network (VIN): a fully differentiable neuralnetwork with a `planning module' embedded within. VINs can learn to plan, andare suitable for predicting outcomes that involve planning-based reasoning,such as policies for reinforcement learning. Key to our approach is a noveldifferentiable approximation of the value-iteration algorithm, which can berepresented as a convolutional neural network, and trained end-to-end usingstandard backpropagation. We evaluate VIN based policies on discrete andcontinuous path-planning domains, and on a natural-language based search task.We show that by learning an explicit planning computation, VIN policiesgeneralize better to new, unseen domains.",Value Iteration Networks
152,,,,,,"Although RNNs have been shown to be powerful tools for processing sequentialdata, finding architectures or optimization strategies that allow them to modelvery long term dependencies is still an active area of research. In this work,we carefully analyze two synthetic datasets originally outlined in (Hochreiterand Schmidhuber, 1997) which are used to evaluate the ability of RNNs to storeinformation over many time steps. We explicitly construct RNN solutions tothese problems, and using these constructions, illuminate both the problemsthemselves and the way in which RNNs store different types of information intheir hidden states. These constructions furthermore explain the success ofrecent methods that specify unitary initializations or constraints on thetransition matrices.",Recurrent Orthogonal Networks and Long-Memory Tasks
153,,,,,,"Most learning algorithms are not invariant to the scale of the function thatis being approximated. We propose to adaptively normalize the targets used inlearning. This is useful in value-based reinforcement learning, where themagnitude of appropriate value approximations can change over time when weupdate the policy of behavior. Our main motivation is prior work on learning toplay Atari games, where the rewards were all clipped to a predetermined range.This clipping facilitates learning across many different games with a singlelearning algorithm, but a clipped reward function can result in qualitativelydifferent behavior. Using the adaptive normalization we can remove thisdomain-specific heuristic without diminishing overall performance.",Learning values across many orders of magnitude
154,Chemistry,Chemistry,,,,"Each human genome is a 3 billion base pair set of encoding instructions.Decoding the genome using deep learning fundamentally differs from most tasks,as we do not know the full structure of the data and therefore cannot designarchitectures to suit it. As such, architectures that fit the structure ofgenomics should be learned not prescribed. Here, we develop a novel searchalgorithm, applicable across domains, that discovers an optimal architecturewhich simultaneously learns general genomic patterns and identifies the mostimportant sequence motifs in predicting functional genomic outcomes. Thearchitectures we find using this algorithm succeed at using only RNA expressiondata to predict gene regulatory structure, learn human-interpretablevisualizations of key sequence motifs, and surpass state-of-the-art results onbenchmark genomics challenges.",Genetic Architect: Discovering Genomic Structure with Learned Neural  Architectures
155,Nuclear,Nuclear,,,,"Learning robust value functions given raw observations and rewards is nowpossible with model-free and model-based deep reinforcement learningalgorithms. There is a third alternative, called Successor Representations(SR), which decomposes the value function into two components -- a rewardpredictor and a successor map. The successor map represents the expected futurestate occupancy from any given state and the reward predictor maps states toscalar rewards. The value function of a state can be computed as the innerproduct between the successor map and the reward weights. In this paper, wepresent DSR, which generalizes SR within an end-to-end deep reinforcementlearning framework. DSR has several appealing properties including: increasedsensitivity to distal reward changes due to factorization of reward and worlddynamics, and the ability to extract bottleneck states (subgoals) givensuccessor maps trained under a random policy. We show the efficacy of ourapproach on two diverse environments given raw pixel observations -- simplegrid-world domains (MazeBase) and the Doom game engine.",Deep Successor Reinforcement Learning
156,Data,Data,,,,"Deep reinforcement learning (deep RL) has been successful in learningsophisticated behaviors automatically; however, the learning process requires ahuge number of trials. In contrast, animals can learn new tasks in just a fewtrials, benefiting from their prior knowledge about the world. This paper seeksto bridge this gap. Rather than designing a ""fast"" reinforcement learningalgorithm, we propose to represent it as a recurrent neural network (RNN) andlearn it from data. In our proposed method, RL$^2$, the algorithm is encoded inthe weights of the R, which are learned slowly through a general-purpose(""slow"") RL algorithm. The RNN receives all information a typical RL algorithmwould receive, including observations, actions, rewards, and termination flags;and it retains its state across episodes in a given Markov Decision Process(MDP). The activations of the RNN store the state of the ""fast"" RL algorithm onthe current (previously unseen) MDP. We evaluate RL$^2$ experimentally on bothsmall-scale and large-scale problems. On the small-scale side, we train it tosolve randomly generated multi-arm bandit problems and finite MDPs. AfterRL$^2$ is trained, its performance on new MDPs is close to human-designedalgorithms with optimality guarantees. On the large-scale side, we test RL$^2$on a vision-based navigation task and show that it scales up tohigh-dimensional problems.",RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning
157,DV,DV,,,,"Two potential bottlenecks on the expressiveness of recurrent neural networks(RNNs) are their ability to store information about the task in theirparameters, and to store information about the input history in their units. Weshow experimentally that all common RNN architectures achieve nearly the sameper-task and per-unit capacity bounds with careful training, for a variety oftasks and stacking depths. They can store an amount of task information whichis linear in the number of parameters, and is approximately 5 bits perparameter. They can additionally store approximately one real number from theirinput history per hidden unit. We further find that for several tasks it is theper-task parameter capacity bound that determines performance. These resultssuggest that many previous results comparing RNN architectures are drivenprimarily by differences in training effectiveness, rather than differences incapacity. Supporting this observation, we compare training difficulty forseveral architectures, and show that vanilla RNNs are far more difficult totrain, yet have slightly higher capacity. Finally, we propose two novel RNNarchitectures, one of which is easier to train than the LSTM or GRU for deeplystacked architectures.",Capacity and Trainability in Recurrent Neural Networks
158,,,,,,"In application domains such as healthcare, we want accurate predictive modelsthat are also causally interpretable. In pursuit of such models, we propose acausal regularizer to steer predictive models towards causally-interpretablesolutions and theoretically study its properties. In a large-scale analysis ofElectronic Health Records (EHR), our causally-regularized model outperforms itsL1-regularized counterpart in causal accuracy and is competitive in predictiveperformance. We perform non-linear causality analysis by causally regularizinga special neural network architecture. We also show that the proposed causalregularizer can be used together with neural representation learning algorithmsto yield up to 20% improvement over multilayer perceptron in detectingmultivariate causation, a situation common in healthcare, where many causalfactors should occur simultaneously to have an effect on the target variable.",Causal Regularization
159,,,,,,"Deep neural networks are representation learning techniques. During training,a deep net is capable of generating a descriptive language of unprecedentedsize and detail in machine learning. Extracting the descriptive language codedwithin a trained CNN model (in the case of image data), and reusing it forother purposes is a field of interest, as it provides access to the visualdescriptors previously learnt by the CNN after processing millions of images,without requiring an expensive training phase. Contributions to this field(commonly known as feature representation transfer or transfer learning) havebeen purely empirical so far, extracting all CNN features from a single layerclose to the output and testing their performance by feeding them to aclassifier. This approach has provided consistent results, although itsrelevance is limited to classification tasks. In a completely differentapproach, in this paper we statistically measure the discriminative power ofevery single feature found within a deep C, when used for characterizingevery class of 11 datasets. We seek to provide new insights into the behaviorof CNN features, particularly the ones from convolutional layers, as this canbe relevant for their application to knowledge representation and reasoning.Our results confirm that low and middle level features may behave differentlyto high level features, but only under certain conditions. We find that all CNNfeatures can be used for knowledge representation purposes both by theirpresence or by their absence, doubling the information a single CNN feature mayprovide. We also study how much noise these features may include, and propose athresholding approach to discard most of it. All these insights have a directapplication to the generation of CNN embedding spaces.",On the Behavior of Convolutional Nets for Feature Extraction
160,,,,,,"Adversarial learning of probabilistic models has recently emerged as apromising alternative to maximum likelihood. Implicit models such as generativeadversarial networks (GAN) often generate better samples compared to explicitmodels trained by maximum likelihood. Yet, GANs sidestep the characterizationof an explicit density which makes quantitative evaluations challenging. Tobridge this gap, we propose Flow-GANs, a generative adversarial network forwhich we can perform exact likelihood evaluation, thus supporting bothadversarial and maximum likelihood training. When trained adversarially,Flow-GANs generate high-quality samples but attain extremely poorlog-likelihood scores, inferior even to a mixture model memorizing the trainingdata; the opposite is true when trained by maximum likelihood. Results on MNISTand CIFAR-10 demonstrate that hybrid training can attain high held-outlikelihoods while retaining visual fidelity in the generated samples.",Flow-GAN: Combining Maximum Likelihood and Adversarial Learning in  Generative Models
161,,,,,,"When used as a surrogate objective for maximum likelihood estimation inlatent variable models, the evidence lower bound (ELBO) producesstate-of-the-art results. Inspired by this, we consider the extension of theELBO to a family of lower bounds defined by a particle filter's estimator ofthe marginal likelihood, the filtering variational objectives (FIVOs). FIVOstake the same arguments as the ELBO, but can exploit a model's sequentialstructure to form tighter bounds. We present results that relate the tightnessof FIVO's bound to the variance of the particle filter's estimator byconsidering the generic case of bounds defined as log-transformed likelihoodestimators. Experimentally, we show that training with FIVO results insubstantial improvements over training the same model architecture with theELBO on sequential data.",Filtering Variational Objectives
162,,,,,,"Recent progress in variational inference has paid much attention to theflexibility of variational posteriors. One promising direction is to useimplicit distributions, i.e., distributions without tractable densities as thevariational posterior. However, existing methods on implicit posteriors stillface challenges of noisy estimation and computational infeasibility whenapplied to models with high-dimensional latent variables. In this paper, wepresent a new approach named Kernel Implicit Variational Inference thataddresses these challenges. As far as we know, for the first time implicitvariational inference is successfully applied to Bayesian neural networks,which shows promising results on both regression and classification tasks.",Kernel Implicit Variational Inference
163,Chemistry,,,Chemistry,,"Partially observable environments present an important open challenge in thedomain of sequential control learning with delayed rewards. Despite numerousattempts during the two last decades, the majority of reinforcement learningalgorithms and associated approximate models, applied to this context, stillassume Markovian state transitions. In this paper, we explore the use of arecently proposed attention-based model, the Gated End-to-End Memory Network,for sequential control. We call the resulting model the Gated End-to-End MemoryPolicy Network. More precisely, we use a model-free value-based algorithm tolearn policies for partially observed domains using this memory-enhanced neuralnetwork. This model is end-to-end learnable and it features unbounded memory.Indeed, because of its attention mechanism and associated non-parametricmemory, the proposed model allows us to define an attention mechanism over theobservation stream unlike recurrent models. We show encouraging results thatillustrate the capability of our attention-based model in the context of thecontinuous-state non-stationary control problem of stock trading. We alsopresent an OpenAI Gym environment for simulated stock exchange and explain itsrelevance as a benchmark for the field of non-Markovian decision processlearning.",Non-Markovian Control with Gated End-to-End Memory Policy Networks
164,,,,,,"Regression or classification? This is perhaps the most basic question facedwhen tackling a new supervised learning problem. We present an EvolutionaryDeep Learning (EDL) algorithm that automatically solves this by identifying thequestion type with high accuracy, along with a proposed deep architecture.Typically, a significant amount of human insight and preparation is requiredprior to executing machine learning algorithms. For example, when creating deepneural networks, the number of parameters must be selected in advance andfurthermore, a lot of these choices are made based upon pre-existing knowledgeof the data such as the use of a categorical cross entropy loss function.Humans are able to study a dataset and decide whether it represents aclassification or a regression problem, and consequently make decisions whichwill be applied to the execution of the neural network. We propose theAutomated Problem Identification (API) algorithm, which uses an evolutionaryalgorithm interface to TensorFlow to manipulate a deep neural network to decideif a dataset represents a classification or a regression problem. We test APIon 16 different classification, regression and sentiment analysis datasets withup to 10,000 features and up to 17,000 unique target values. API achieves anaverage accuracy of $96.3\%$ in identifying the problem type without hardcodingany insights about the general characteristics of regression or classificationproblems. For example, API successfully identifies classification problems evenwith 1000 target values. Furthermore, the algorithm recommends which lossfunction to use and also recommends a neural network architecture. Our work istherefore a step towards fully automated machine learning.",Automated Problem Identification: Regression vs Classification via  Evolutionary Deep Networks
165,Data,Data,,,,"Deep neural networks excel in regimes with large amounts of data, but tend tostruggle when data is scarce or when they need to adapt quickly to changes inthe task. In response, recent work in meta-learning proposes training ameta-learner on a distribution of similar tasks, in the hopes of generalizationto novel but related tasks by learning a high-level strategy that captures theessence of the problem it is asked to solve. However, many recent meta-learningapproaches are extensively hand-designed, either using architecturesspecialized to a particular application, or hard-coding algorithmic componentsthat constrain how the meta-learner solves the task. We propose a class ofsimple and generic meta-learner architectures that use a novel combination oftemporal convolutions and soft attention; the former to aggregate informationfrom past experience and the latter to pinpoint specific pieces of information.In the most extensive set of meta-learning experiments to date, we evaluate theresulting Simple Neural AttentIve Learner (or SNAIL) on severalheavily-benchmarked tasks. On all tasks, in both supervised and reinforcementlearning, SNAIL attains state-of-the-art performance by significant margins.",A Simple Neural Attentive Meta-Learner
166,Chemistry,,,Chemistry,,"Neural networks are generally built by interleaving (adaptable) linear layerswith (fixed) nonlinear activation functions. To increase their flexibility,several authors have proposed methods for adapting the activation functionsthemselves, endowing them with varying degrees of flexibility. None of theseapproaches, however, have gained wide acceptance in practice, and research inthis topic remains open. In this paper, we introduce a novel family of flexibleactivation functions that are based on an inexpensive kernel expansion at everyneuron. Leveraging over several properties of kernel-based models, we proposemultiple variations for designing and initializing these kernel activationfunctions (KAFs), including a multidimensional scheme allowing to nonlinearlycombine information from different paths in the network. The resulting KAFs canapproximate any mapping defined over a subset of the real line, either convexor nonconvex. Furthermore, they are smooth over their entire domain, linear intheir parameters, and they can be regularized using any known scheme, includingthe use of $\ell_1$ penalties to enforce sparseness. To the best of ourknowledge, no other known model satisfies all these properties simultaneously.In addition, we provide a relatively complete overview on alternativetechniques for adapting the activation functions, which is currently lacking inthe literature. A large set of experiments validates our proposal.",Kafnets: kernel-based non-parametric activation functions for neural  networks
167,Data,Data,,,,"Conventional wisdom holds that model-based planning is a powerful approach tosequential decision-making. It is often very challenging in practice, however,because while a model can be used to evaluate a plan, it does not prescribe howto construct a plan. Here we introduce the ""Imagination-based Planner"", thefirst model-based, sequential decision-making agent that can learn toconstruct, evaluate, and execute plans. Before any action, it can perform avariable number of imagination steps, which involve proposing an imaginedaction and evaluating it with its model-based imagination. All imagined actionsand outcomes are aggregated, iteratively, into a ""plan context"" whichconditions future real and imagined actions. The agent can even decide how toimagine: testing out alternative imagined actions, chaining sequences ofactions together, or building a more complex ""imagination tree"" by navigatingflexibly among the previously imagined states using a learned policy. And ouragent can learn to plan economically, jointly optimizing for external rewardsand computational costs associated with using its imagination. We show that ourarchitecture can learn to solve a challenging continuous control problem, andalso learn elaborate planning strategies in a discrete maze-solving task. Ourwork opens a new direction toward learning the components of a model-basedplanning system and how to use them.",Learning model-based planning from scratch
168,DV,DV,,,,"We propose a recurrent extension of the Ladder networks whose structure ismotivated by the inference required in hierarchical latent variable models. Wedemonstrate that the recurrent Ladder is able to handle a wide variety ofcomplex learning tasks that benefit from iterative inference and temporalmodeling. The architecture shows close-to-optimal results on temporal modelingof video data, competitive results on music modeling, and improved perceptualgrouping based on higher order abstractions, such as stochastic textures andmotion cues. We present results for fully supervised, semi-supervised, andunsupervised tasks. The results suggest that the proposed architecture andprinciples are powerful tools for learning a hierarchy of abstractions,learning iterative inference and handling temporal information.",Recurrent Ladder Networks
169,Data,,,Data,,"With a direct analysis of neural networks, this paper presents amathematically tight generalization theory to partially address an open problemregarding the generalization of deep learning. Unlike previous bound-basedtheory, our main theory is quantitatively as tight as possible for everydataset individually, while producing qualitative insights competitively. Ourresults give insight into why and how deep learning can generalize well,despite its large capacity, complexity, possible algorithmic instability,nonrobustness, and sharp minima, answering to an open question in theliterature. We also discuss limitations of our results and propose additionalopen problems.",Generalization in Deep Learning
170,,,,,,"It is commonly agreed that the use of relevant invariances as a goodstatistical bias is important in machine-learning. However, most approachesthat explicitly incorporate invariances into a model architecture only make useof very simple transformations, such as translations and rotations. Hence,there is a need for methods to model and extract richer transformations thatcapture much higher-level invariances. To that end, we introduce a toolallowing to parametrize the set of filters of a trained convolutional neuralnetwork with the latent space of a generative adversarial network. We then showthat the method can capture highly non-linear invariances of the data byvisualizing their effect in the data space.",Parametrizing filters of a CNN with a GAN
171,Chemistry,,,Chemistry,,"Long Short-Term Memory (LSTM) is a popular approach to boosting the abilityof Recurrent Neural Networks to store longer term temporal information. Thecapacity of an LSTM network can be increased by widening and adding layers.However, usually the former introduces additional parameters, while the latterincreases the runtime. As an alternative we propose the Tensorized LSTM inwhich the hidden states are represented by tensors and updated via across-layer convolution. By increasing the tensor size, the network can bewidened efficiently without additional parameters since the parameters areshared across different locations in the tensor; by delaying the output, thenetwork can be deepened implicitly with little additional runtime since deepcomputations for each timestep are merged into temporal computations of thesequence. Experiments conducted on five challenging sequence learning tasksshow the potential of the proposed model.","Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence  Learning"
172,,,,,,"We describe a novel spiking neural network (SNN) for automated, real-timehandwritten digit classification and its implementation on a GP-GPU platform.Information processing within the network, from feature extraction toclassification is implemented by mimicking the basic aspects of neuronal spikeinitiation and propagation in the brain. The feature extraction layer of theSNN uses fixed synaptic weight maps to extract the key features of the imageand the classifier layer uses the recently developed NormAD approximategradient descent based supervised learning algorithm for spiking neuralnetworks to adjust the synaptic weights. On the standard MNIST database imagesof handwritten digits, our network achieves an accuracy of 99.80% on thetraining set and 98.06% on the test set, with nearly 7x fewer parameterscompared to the state-of-the-art spiking networks. We further use this networkin a GPU based user-interface system demonstrating real-time SNN simulation toinfer digits written by different users. On a test set of 500 such images, thisreal-time platform achieves an accuracy exceeding 97% while making a predictionwithin an SNN emulation time of less than 100ms.",Learning and Real-time Classification of Hand-written Digits With  Spiking Neural Networks
173,Data,,,Data,,"Catastrophic forgetting occurs when a neural network loses the informationlearned in a previous task after training on subsequent tasks. This problemremains a hurdle for artificial intelligence systems with sequential learningcapabilities. In this paper, we propose a task-based hard attention mechanismthat preserves previous tasks' information without affecting the current task'slearning. A hard attention mask is learned concurrently to every task, throughstochastic gradient descent, and previous masks are exploited to condition suchlearning. We show that the proposed mechanism is effective for reducingcatastrophic forgetting, cutting current rates by 45 to 80%. We also show thatit is robust to different hyperparameter choices, and that it offers a numberof monitoring capabilities. The approach features the possibility to controlboth the stability and compactness of the learned knowledge, which we believemakes it also attractive for online learning or network compressionapplications.",Overcoming catastrophic forgetting with hard attention to the task
174,,,,,,"Faced with distribution shift between training and test set, we wish todetect and quantify the shift, and to correct our classifiers without test setlabels. Motivated by medical diagnosis, where diseases (targets), causesymptoms (observations), we focus on label shift, where the label marginal$p(y)$ changes but the conditional $p(x|y)$ does not. We propose Black BoxShift Estimation (BBSE) to estimate the test distribution $p(y)$. BBSE exploitsarbitrary black box predictors to reduce dimensionality prior to shiftcorrection. While better predictors give tighter estimates, BBSE works evenwhen predictors are biased, inaccurate, or uncalibrated, so long as theirconfusion matrices are invertible. We prove BBSE's consistency, bound itserror, and introduce a statistical test that uses BBSE to detect shift. We alsoleverage BBSE to correct classifiers. Experiments demonstrate accurateestimates and improved prediction, even on high-dimensional datasets of naturalimages.",Detecting and Correcting for Label Shift with Black Box Predictors
175,,,,,,"This paper introduces a novel measure-theoretic learning theory to analyzegeneralization behaviors of practical interest. The proposed learning theoryhas the following abilities: 1) to utilize the qualities of each learnedrepresentation on the path from raw inputs to outputs in representationlearning, 2) to guarantee good generalization errors possibly with arbitrarilyrich hypothesis spaces (e.g., arbitrarily large capacity and Rademachercomplexity) and non-stable/non-robust learning algorithms, and 3) to clearlydistinguish each individual problem instance from each other. Ourgeneralization bounds are relative to a representation of the data, and holdtrue even if the representation is learned. We discuss several consequences ofour results on deep learning, one-shot learning and curriculum learning. Unlikestatistical learning theory, the proposed learning theory analyzes each probleminstance individually via measure theory, rather than a set of probleminstances via statistics. Because of the differences in the assumptions and theobjectives, the proposed learning theory is meant to be complementary toprevious learning theory and is not designed to compete with it.",Generalization in Machine Learning via Analytical Learning Theory
176,,,,,,"In practice it is often found that large over-parameterized neural networksgeneralize better than their smaller counterparts, an observation that appearsto conflict with classical notions of function complexity, which typicallyfavor smaller models. In this work, we investigate this tension betweencomplexity and generalization through an extensive empirical exploration of twonatural metrics of complexity related to sensitivity to input perturbations.Our experiments survey thousands of models with various fully-connectedarchitectures, optimizers, and other hyper-parameters, as well as fourdifferent image classification datasets.  We find that trained neural networks are more robust to input perturbationsin the vicinity of the training data manifold, as measured by the norm of theinput-output Jacobian of the network, and that it correlates well withgeneralization. We further establish that factors associated with poorgeneralization $-$ such as full-batch training or using random labels $-$correspond to lower robustness, while factors associated with goodgeneralization $-$ such as data augmentation and ReLU non-linearities $-$ giverise to more robust functions. Finally, we demonstrate how the input-outputJacobian norm can be predictive of generalization at the level of individualtest points.",Sensitivity and Generalization in Neural Networks: an Empirical Study
177,,,,,,"Despite their ability to memorize large datasets, deep neural networks oftenachieve good generalization performance. However, the differences between thelearned solutions of networks which generalize and those which do not remainunclear. Additionally, the tuning properties of single directions (defined asthe activation of a single unit or some linear combination of units in responseto some input) have been highlighted, but their importance has not beenevaluated. Here, we connect these lines of inquiry to demonstrate that anetwork's reliance on single directions is a good predictor of itsgeneralization performance, across networks trained on datasets with differentfractions of corrupted labels, across ensembles of networks trained on datasetswith unmodified labels, across different hyperparameters, and over the courseof training. While dropout only regularizes this quantity up to a point, batchnormalization implicitly discourages single direction reliance, in part bydecreasing the class selectivity of individual units. Finally, we find thatclass selectivity is a poor predictor of task importance, suggesting not onlythat networks which generalize well minimize their dependence on individualunits by reducing their selectivity, but also that individually selective unitsmay not be necessary for strong network performance.",On the importance of single directions for generalization
178,DV,DV,,,,"Images can be segmented by first using a classifier to predict an affinitygraph that reflects the degree to which image pixels must be grouped togetherand then partitioning the graph to yield a segmentation. Machine learning hasbeen applied to the affinity classifier to produce affinity graphs that aregood in the sense of minimizing edge misclassification rates. However, thiserror measure is only indirectly related to the quality of segmentationsproduced by ultimately partitioning the affinity graph. We present the firstmachine learning algorithm for training a classifier to produce affinity graphsthat are good in the sense of producing segmentations that directly minimizethe Rand index, a well known segmentation performance measure. The Rand indexmeasures segmentation performance by quantifying the classification of theconnectivity of image pixel pairs after segmentation. By using the simple graphpartitioning algorithm of finding the connected components of the thresholdedaffinity graph, we are able to train an affinity classifier to directlyminimize the Rand index of segmentations resulting from the graph partitioning.Our learning algorithm corresponds to the learning of maximin affinitiesbetween image pixel pairs, which are predictive of the pixel-pair connectivity.",Maximin affinity learning of image segmentation
179,DV,DV,,,,"This study is focused on the development of the cortex-like visual objectrecognition system. We propose a general framework, which consists of threehierarchical levels (modules). These modules functionally correspond to the V1,V4 and IT areas. Both bottom-up and top-down connections between thehierarchical levels V4 and IT are employed. The higher the degree of matchingbetween the input and the preferred stimulus, the shorter the response time ofthe neuron. Therefore information about a single stimulus is distributed intime and is transmitted by the waves of spikes. The reciprocal connections andwaves of spikes implement predictive coding: an initial hypothesis is generatedon the basis of information delivered by the first wave of spikes and is testedwith the information carried by the consecutive waves. The development isconsidered as extraction and accumulation of features in V4 and objects in IT.Once stored a feature can be disposed, if rarely activated. This cause updateof feature repository. Consequently, objects in IT are also updated. Thisillustrates the growing process and dynamical change of topological structuresof V4, IT and connections between these areas.","A General Framework for Development of the Cortex-like Visual Object  Recognition System: Waves of Spikes, Predictive Coding and Universal  Dictionary of Features"
180,,,,,,"The competitive MNIST handwritten digit recognition benchmark has a longhistory of broken records since 1998. The most recent substantial improvementby others dates back 7 years (error rate 0.4%) . Recently we were able tosignificantly improve this result, using graphics cards to greatly speed uptraining of simple but deep MLPs, which achieved 0.35%, outperforming all theprevious more complex methods. Here we report another substantial improvement:0.31% obtained using a committee of MLPs.",Handwritten Digit Recognition with a Committee of Deep Neural Nets on  GPUs
181,,,,,,"Artificial Neural Network is among the most popular algorithm for supervisedlearning. However, Neural Networks have a well-known drawback of being a ""BlackBox"" learner that is not comprehensible to the Users. This lack of transparencymakes it unsuitable for many high risk tasks such as medical diagnosis thatrequires a rational justification for making a decision. Rule Extractionmethods attempt to curb this limitation by extracting comprehensible rules froma trained Network. Many such extraction algorithms have been developed over theyears with their respective strengths and weaknesses. They have been broadlycategorized into three types based on their approach to use internal model ofthe Network. Eclectic Methods are hybrid algorithms that combine the otherapproaches to attain more performance. In this paper, we present an Eclecticmethod called HERETIC. Our algorithm uses Inductive Decision Tree learningcombined with information of the neural network structure for extractinglogical rules. Experiments and theoretical analysis show HERETIC to be betterin terms of speed and performance.",Eclectic Extraction of Propositional Rules from Neural Networks
182,Data,,,Data,,"Communicating and sharing intelligence among agents is an important facet ofachieving Artificial General Intelligence. As a first step towards thischallenge, we introduce a novel framework for image generation: Message PassingMulti-Agent Generative Adversarial Networks (MPM GANs). While GANs haverecently been shown to be very effective for image generation and other tasks,these networks have been limited to mostly single generator-discriminatornetworks. We show that we can obtain multi-agent GANs that communicate throughmessage passing to achieve better image generation. The objectives of theindividual agents in this framework are two fold: a co-operation objective anda competing objective. The co-operation objective ensures that the messagesharing mechanism guides the other generator to generate better than itselfwhile the competing objective encourages each generator to generate better thanits counterpart. We analyze and visualize the messages that these GANs shareamong themselves in various scenarios. We quantitatively show that the messagesharing formulation serves as a regularizer for the adversarial training.Qualitatively, we show that the different generators capture different traitsof the underlying data distribution.",Message Passing Multi-Agent GANs
183,,,,,,"Although Generative Adversarial Networks achieve state-of-the-art results ona variety of generative tasks, they are regarded as highly unstable and proneto miss modes. We argue that these bad behaviors of GANs are due to the veryparticular functional shape of the trained discriminators in high dimensionalspaces, which can easily make training stuck or push probability mass in thewrong direction, towards that of higher concentration than that of the datagenerating distribution. We introduce several ways of regularizing theobjective, which can dramatically stabilize the training of GAN models. We alsoshow that our regularizers can help the fair distribution of probability massacross the modes of the data generating distribution, during the early phasesof training and thus providing a unified solution to the missing modes problem.",Mode Regularized Generative Adversarial Networks
184,Nuclear,,,Nuclear,,"The increasing complexity of deep learning architectures is resulting intraining time requiring weeks or even months. This slow training is due in partto vanishing gradients, in which the gradients used by back-propagation areextremely large for weights connecting deep layers (layers near the outputlayer), and extremely small for shallow layers (near the input layer); thisresults in slow learning in the shallow layers. Additionally, it has also beenshown that in highly non-convex problems, such as deep neural networks, thereis a proliferation of high-error low curvature saddle points, which slows downlearning dramatically. In this paper, we attempt to overcome the two aboveproblems by proposing an optimization method for training deep neural networkswhich uses learning rates which are both specific to each layer in the networkand adaptive to the curvature of the function, increasing the learning rate atlow curvature points. This enables us to speed up learning in the shallowlayers of the network and quickly escape high-error low curvature saddlepoints. We test our method on standard image classification datasets such asMNIST, CIFAR10 and ImageNet, and demonstrate that our method increases accuracyas well as reduces the required training time over standard algorithms.",Layer-Specific Adaptive Learning Rates for Deep Networks
185,Data,,,Data,,"Unlike human learning, machine learning often fails to handle changes betweentraining (source) and test (target) input distributions. Such domain shifts,common in practical scenarios, severely damage the performance of conventionalmachine learning methods. Supervised domain adaptation methods have beenproposed for the case when the target data have labels, including some thatperform very well despite being ""frustratingly easy"" to implement. However, inpractice, the target domain is often unlabeled, requiring unsupervisedadaptation. We propose a simple, effective, and efficient method forunsupervised domain adaptation called CORrelation ALignment (CORAL). CORALminimizes domain shift by aligning the second-order statistics of source andtarget distributions, without requiring any target labels. Even though it isextraordinarily simple--it can be implemented in four lines of Matlabcode--CORAL performs remarkably well in extensive evaluations on standardbenchmark datasets.",Return of Frustratingly Easy Domain Adaptation
186,,,,,,"An ever increasing number of computer vision and image/video processingchallenges are being approached using deep convolutional neural networks,obtaining state-of-the-art results in object recognition and detection,semantic segmentation, action recognition, optical flow and superresolution.Hardware acceleration of these algorithms is essential to adopt theseimprovements in embedded and mobile computer vision systems. We present a newarchitecture, design and implementation as well as the first reported siliconmeasurements of such an accelerator, outperforming previous work in terms ofpower-, area- and I/O-efficiency. The manufactured device provides up to 196GOp/s on 3.09 mm^2 of silicon in UMC 65nm technology and can achieve a powerefficiency of 803 GOp/s/W. The massively reduced bandwidth requirements make itthe first architecture scalable to TOp/s performance.",Origami: A 803 GOp/s/W Convolutional Network Accelerator
187,,,,,,This paper introduces an automated skill acquisition framework inreinforcement learning which involves identifying a hierarchical description ofthe given task in terms of abstract states and extended actions betweenabstract states. Identifying such structures present in the task provides waysto simplify and speed up reinforcement learning algorithms. These structuresalso help to generalize such algorithms over multiple tasks without relearningpolicies from scratch. We use ideas from dynamical systems to find metastableregions in the state space and associate them with abstract states. Thespectral clustering algorithm PCCA+ is used to identify suitable abstractionsaligned to the underlying structure. Skills are defined in terms of thesequence of actions that lead to transitions between such abstract states. Theconnectivity information from PCCA+ is used to generate these skills oroptions. These skills are independent of the learning task and can beefficiently reused across a variety of tasks defined over the same model. Thisapproach works well even without the exact model of the environment by usingsample trajectories to construct an approximate estimate. We also present ourapproach to scaling the skill acquisition framework to complex tasks with largestate spaces for which we perform state aggregation using the representationlearned from an action conditional video prediction network and use the skillacquisition framework on the aggregated state space.,Option Discovery in Hierarchical Reinforcement Learning using  Spatio-Temporal Clustering
188,,,,,,"In this work we propose a novel interpretation of residual networks showingthat they can be seen as a collection of many paths of differing length.Moreover, residual networks seem to enable very deep networks by leveragingonly the short paths during training. To support this observation, we rewriteresidual networks as an explicit collection of paths. Unlike traditionalmodels, paths through residual networks vary in length. Further, a lesion studyreveals that these paths show ensemble-like behavior in the sense that they donot strongly depend on each other. Finally, and most surprising, most paths areshorter than one might expect, and only the short paths are needed duringtraining, as longer paths do not contribute any gradient. For example, most ofthe gradient in a residual network with 110 layers comes from paths that areonly 10-34 layers deep. Our results reveal one of the key characteristics thatseem to enable the training of very deep networks: Residual networks avoid thevanishing gradient problem by introducing short paths which can carry gradientthroughout the extent of very deep networks.",Residual Networks Behave Like Ensembles of Relatively Shallow Networks
189,Data,Data,,,,"Deep neural networks (DNNs) have demonstrated state-of-the-art results onmany pattern recognition tasks, especially vision classification problems.Understanding the inner workings of such computational brains is bothfascinating basic science that is interesting in its own right - similar to whywe study the human brain - and will enable researchers to further improve DNNs.One path to understanding how a neural network functions internally is to studywhat each of its neurons has learned to detect. One such method is calledactivation maximization (AM), which synthesizes an input (e.g. an image) thathighly activates a neuron. Here we dramatically improve the qualitative stateof the art of activation maximization by harnessing a powerful, learned prior:a deep generator network (DGN). The algorithm (1) generates qualitativelystate-of-the-art synthetic images that look almost real, (2) reveals thefeatures learned by each neuron in an interpretable way, (3) generalizes wellto new datasets and somewhat well to different network architectures withoutrequiring the prior to be relearned, and (4) can be considered as ahigh-quality generative method (in this case, by generating novel, creative,interesting, recognizable images).",Synthesizing the preferred inputs for neurons in neural networks via  deep generator networks
190,,,,,,"We derive a relationship between network representation in energy-efficientneuromorphic architectures and block Toplitz convolutional matrices. Inspiredby this connection, we develop deep convolutional networks using a family ofstructured convolutional matrices and achieve state-of-the-art trade-offbetween energy efficiency and classification accuracy for well-known imagerecognition tasks. We also put forward a novel method to train binaryconvolutional networks by utilising an existing connection betweennoisy-rectified linear units and binary activations.",Structured Convolution Matrices for Energy-efficient Deep learning
191,,,,,,"Deep neural networks are able to learn powerful representations from largequantities of labeled input data, however they cannot always generalize wellacross changes in input distributions. Domain adaptation algorithms have beenproposed to compensate for the degradation in performance due to domain shift.In this paper, we address the case when the target domain is unlabeled,requiring unsupervised adaptation. CORAL is a ""frustratingly easy"" unsuperviseddomain adaptation method that aligns the second-order statistics of the sourceand target distributions with a linear transformation. Here, we extend CORAL tolearn a nonlinear transformation that aligns correlations of layer activationsin deep neural networks (Deep CORAL). Experiments on standard benchmarkdatasets show state-of-the-art performance.",Deep CORAL: Correlation Alignment for Deep Domain Adaptation
192,,,,,,"3D action recognition - analysis of human actions based on 3D skeleton data -becomes popular recently due to its succinctness, robustness, andview-invariant representation. Recent attempts on this problem suggested todevelop RNN-based learning methods to model the contextual dependency in thetemporal domain. In this paper, we extend this idea to spatio-temporal domainsto analyze the hidden sources of action-related information within the inputdata over both domains concurrently. Inspired by the graphical structure of thehuman skeleton, we further propose a more powerful tree-structure basedtraversal method. To handle the noise and occlusion in 3D skeleton data, weintroduce new gating mechanism within LSTM to learn the reliability of thesequential input data and accordingly adjust its effect on updating thelong-term context information stored in the memory cell. Our method achievesstate-of-the-art performance on 4 challenging benchmark datasets for 3D humanaction analysis.",Spatio-Temporal LSTM with Trust Gates for 3D Human Action Recognition
193,,,,,,"Deep Neural Networks often require good regularizers to generalize well.Dropout is one such regularizer that is widely used among Deep Learningpractitioners. Recent work has shown that Dropout can also be viewed asperforming Approximate Bayesian Inference over the network parameters. In thiswork, we generalize this notion and introduce a rich family of regularizerswhich we call Generalized Dropout. One set of methods in this family, calledDropout++, is a version of Dropout with trainable parameters. Classical Dropoutemerges as a special case of this method. Another member of this family selectsthe width of neural network layers. Experiments show that these methods help inimproving generalization performance over Dropout.",Generalized Dropout
194,,,,,,"A new, radical CNN design approach is presented in this paper, consideringthe reduction of the total computational load during inference. This isachieved by a new holistic intervention on both the CNN architecture and thetraining procedure, which targets to the parsimonious inference by learning toexploit or remove the redundant capacity of a CNN architecture. This isaccomplished, by the introduction of a new structural element that can beinserted as an add-on to any contemporary CNN architecture, whilst preservingor even improving its recognition accuracy. Our approach formulates asystematic and data-driven method for developing CNNs that are trained toeventually change size and form in real-time during inference, targeting to thesmaller possible computational footprint. Results are provided for the optimalimplementation on a few modern, high-end mobile computing platforms indicatinga significant speed-up of up to x3 times.",Parsimonious Inference on Convolutional Neural Networks: Learning and  applying on-line kernel activation rules
195,,,,,,"We propose an algorithm for meta-learning that is model-agnostic, in thesense that it is compatible with any model trained with gradient descent andapplicable to a variety of different learning problems, includingclassification, regression, and reinforcement learning. The goal ofmeta-learning is to train a model on a variety of learning tasks, such that itcan solve new learning tasks using only a small number of training samples. Inour approach, the parameters of the model are explicitly trained such that asmall number of gradient steps with a small amount of training data from a newtask will produce good generalization performance on that task. In effect, ourmethod trains the model to be easy to fine-tune. We demonstrate that thisapproach leads to state-of-the-art performance on two few-shot imageclassification benchmarks, produces good results on few-shot regression, andaccelerates fine-tuning for policy gradient reinforcement learning with neuralnetwork policies.",Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks
196,,,,,,"For computer vision applications, prior works have shown the efficacy ofreducing the numeric precision of model parameters (network weights) in deepneural networks but also that reducing the precision of activations hurts modelaccuracy much more than reducing the precision of model parameters. We studyschemes to train networks from scratch using reduced-precision activationswithout hurting the model accuracy. We reduce the precision of activation maps(along with model parameters) using a novel quantization scheme and increasethe number of filter maps in a layer, and find that this scheme compensates orsurpasses the accuracy of the baseline full-precision network. As a result, onecan significantly reduce the dynamic memory footprint, memory bandwidth,computational energy and speed up the training and inference process withappropriate hardware support. We call our scheme WRPN - wide reduced-precisionnetworks. We report results using our proposed schemes and show that ourresults are better than previously reported accuracies on ILSVRC-12 datasetwhile being computationally less expensive compared to previously reportedreduced-precision networks.",WRPN: Training and Inference using Wide Reduced-Precision Networks
197,Chemistry,Chemistry,,,,"Deep neural networks trained on large supervised datasets have led toimpressive results in image classification and other tasks. However,well-annotated datasets can be time-consuming and expensive to collect, lendingincreased interest to larger but noisy datasets that are more easily obtained.In this paper, we show that deep neural networks are capable of generalizingfrom training data for which true labels are massively outnumbered by incorrectlabels. We demonstrate remarkably high test performance after training oncorrupted data from MNIST, CIFAR, and ImageNet. For example, on MNIST we obtaintest accuracy above 90 percent even after each clean training example has beendiluted with 100 randomly-labeled examples. Such behavior holds across multiplepatterns of label noise, even when erroneous labels are biased towardsconfusing classes. We show that training in this regime requires a significantbut manageable increase in dataset size that is related to the factor by whichcorrect labels have been diluted. Finally, we provide an analysis of ourresults that shows how increasing noise decreases the effective batch size.",Deep Learning is Robust to Massive Label Noise
198,Data,,,Data,,"Content-invariance in mapping codes learned by GAEs is a useful feature forvarious relation learning tasks. In this paper we show that thecontent-invariance of mapping codes for images of 2D and 3D rotated objects canbe substantially improved by extending the standard GAE loss (symmetricreconstruction error) with a regularization term that penalizes the symmetriccross-reconstruction error. This error term involves reconstruction of pairswith mapping codes obtained from other pairs exhibiting similartransformations. Although this would principally require knowledge of thetransformations exhibited by training pairs, our experiments show that abootstrapping approach can sidestep this issue, and that the regularizationterm can effectively be used in an unsupervised setting.",Improving Content-Invariance in Gated Autoencoders for 2D and 3D Object  Rotation
199,Data,,,Data,,"Sensor-based activity recognition seeks the profound high-level knowledgeabout human activities from multitudes of low-level sensor readings.Conventional pattern recognition approaches have made tremendous progress inthe past years. However, those methods often heavily rely on heuristichand-crafted feature extraction, which could hinder their generalizationperformance. Additionally, existing methods are undermined for unsupervised andincremental learning tasks. Recently, the recent advancement of deep learningmakes it possible to perform automatic high-level feature extraction thusachieves promising performance in many areas. Since then, deep learning basedmethods have been widely adopted for the sensor-based activity recognitiontasks. This paper surveys the recent advance of deep learning basedsensor-based activity recognition. We summarize existing literature from threeaspects: sensor modality, deep model, and application. We also present detailedinsights on existing work and propose grand challenges for future research.",Deep Learning for Sensor-based Activity Recognition: A Survey
200,Chemistry,,,Chemistry,,"We explain that the difficulties of training deep neural networks come from asyndrome of three consistency issues. This paper describes our efforts in theiranalysis and treatment. The first issue is the training speed inconsistency indifferent layers. We propose to address it with an intuitive,simple-to-implement, low footprint second-order method. The second issue is thescale inconsistency between the layer inputs and the layer residuals. Weexplain how second-order information provides favorable convenience in removingthis roadblock. The third and most challenging issue is the inconsistency inresidual propagation. Based on the fundamental theorem of linear algebra, weprovide a mathematical characterization of the famous vanishing gradientproblem. Thus, an important design principle for future optimization and neuralnetwork design is derived. We conclude this paper with the construction of anovel contractive neural network.",On the Importance of Consistency in Training Deep Neural Networks
201,,,,,,"For complex segmentation tasks, fully automatic systems are inherentlylimited in their achievable accuracy for extracting relevant objects.Especially in cases where only few data sets need to be processed for a highlyaccurate result, semi-automatic segmentation techniques exhibit a clear benefitfor the user. One area of application is medical image processing during anintervention for a single patient. We propose a learning-based cooperativesegmentation approach which includes the computing entity as well as the userinto the task. Our system builds upon a state-of-the-art fully convolutionalartificial neural network (FCN) as well as an active user model for training.During the segmentation process, a user of the trained system can iterativelyadd additional hints in form of pictorial scribbles as seed points into the FCNsystem to achieve an interactive and precise segmentation result. Thesegmentation quality of interactive FCNs is evaluated. Iterative FCN approachescan yield superior results compared to networks without the user input channelcomponent, due to a consistent improvement in segmentation quality after eachinteraction.",UI-Net: Interactive Artificial Neural Networks for Iterative Image  Segmentation Based on a User Model
202,Data,,,Data,,"Most of the weights in a Lightweight Neural Network have a value of zero,while the remaining ones are either +1 or -1. These universal approximatorsrequire approximately 1.1 bits/weight of storage, posses a quick forward passand achieve classification accuracies similar to conventional continuous-weightnetworks. Their training regimen focuses on error reduction initially, butlater emphasizes discretization of weights. They ignore insignificant inputs,remove unnecessary weights, and drop unneeded hidden neurons. We havesuccessfully tested them on the MNIST, credit card fraud, and credit carddefaults data sets using networks having 2 to 16 hidden layers and up to 4.4million weights.",Lightweight Neural Networks
203,Nuclear,,,Nuclear,,"We introduce tensor field networks, which are locally equivariant to 3Drotations, translations, and permutations of points at every layer. 3D rotationequivariance removes the need for data augmentation to identify features inarbitrary orientations. Our network uses filters built from sphericalharmonics; due to the mathematical consequences of this filter choice, eachlayer accepts as input (and guarantees as output) scalars, vectors, andhigher-order tensors, in the geometric sense of these terms. We demonstrate howtensor field networks learn to model simple physics (Newtonian gravitation andmoment of inertia), classify simple 3D shapes (trained on one orientation andtested on shapes in arbitrary orientations), and, given a small organicmolecule with an atom removed, replace the correct element at the correctlocation in space.",Tensor Field Networks: Rotation- and Translation-Equivariant Neural  Networks for 3D Point Clouds
204,Nuclear,Nuclear,,,,"We explore the effect of introducing prior information into the intermediatelevel of neural networks for a learning task on which all the state-of-the-artmachine learning algorithms tested failed to learn. We motivate our work fromthe hypothesis that humans learn such intermediate concepts from otherindividuals via a form of supervision or guidance using a curriculum. Theexperiments we have conducted provide positive evidence in favor of thishypothesis. In our experiments, a two-tiered MLP architecture is trained on adataset with 64x64 binary inputs images, each image with three sprites. Thefinal task is to decide whether all the sprites are the same or one of them isdifferent. Sprites are pentomino tetris shapes and they are placed in an imagewith different locations using scaling and rotation transformations. The firstpart of the two-tiered MLP is pre-trained with intermediate-level targets beingthe presence of sprites at each location, while the second part takes theoutput of the first part as input and predicts the final task's target binaryevent. The two-tiered MLP architecture, with a few tens of thousand examples,was able to learn the task perfectly, whereas all other algorithms (includeunsupervised pre-training, but also traditional algorithms like SVMs, decisiontrees and boosting) all perform no better than chance. We hypothesize that theoptimization difficulty involved when the intermediate pre-training is notperformed is due to the {\em composition} of two highly non-linear tasks. Ourfindings are also consistent with hypotheses on cultural learning inspired bythe observations of optimization problems with deep learning, presumablybecause of effective local minima.",Knowledge Matters: Importance of Prior Information for Optimization
205,Nuclear,Nuclear,,,,"Regularized training of an autoencoder typically results in hidden unitbiases that take on large negative values. We show that negative biases are anatural result of using a hidden layer whose responsibility is to bothrepresent the input data and act as a selection mechanism that ensures sparsityof the representation. We then show that negative biases impede the learning ofdata distributions whose intrinsic dimensionality is high. We also propose anew activation function that decouples the two roles of the hidden layer andthat allows us to learn representations on data with very high intrinsicdimensionality, where standard autoencoders typically fail. Since the decoupledactivation function acts like an implicit regularizer, the model can be trainedby minimizing the reconstruction error of training data, without requiring anyadditional regularization.",Zero-bias autoencoders and the benefits of co-adapting features
206,,,,,,"Deep convolutional neural networks (CNNs) have shown great potential fornumerous real-world machine learning applications, but performing inference inlarge CNNs in real-time remains a challenge. We have previously demonstratedthat traditional CNNs can be converted into deep spiking neural networks(SNNs), which exhibit similar accuracy while reducing both latency andcomputational load as a consequence of their data-driven, event-based style ofcomputing. Here we provide a novel theory that explains why this conversion issuccessful, and derive from it several new tools to convert a larger and morepowerful class of deep networks into SNNs. We identify the main sources ofapproximation errors in previous conversion methods, and propose simplemechanisms to fix these issues. Furthermore, we develop spiking implementationsof common CNN operations such as max-pooling, softmax, and batch-normalization,which allow almost loss-less conversion of arbitrary CNN architectures into thespiking domain. Empirical evaluation of different network architectures on theMNIST and CIFAR10 benchmarks leads to the best SNN results reported to date.",Theory and Tools for the Conversion of Analog to Spiking Convolutional  Neural Networks
207,Chemistry,Chemistry,,,,"In this paper, we propose a novel generative model named Stacked GenerativeAdversarial Networks (SGAN), which is trained to invert the hierarchicalrepresentations of a bottom-up discriminative network. Our model consists of atop-down stack of GANs, each learned to generate lower-level representationsconditioned on higher-level representations. A representation discriminator isintroduced at each feature hierarchy to encourage the representation manifoldof the generator to align with that of the bottom-up discriminative network,leveraging the powerful discriminative representations to guide the generativemodel. In addition, we introduce a conditional loss that encourages the use ofconditional information from the layer above, and a novel entropy loss thatmaximizes a variational lower bound on the conditional entropy of generatoroutputs. We first train each stack independently, and then train the wholemodel end-to-end. Unlike the original GAN that uses a single noise vector torepresent all the variations, our SGAN decomposes variations into multiplelevels and gradually resolves uncertainties in the top-down generative process.Based on visual inspection, Inception scores and visual Turing test, wedemonstrate that SGAN is able to generate images of much higher quality thanGANs without stacking.",Stacked Generative Adversarial Networks
208,Physics,Physics,,,,"We study the problem of large scale, multi-label visual recognition with alarge number of possible classes. We propose a method for augmenting a trainedneural network classifier with auxiliary capacity in a manner designed tosignificantly improve upon an already well-performing model, while minimallyimpacting its computational footprint. Using the predictions of the networkitself as a descriptor for assessing visual similarity, we define apartitioning of the label space into groups of visually similar entities. Wethen augment the network with auxilliary hidden layer pathways withconnectivity only to these groups of label units. We report a significantimprovement in mean average precision on a large-scale object recognition taskwith the augmented model, while increasing the number of multiply-adds by lessthan 3%.",Self-informed neural network structure learning
209,Chemistry,,,Chemistry,,"Artificial neural networks typically have a fixed, non-linear activationfunction at each neuron. We have designed a novel form of piecewise linearactivation function that is learned independently for each neuron usinggradient descent. With this adaptive activation function, we are able toimprove upon deep neural network architectures composed of static rectifiedlinear units, achieving state-of-the-art performance on CIFAR-10 (7.51%),CIFAR-100 (30.83%), and a benchmark from high-energy physics involving Higgsboson decay modes.",Learning Activation Functions to Improve Deep Neural Networks
210,DV,DV,,,,"Suitable lateral connections between encoder and decoder are shown to allowhigher layers of a denoising autoencoder (dAE) to focus on invariantrepresentations. In regular autoencoders, detailed information needs to becarried through the highest layers but lateral connections from encoder todecoder relieve this pressure. It is shown that abstract invariant features canbe translated to detailed reconstructions when invariant features are allowedto modulate the strength of the lateral connection. Three dAE structures withmodulated and additive lateral connections, and without lateral connectionswere compared in experiments using real-world images. The experiments verifythat adding modulated lateral connections to the model 1) improves the accuracyof the probability model for inputs, as measured by denoising performance; 2)results in representations whose degree of invariance grows faster towards thehigher layers; and 3) supports the formation of diverse invariant poolings.",Denoising autoencoder with modulated lateral connections learns  invariant representations of natural images
211,Nuclear,,,Nuclear,,"A grand challenge in machine learning is the development of computationalalgorithms that match or outperform humans in perceptual inference tasks thatare complicated by nuisance variation. For instance, visual object recognitioninvolves the unknown object position, orientation, and scale in objectrecognition while speech recognition involves the unknown voice pronunciation,pitch, and speed. Recently, a new breed of deep learning algorithms haveemerged for high-nuisance inference tasks that routinely yield patternrecognition systems with near- or super-human capabilities. But a fundamentalquestion remains: Why do they work? Intuitions abound, but a coherent frameworkfor understanding, analyzing, and synthesizing deep learning architectures hasremained elusive. We answer this question by developing a new probabilisticframework for deep learning based on the Deep Rendering Model: a generativeprobabilistic model that explicitly captures latent nuisance variation. Byrelaxing the generative model to a discriminative one, we can recover two ofthe current leading deep learning systems, deep convolutional neural networksand random decision forests, providing insights into their successes andshortcomings, as well as a principled route to their improvement.",A Probabilistic Theory of Deep Learning
212,Data,Data,,,,"Tackling pattern recognition problems in areas such as computer vision,bioinformatics, speech or text recognition is often done best by taking intoaccount task-specific statistical relations between output variables. Instructured prediction, this internal structure is used to predict multipleoutputs simultaneously, leading to more accurate and coherent predictions.Structural support vector machines (SSVMs) are nonprobabilistic models thatoptimize a joint input-output function through margin-based learning. BecauseSSVMs generally disregard the interplay between unary and interaction factorsduring the training phase, final parameters are suboptimal. Moreover, itsfactors are often restricted to linear combinations of input features, limitingits generalization power. To improve prediction accuracy, this paper proposes:(i) Joint inference and learning by integration of back-propagation andloss-augmented inference in SSVM subgradient descent; (ii) Extending SSVMfactors to neural networks that form highly nonlinear functions of inputfeatures. Image segmentation benchmark results demonstrate improvements overconventional SSVM training methods in terms of accuracy, highlighting thefeasibility of end-to-end SSVM training with neural factors.",Integrated Inference and Learning of Neural Factors in Structural  Support Vector Machines
213,Chemistry,Chemistry,,,,"Top-down information plays a central role in human perception, but playsrelatively little role in many current state-of-the-art deep networks, such asConvolutional Neural Networks (CNNs). This work seeks to explore a path bywhich top-down information can have a direct impact within current deepnetworks. We explore this path by learning and using ""generators"" correspondingto the network internal effects of three types of transformation (each arestriction of a general affine transformation): rotation, scaling, andtranslation. We demonstrate how these learned generators can be used totransfer top-down information to novel settings, as mediated by the ""featureflows"" that the transformations (and the associated generators) correspond toinside the network. Specifically, we explore three aspects: 1) using generatorsas part of a method for synthesizing transformed images --- given a previouslyunseen image, produce versions of that image corresponding to one or morespecified transformations, 2) ""zero-shot learning"" --- when provided with afeature flow corresponding to the effect of a transformation of unknown amount,leverage learned generators as part of a method by which to perform an accuratecategorization of the amount of transformation, even for amounts never observedduring training, and 3) (inside-CNN) ""data augmentation"" --- improve theclassification performance of an existing network by using the learnedgenerators to directly provide additional training ""inside the CNN"".",What Happened to My Dog in That Network: Unraveling Top-down Generators  in Convolutional Neural Networks
214,Nuclear,,,Nuclear,,"Modern computer vision algorithms typically require expensive dataacquisition and accurate manual labeling. In this work, we instead leverage therecent progress in computer graphics to generate fully labeled, dynamic, andphoto-realistic proxy virtual worlds. We propose an efficient real-to-virtualworld cloning method, and validate our approach by building and publiclyreleasing a new video dataset, called Virtual KITTI (seehttp://www.xrce.xerox.com/Research-Development/Computer-Vision/Proxy-Virtual-Worlds),automatically labeled with accurate ground truth for object detection,tracking, scene and instance segmentation, depth, and optical flow. We providequantitative experimental evidence suggesting that (i) modern deep learningalgorithms pre-trained on real data behave similarly in real and virtualworlds, and (ii) pre-training on virtual data improves performance. As the gapbetween real and virtual worlds is small, virtual worlds enable measuring theimpact of various weather and imaging conditions on recognition performance,all other things being equal. We show these factors may affect drasticallyotherwise high-performing deep models for tracking.",Virtual Worlds as Proxy for Multi-Object Tracking Analysis
215,,,,,,"Video sequences contain rich dynamic patterns, such as dynamic texturepatterns that exhibit stationarity in the temporal domain, and action patternsthat are non-stationary in either spatial or temporal domain. We show that aspatial-temporal generative ConvNet can be used to model and synthesize dynamicpatterns. The model defines a probability distribution on the video sequence,and the log probability is defined by a spatial-temporal ConvNet that consistsof multiple layers of spatial-temporal filters to capture spatial-temporalpatterns of different scales. The model can be learned from the training videosequences by an ""analysis by synthesis"" learning algorithm that iterates thefollowing two steps. Step 1 synthesizes video sequences from the currentlylearned model. Step 2 then updates the model parameters based on the differencebetween the synthesized video sequences and the observed training sequences. Weshow that the learning algorithm can synthesize realistic dynamic patterns.",Synthesizing Dynamic Patterns by Spatial-Temporal Generative ConvNet
216,Data,Data,,,,"Taking inspiration from biological evolution, we explore the idea of ""Candeep neural networks evolve naturally over successive generations into highlyefficient deep neural networks?"" by introducing the notion of synthesizing newhighly efficient, yet powerful deep neural networks over successive generationsvia an evolutionary process from ancestor deep neural networks. Thearchitectural traits of ancestor deep neural networks are encoded usingsynaptic probability models, which can be viewed as the `DNA' of thesenetworks. New descendant networks with differing network architectures aresynthesized based on these synaptic probability models from the ancestornetworks and computational environmental factor models, in a random manner tomimic heredity, natural selection, and random mutation. These offspringnetworks are then trained into fully functional networks, like one would traina newborn, and have more efficient, more diverse network architectures thantheir ancestor networks, while achieving powerful modeling capabilities.Experimental results for the task of visual saliency demonstrated that thesynthesized `evolved' offspring networks can achieve state-of-the-artperformance while having network architectures that are significantly moreefficient (with a staggering $\sim$48-fold decrease in synapses by the fourthgeneration) compared to the original ancestor network.",Deep Learning with Darwin: Evolutionary Synthesis of Deep Neural  Networks
217,,,,,,"This paper proposes an alternating back-propagation algorithm for learningthe generator network model. The model is a non-linear generalization of factoranalysis. In this model, the mapping from the continuous latent factors to theobserved signal is parametrized by a convolutional neural network. Thealternating back-propagation algorithm iterates the following two steps: (1)Inferential back-propagation, which infers the latent factors by Langevindynamics or gradient descent. (2) Learning back-propagation, which updates theparameters given the inferred latent factors by gradient descent. The gradientcomputations in both steps are powered by back-propagation, and they share mostof their code in common. We show that the alternating back-propagationalgorithm can learn realistic generator models of natural images, videosequences, and sounds. Moreover, it can also be used to learn from incompleteor indirect training data.",Alternating Back-Propagation for Generator Network
218,Chemistry,Chemistry,,,,"Recently, several optimization methods have been successfully applied to thehyperparameter optimization of deep neural networks (DNNs). The methods work bymodeling the joint distribution of hyperparameter values and correspondingerror. Those methods become less practical when applied to modern DNNs whosetraining may take a few days and thus one cannot collect sufficientobservations to accurately model the distribution. To address this challengingissue, we propose a method that learns to transfer optimal hyperparametervalues for a small source dataset to hyperparameter values with comparableperformance on a dataset of interest. As opposed to existing transfer learningmethods, our proposed method does not use hand-designed features. Instead, ituses surrogates to model the hyperparameter-error distributions of the twodatasets and trains a neural network to learn the transfer function. Extensiveexperiments on three CV benchmark datasets clearly demonstrate the efficiencyof our method.",Hyperparameter Transfer Learning through Surrogate Alignment for  Efficient Deep Neural Network Training
219,Chemistry,Chemistry,,,,"While perception tasks such as visual object recognition and textunderstanding play an important role in human intelligence, the subsequenttasks that involve inference, reasoning and planning require an even higherlevel of intelligence. The past few years have seen major advances in manyperception tasks using deep learning models. For higher-level inference,however, probabilistic graphical models with their Bayesian nature are stillmore powerful and flexible. To achieve integrated intelligence that involvesboth perception and inference, it is naturally desirable to tightly integratedeep learning and Bayesian models within a principled probabilistic framework,which we call Bayesian deep learning. In this unified framework, the perceptionof text or images using deep learning can boost the performance of higher-levelinference and in return, the feedback from the inference process is able toenhance the perception of text or images. This paper proposes a generalframework for Bayesian deep learning and reviews its recent applications onrecommender systems, topic models, and control. In this paper, we also discussthe relationship and differences between Bayesian deep learning and otherrelated topics like Bayesian treatment of neural networks.",Towards Bayesian Deep Learning: A Framework and Some Existing Methods
220,,,,,,"We propose and systematically evaluate three strategies for trainingdynamically-routed artificial neural networks: graphs of learnedtransformations through which different input signals may take different paths.Though some approaches have advantages over others, the resulting networks areoften qualitatively similar. We find that, in dynamically-routed networkstrained to classify images, layers and branches become specialized to processdistinct categories of images. Additionally, given a fixed computationalbudget, dynamically-routed networks tend to perform better than comparablestatically-routed networks.",Deciding How to Decide: Dynamic Routing in Artificial Neural Networks
221,DV,DV,,,,"Deconvolutional layers have been widely used in a variety of deep models forup-sampling, including encoder-decoder networks for semantic segmentation anddeep generative models for unsupervised learning. One of the key limitations ofdeconvolutional operations is that they result in the so-called checkerboardproblem. This is caused by the fact that no direct relationship exists amongadjacent pixels on the output feature map. To address this problem, we proposethe pixel deconvolutional layer (PixelDCL) to establish direct relationshipsamong adjacent pixels on the up-sampled feature map. Our method is based on afresh interpretation of the regular deconvolution operation. The resultingPixelDCL can be used to replace any deconvolutional layer in a plug-and-playmanner without compromising the fully trainable capabilities of originalmodels. The proposed PixelDCL may result in slight decrease in efficiency, butthis can be overcome by an implementation trick. Experimental results onsemantic segmentation demonstrate that PixelDCL can consider spatial featuressuch as edges and shapes and yields more accurate segmentation outputs thandeconvolutional layers. When used in image generation tasks, our PixelDCL canlargely overcome the checkerboard problem suffered by regular deconvolutionoperations.",Pixel Deconvolutional Networks
222,,,,,,"We propose a novel architecture for $k$-shot classification on the Omniglotdataset. Building on prototypical networks, we extend their architecture towhat we call Gaussian prototypical networks. Prototypical networks learn a mapbetween images and embedding vectors, and use their clustering forclassification. In our model, a part of the encoder output is interpreted as aconfidence region estimate about the embedding point, and expressed as aGaussian covariance matrix. Our network then constructs a direction and classdependent distance metric on the embedding space, using uncertainties ofindividual data points as weights. We show that Gaussian prototypical networksare a preferred architecture over vanilla prototypical networks with anequivalent number of parameters. We report state-of-the-art performance in1-shot and 5-shot classification both in 5-way and 20-way regime (for 5-shot5-way, we are comparable to previous state-of-the-art) on the Omniglot dataset.We explore artificially down-sampling a fraction of images in the training set,which improves our performance even further. We therefore hypothesize thatGaussian prototypical networks might perform better in less homogeneous,noisier datasets, which are commonplace in real world applications.",Gaussian Prototypical Networks for Few-Shot Learning on Omniglot
223,Physics,Physics,,,,"In this paper, we show a phenomenon, which we named ""super-convergence"",where residual networks can be trained using an order of magnitude feweriterations than is used with standard training methods. The existence ofsuper-convergence is relevant to understanding why deep networks generalizewell. One of the key elements of super-convergence is training with cyclicallearning rates and a large maximum learning rate. Furthermore, we presentevidence that training with large learning rates improves performance byregularizing the network. In addition, we show that super-convergence providesa greater boost in performance relative to standard training when the amount oflabeled training data is limited. We also derive a simplification of theHessian Free optimization method to compute an estimate of the optimal learningrate. The architectures and code to replicate the figures in this paper areavailable at github.com/lnsmith54/super-convergence.",Super-Convergence: Very Fast Training of Residual Networks Using Large  Learning Rates
224,,,,,,"Learning, taking into account full distribution of the data, referred to asgenerative, is not feasible with deep neural networks (DNNs) because they modelonly the conditional distribution of the outputs given the inputs. Currentsolutions are either based on joint probability models facing difficultestimation problems or learn two separate networks, mapping inputs to outputs(recognition) and vice-versa (generation). We propose an intermediate approach.First, we show that forward computation in DNNs with logistic sigmoidactivations corresponds to a simplified approximate Bayesian inference in adirected probabilistic multi-layer model. This connection allows to interpretDNN as a probabilistic model of the output and all hidden units given theinput. Second, we propose that in order for the recognition and generationnetworks to be more consistent with the joint model of the data, weights of therecognition and generator network should be related by transposition. Wedemonstrate in a tentative experiment that such a coupled pair can be learnedgeneratively, modelling the full distribution of the data, and has enoughcapacity to perform well in both recognition and generation.",Generative learning for deep networks
225,Nuclear,,,Nuclear,,"We explore efficient neural architecture search methods and show that asimple yet powerful evolutionary algorithm can discover new architectures withexcellent performance. Our approach combines a novel hierarchical geneticrepresentation scheme that imitates the modularized design pattern commonlyadopted by human experts, and an expressive search space that supports complextopologies. Our algorithm efficiently discovers architectures that outperform alarge number of manually designed models for image classification, obtainingtop-1 error of 3.6% on CIFAR-10 and 20.3% when transferred to ImageNet, whichis competitive with the best existing neural architecture search approaches. Wealso present results using random search, achieving 0.3% less top-1 accuracy onCIFAR-10 and 0.1% less on ImageNet whilst reducing the search time from 36hours down to 1 hour.",Hierarchical Representations for Efficient Architecture Search
226,Nuclear,Nuclear,,,,"Effective training of neural networks requires much data. In the low-dataregime, parameters are underdetermined, and learnt networks generalise poorly.Data Augmentation alleviates this by using existing data more effectively.However standard data augmentation produces only limited plausible alternativedata. Given there is potential to generate a much broader set of augmentations,we design and train a generative model to do data augmentation. The model,based on image conditional Generative Adversarial Networks, takes data from asource domain and learns to take any data item and generalise it to generateother within-class data items. As this generative process does not depend onthe classes themselves, it can be applied to novel unseen classes of data. Weshow that a Data Augmentation Generative Adversarial Network (DAGAN) augmentsstandard vanilla classifiers well. We also show a DAGAN can enhance few-shotlearning systems such as Matching Networks. We demonstrate these approaches onOmniglot, on EMNIST having learnt the DAGAN on Omniglot, and VGG-Face data. Inour experiments we can see over 13% increase in accuracy in the low-data regimeexperiments in Omniglot (from 69% to 82%), EMNIST (73.9% to 76%) and VGG-Face(4.5% to 12%); in Matching Networks for Omniglot we observe an increase of 0.5%(from 96.9% to 97.4%) and an increase of 1.8% in EMNIST (from 59.5% to 61.3%).",Data Augmentation Generative Adversarial Networks
227,,,,,,"This paper introduces the first deep neural network-based estimation metricfor the jigsaw puzzle problem. Given two puzzle piece edges, the neural networkpredicts whether or not they should be adjacent in the correct assembly of thepuzzle, using nothing but the pixels of each piece. The proposed metricexhibits an extremely high precision even though no manual feature extractionis performed. When incorporated into an existing puzzle solver, the solution'saccuracy increases significantly, achieving thereby a new state-of-the-artstandard.",DNN-Buddies: A Deep Neural Network-Based Estimation Metric for the  Jigsaw Puzzle Problem
228,,,,,,"In this paper we describe the problem of painter classification, and proposea novel approach based on deep convolutional autoencoder neural networks. Whileprevious approaches relied on image processing and manual feature extractionfrom paintings, our approach operates on the raw pixel level, without anypreprocessing or manual feature extraction. We first train a deep convolutionalautoencoder on a dataset of paintings, and subsequently use it to initialize asupervised convolutional neural network for the classification phase.  The proposed approach substantially outperforms previous methods, improvingthe previous state-of-the-art for the 3-painter classification problem from90.44% accuracy (previous state-of-the-art) to 96.52% accuracy, i.e., a 63%reduction in error rate.",DeepPainter: Painter Classification Using Deep Convolutional  Autoencoders
229,Physics,Physics,,,,"This paper presents a novel deep learning-based method for learning afunctional representation of mammalian neural images. The method uses a deepconvolutional denoising autoencoder (CDAE) for generating an invariant, compactrepresentation of in situ hybridization (ISH) images. While most existingmethods for bio-imaging analysis were not developed to handle images withhighly complex anatomical structures, the results presented in this paper showthat functional representation extracted by CDAE can help learn features offunctional gene ontology categories for their classification in a highlyaccurate manner. Using this CDAE representation, our method outperforms theprevious state-of-the-art classification rate, by improving the average AUCfrom 0.92 to 0.98, i.e., achieving 75% reduction in error. The method operateson input images that were downsampled significantly with respect to theoriginal ones to make it computationally feasible.",DeepBrain: Functional Representation of Neural In-Situ Hybridization  Images for Gene Ontology Classification Using Deep Convolutional Autoencoders
230,,,,,,"In this paper, we propose novel generative models for creating adversarialexamples, slightly perturbed images resembling natural images but maliciouslycrafted to fool pre-trained models. We present trainable deep neural networksfor transforming images to adversarial perturbations. Our proposed models canproduce image-agnostic and image-dependent perturbations for both targeted andnon-targeted attacks. We also demonstrate that similar architectures canachieve impressive results in fooling classification and semantic segmentationmodels, obviating the need for hand-crafting attack methods for each task.Using extensive experiments on challenging high-resolution datasets such asImageNet and Cityscapes, we show that our perturbations achieve high foolingrates with small perturbation norms. Moreover, our attacks are considerablyfaster than current iterative methods at inference time.",Generative Adversarial Perturbations
231,Physics,Physics,,,,"We show that simple transformations, namely translations and rotations alone,are sufficient to fool neural network-based vision models on a significantfraction of inputs. This is in sharp contrast to previous work that relied onmore complicated optimization approaches that are unlikely to appear outside ofa truly adversarial setting. Moreover, fooling rotations and translations areeasy to find and require only a few black-box queries to the target model.Overall, our findings emphasize the need for designing robust classifiers evenin natural, benign contexts.",A Rotation and a Translation Suffice: Fooling CNNs with Simple  Transformations
232,Nuclear,,,Nuclear,,"The quest for performant networks has been a significant force that drivesthe advancements of deep learning in recent years. While rewarding, improvingnetwork design has never been an easy journey. The large design space combinedwith the tremendous cost required for network training poses a major obstacleto this endeavor. In this work, we propose a new approach to this problem,namely, predicting the performance of a network before training, based on itsarchitecture. Specifically, we develop a unified way to encode individuallayers into vectors and bring them together to form an integrated descriptionvia LSTM. Taking advantage of the recurrent network's strong expressive power,this method can reliably predict the performances of various networkarchitectures. Our empirical studies showed that it not only achieved accuratepredictions but also produced consistent rankings across datasets -- a keydesideratum in performance prediction.",Peephole: Predicting Network Performance Before Training
233,,,,,,"Convolutional neural networks (CNNs) are similar to ""ordinary"" neuralnetworks in the sense that they are made up of hidden layers consisting ofneurons with ""learnable"" parameters. These neurons receive inputs, performs adot product, and then follows it with a non-linearity. The whole networkexpresses the mapping between raw image pixels and their class scores.Conventionally, the Softmax function is the classifier used at the last layerof this network. However, there have been studies (Alalshekmubarak and Smith,2013; Agarap, 2017; Tang, 2013) conducted to challenge this norm. The citedstudies introduce the usage of linear support vector machine (SVM) in anartificial neural network architecture. This project is yet another take on thesubject, and is inspired by (Tang, 2013). Empirical data has shown that theCNN-SVM model was able to achieve a test accuracy of ~99.04% using the MNISTdataset (LeCun, Cortes, and Burges, 2010). On the other hand, the CNN-Softmaxwas able to achieve a test accuracy of ~99.23% using the same dataset. Bothmodels were also tested on the recently-published Fashion-MNIST dataset (Xiao,Rasul, and Vollgraf, 2017), which is suppose to be a more difficult imageclassification dataset than MNIST (Zalandoresearch, 2017). This proved to bethe case as CNN-SVM reached a test accuracy of ~90.72%, while the CNN-Softmaxreached a test accuracy of ~91.86%. The said results may be improved if datapreprocessing techniques were employed on the datasets, and if the base CNNmodel was a relatively more sophisticated than the one used in this study.",An Architecture Combining Convolutional Neural Network (CNN) and Support  Vector Machine (SVM) for Image Classification
234,Nuclear,,,Nuclear,,"Artifical Neural Networks are a particular class of learning systems modeledafter biological neural functions with an interesting penchant for Hebbianlearning, that is ""neurons that wire together, fire together"". However, unliketheir natural counterparts, artificial neural networks have a close andstringent coupling between the modules of neurons in the network. This couplingor locking imposes upon the network a strict and inflexible structure thatprevent layers in the network from updating their weights until a fullfeed-forward and backward pass has occurred. Such a constraint though may havesufficed for a while, is now no longer feasible in the era of very-large-scalemachine learning, coupled with the increased desire for parallelization of thelearning process across multiple computing infrastructures. To solve thisproblem, synthetic gradients (SG) with decoupled neural interfaces (DNI) areintroduced as a viable alternative to the backpropagation algorithm. This paperperforms a speed benchmark to compare the speed and accuracy capabilities ofSG-DNI as opposed to a standard neural interface using multilayer perceptronMLP. SG-DNI shows good promise, in that it not only captures the learningproblem, it is also over 3-fold faster due to it asynchronous learningcapabilities.",Benchmarking Decoupled Neural Interfaces with Synthetic Gradients
235,Physics,Physics,,,,"Image segmentation is the process of partitioning an image into a set ofmeaningful regions according to some criteria. Hierarchical segmentation hasemerged as a major trend in this regard as it favors the emergence of importantregions at different scales. On the other hand, many methods allow us to haveprior information on the position of structures of interest in the images. Inthis paper, we present a versatile hierarchical segmentation method that takesinto account any prior spatial information and outputs a hierarchicalsegmentation that emphasizes the contours or regions of interest whilepreserving the important structures in the image. An application of this methodto the weakly-supervised segmentation problem is presented.",Segmentation hirarchique faiblement supervise
236,,,,,,"For fast and energy-efficient deployment of trained deep neural networks onresource-constrained embedded hardware, each learned weight parameter shouldideally be represented and stored using a single bit. Error-rates usuallyincrease when this requirement is imposed. Here, we report large improvementsin error rates on multiple datasets, for deep convolutional neural networksdeployed with 1-bit-per-weight. Using wide residual networks as our mainbaseline, our approach simplifies existing methods that binarize weights byapplying the sign function in training; we apply scaling factors for each layerwith constant unlearned values equal to the layer-specific standard deviationsused for initialization. For CIFAR-10, CIFAR-100 and ImageNet, and models with1-bit-per-weight requiring less than 10 MB of parameter memory, we achieveerror rates of 3.9%, 18.5% and 26.0% / 8.5% (Top-1 / Top-5) respectively. Wealso considered MNIST, SVHN and ImageNet32, achieving 1-bit-per-weight testresults of 0.27%, 1.9%, and 41.3% / 19.1% respectively. For CIFAR, our errorrates halve previously reported values, and are within about 1% of ourerror-rates for the same network with full-precision weights. For networks thatoverfit, we also show significant improvements in error rate by not learningbatch normalization scale and offset parameters. This applies to both fullprecision and 1-bit-per-weight networks. Using a warm-restart learning-rateschedule, we found that training for 1-bit-per-weight is just as fast asfull-precision networks, with better accuracy than standard schedules, andachieved about 98%-99% of peak performance in just 62 training epochs forCIFAR-10/100. For full training code and trained models in MATLAB, Keras andPyTorch see https://github.com/McDonnell-Lab/1-bit-per-weight/ .",Training wide residual networks for deployment using a single bit for  each weight
237,,,,,,"We introduce the use of rectified linear units (ReLU) as the classificationfunction in a deep neural network (DNN). Conventionally, ReLU is used as anactivation function in DNNs, with Softmax function as their classificationfunction. However, there have been several studies on using a classificationfunction other than Softmax, and this study is an addition to those. Weaccomplish this by taking the activation of the penultimate layer $h_{n - 1}$in a neural network, then multiply it by weight parameters $\theta$ to get theraw scores $o_{i}$. Afterwards, we threshold the raw scores $o_{i}$ by $0$,i.e. $f(o) = \max(0, o_{i})$, where $f(o)$ is the ReLU function. We provideclass predictions $\hat{y}$ through argmax function, i.e. argmax $f(x)$.",Deep Learning using Rectified Linear Units (ReLU)
238,,,,,,"We propose rectified factor networks (RFNs) to efficiently construct verysparse, non-linear, high-dimensional representations of the input. RFN modelsidentify rare and small events in the input, have a low interference betweencode units, have a small reconstruction error, and explain the data covariancestructure. RFN learning is a generalized alternating minimization algorithmderived from the posterior regularization method which enforces non-negativeand normalized posterior means. We proof convergence and correctness of the RFNlearning algorithm. On benchmarks, RFNs are compared to other unsupervisedmethods like autoencoders, RBMs, factor analysis, ICA, and PCA. In contrast toprevious sparse coding methods, RFNs yield sparser codes, capture the data'scovariance structure more precisely, and have a significantly smallerreconstruction error. We test RFNs as pretraining technique for deep networkson different vision datasets, where RFNs were superior to RBMs andautoencoders. On gene expression data from two pharmaceutical drug discoverystudies, RFNs detected small and rare gene modules that revealed highlyrelevant new biological insights which were so far missed by other unsupervisedmethods.",Rectified Factor Networks
239,,,,,,"Motivated by an important insight from neural science, we propose a newframework for understanding the success of the recently proposed ""maxout""networks. The framework is based on encoding information on sparse pathways andrecognizing the correct pathway at inference time. Elaborating further on thisinsight, we propose a novel deep network architecture, called ""channel-out""network, which takes a much better advantage of sparse pathway encoding. Inchannel-out networks, pathways are not only formed a posteriori, but they arealso actively selected according to the inference outputs from the lowerlayers. From a mathematical perspective, channel-out networks can represent awider class of piece-wise continuous functions, thereby endowing the networkwith more expressive power than that of maxout networks. We test ourchannel-out networks on several well-known image classification benchmarks,setting new state-of-the-art performance on CIFAR-100 and STL-10, whichrepresent some of the ""harder"" image classification benchmarks.",From Maxout to Channel-Out: Encoding Information on Sparse Pathways
240,,,,,,We propose a novel learning method for multilayered neural networks whichuses feedforward supervisory signal and associates classification of a newinput with that of pre-trained input. The proposed method effectively uses richinput information in the earlier layer for robust leaning and revising internalrepresentation in a multilayer neural network.,Competitive Learning with Feedforward Supervisory Signal for Pre-trained  Multilayered Networks
241,Data,,,Data,,"Our proposed deeply-supervised nets (DSN) method simultaneously minimizesclassification error while making the learning process of hidden layers directand transparent. We make an attempt to boost the classification performance bystudying a new formulation in deep networks. Three aspects in convolutionalneural networks (CNN) style architectures are being looked at: (1) transparencyof the intermediate layers to the overall classification; (2)discriminativeness and robustness of learned features, especially in the earlylayers; (3) effectiveness in training due to the presence of the exploding andvanishing gradients. We introduce ""companion objective"" to the individualhidden layers, in addition to the overall objective at the output layer (adifferent strategy to layer-wise pre-training). We extend techniques fromstochastic gradient methods to analyze our algorithm. The advantage of ourmethod is evident and our experimental result on benchmark datasets showssignificant performance gain over existing methods (e.g. all state-of-the-artresults on MNIST, CIFAR-10, CIFAR-100, and SVHN).",Deeply-Supervised Nets
242,DV,DV,,,,"We revisit the choice of SGD for training deep neural networks byreconsidering the appropriate geometry in which to optimize the weights. Weargue for a geometry invariant to rescaling of weights that does not affect theoutput of the network, and suggest Path-SGD, which is an approximate steepestdescent method with respect to a path-wise regularizer related to max-normregularization. Path-SGD is easy and efficient to implement and leads toempirical gains over SGD and AdaGrad.",Path-SGD: Path-Normalized Optimization in Deep Neural Networks
243,,,,,,"The Resilient Propagation (Rprop) algorithm has been very popular forbackpropagation training of multilayer feed-forward neural networks in variousapplications. The standard Rprop however encounters difficulties in the contextof deep neural networks as typically happens with gradient-based learningalgorithms. In this paper, we propose a modification of the Rprop that combinesstandard Rprop steps with a special drop out technique. We apply the method fortraining Deep Neural Networks as standalone components and in ensembleformulations. Results on the MNIST dataset show that the proposed modificationalleviates standard Rprop's problems demonstrating improved learning speed andaccuracy.",Adapting Resilient Propagation for Deep Learning
244,,,,,,"Autism Spectrum Disorders (ASDs) are often associated with specific atypicalpostural or motor behaviors, of which Stereotypical Motor Movements (SMMs) havea specific visibility. While the identification and the quantification of SMMpatterns remain complex, its automation would provide support to accuratetuning of the intervention in the therapy of autism. Therefore, it is essentialto develop automatic SMM detection systems in a real world setting, taking careof strong inter-subject and intra-subject variability. Wireless accelerometersensing technology can provide a valid infrastructure for real-time SMMdetection, however such variability remains a problem also for machine learningmethods, in particular whenever handcrafted features extracted fromaccelerometer signal are considered. Here, we propose to employ the deeplearning paradigm in order to learn discriminating features from multi-sensoraccelerometer signals. Our results provide preliminary evidence that featurelearning and transfer learning embedded in the deep architecture achieve higheraccurate SMM detectors in longitudinal scenarios.",Convolutional Neural Network for Stereotypical Motor Movement Detection  in Autism
245,,,,,,"Residual networks (ResNets) have recently achieved state-of-the-art onchallenging computer vision tasks. We introduce Resnet in Resnet (RiR): a deepdual-stream architecture that generalizes ResNets and standard CNNs and iseasily implemented with no computational overhead. RiR consistently improvesperformance over ResNets, outperforms architectures with similar amounts ofaugmentation on CIFAR-10, and establishes a new state-of-the-art on CIFAR-100.",Resnet in Resnet: Generalizing Residual Architectures
246,Chemistry,Chemistry,,,,"There has been significant recent interest towards achieving highly efficientdeep neural network architectures. A promising paradigm for achieving this isthe concept of evolutionary deep intelligence, which attempts to mimicbiological evolution processes to synthesize highly-efficient deep neuralnetworks over successive generations. An important aspect of evolutionary deepintelligence is the genetic encoding scheme used to mimic heredity, which canhave a significant impact on the quality of offspring deep neural networks.Motivated by the neurobiological phenomenon of synaptic clustering, weintroduce a new genetic encoding scheme where synaptic probability is driventowards the formation of a highly sparse set of synaptic clusters. Experimentalresults for the task of image classification demonstrated that the synthesizedoffspring networks using this synaptic cluster-driven genetic encoding schemecan achieve state-of-the-art performance while having network architecturesthat are not only significantly more efficient (with a ~125-fold decrease insynapses for MNIST) compared to the original ancestor network, but alsotailored for GPU-accelerated machine learning applications.",Evolutionary Synthesis of Deep Neural Networks via Synaptic  Cluster-driven Genetic Encoding
247,Data,Data,,,,"The increasingly photorealistic sample quality of generative image modelssuggests their feasibility in applications beyond image generation. We presentthe Neural Photo Editor, an interface that leverages the power of generativeneural networks to make large, semantically coherent changes to existingimages. To tackle the challenge of achieving accurate reconstructions withoutloss of feature quality, we introduce the Introspective Adversarial Network, anovel hybridization of the VAE and GAN. Our model efficiently captureslong-range dependencies through use of a computational block based onweight-shared dilated convolutions, and improves generalization performancewith Orthogonal Regularization, a novel weight regularization method. Wevalidate our contributions on CelebA, SVHN, and CIFAR-100, and produce samplesand reconstructions with high visual fidelity.",Neural Photo Editing with Introspective Adversarial Networks
248,,,,,,"We present an approach to adaptively utilize deep neural networks in order toreduce the evaluation time on new examples without loss of accuracy. Ratherthan attempting to redesign or approximate existing networks, we propose twoschemes that adaptively utilize networks. We first pose an adaptive networkevaluation scheme, where we learn a system to adaptively choose the componentsof a deep network to be evaluated for each example. By allowing examplescorrectly classified using early layers of the system to exit, we avoid thecomputational time associated with full evaluation of the network. We extendthis to learn a network selection system that adaptively selects the network tobe evaluated for each example. We show that computational time can bedramatically reduced by exploiting the fact that many examples can be correctlyclassified using relatively efficient networks and that complex,computationally costly networks are only necessary for a small fraction ofexamples. We pose a global objective for learning an adaptive early exit ornetwork selection policy and solve it by reducing the policy learning problemto a layer-by-layer weighted binary classification problem. Empirically, theseapproaches yield dramatic reductions in computational cost, with up to a 2.8xspeedup on state-of-the-art networks from the ImageNet image recognitionchallenge with minimal (<1%) loss of top5 accuracy.",Adaptive Neural Networks for Efficient Inference
249,,,,,,"The key idea of variational auto-encoders (VAEs) resembles that oftraditional auto-encoder models in which spatial information is supposed to beexplicitly encoded in the latent space. However, the latent variables in VAEsare vectors, which are commonly interpreted as multiple feature maps of size1x1. Such representations can only convey spatial information implicitly whencoupled with powerful decoders. In this work, we propose spatial VAEs that uselatent variables as feature maps of larger size to explicitly capture spatialinformation. This is achieved by allowing the latent variables to be sampledfrom matrix-variate normal (MVN) distributions whose parameters are computedfrom the encoder network. To increase dependencies among locations on latentfeature maps and reduce the number of parameters, we further propose spatialVAEs via low-rank MVN distributions. Experimental results show that theproposed spatial VAEs outperform original VAEs in capturing rich structural andspatial information.",Spatial Variational Auto-Encoding via Matrix-Variate Normal  Distributions
250,,,,,,"The key idea of current deep learning methods for dense prediction is toapply a model on a regular patch centered on each pixel to make pixel-wisepredictions. These methods are limited in the sense that the patches aredetermined by network architecture instead of learned from data. In this work,we propose the dense transformer networks, which can learn the shapes and sizesof patches from data. The dense transformer networks employ an encoder-decoderarchitecture, and a pair of dense transformer modules are inserted into each ofthe encoder and decoder paths. The novelty of this work is that we providetechnical solutions for learning the shapes and sizes of patches from data andefficiently restoring the spatial correspondence required for dense prediction.The proposed dense transformer modules are differentiable, thus the entirenetwork can be trained. We apply the proposed networks on natural andbiological image segmentation tasks and show superior performance is achievedin comparison to baseline methods.",Dense Transformer Networks
251,,,,,,"We develop an algorithm for systematic design of a large artificial neuralnetwork using a progression property. We find that some non-linear functions,such as the rectifier linear unit and its derivatives, hold the property. Thesystematic design addresses the choice of network size and regularization ofparameters. The number of nodes and layers in network increases in progressionwith the objective of consistently reducing an appropriate cost. Each layer isoptimized at a time, where appropriate parameters are learned using convexoptimization. Regularization parameters for convex optimization do not need asignificant manual effort for tuning. We also use random instances for someweight matrices, and that helps to reduce the number of parameters we learn.The developed network is expected to show good generalization power due toappropriate regularization and use of random weights in the layers. Thisexpectation is verified by extensive experiments for classification andregression problems, using standard databases.",Progressive Learning for Systematic Design of Large Neural Networks
252,Nuclear,,,Nuclear,,"A fundamental, and still largely unanswered, question in the context ofGenerative Adversarial Networks (GANs) is whether GANs are actually able tocapture the key characteristics of the datasets they are trained on. Thecurrent approaches to examining this issue require significant humansupervision, such as visual inspection of sampled images, and often offer onlyfairly limited scalability. In this paper, we propose new techniques thatemploy a classification-based perspective to evaluate synthetic GANdistributions and their capability to accurately reflect the essentialproperties of the training data. These techniques require only minimal humansupervision and can easily be scaled and adapted to evaluate a variety ofstate-of-the-art GANs on large, popular datasets. Our analysis indicates thatGANs have significant problems in reproducing the more distributionalproperties of the training dataset. In particular, when seen through the lensof classification, the diversity of GAN data is orders of magnitude less thanthat of the original data.",A Classification-Based Perspective on GAN Distributions
253,,,,,,"Achieving artificial visual reasoning - the ability to answer image-relatedquestions which require a multi-step, high-level process - is an important steptowards artificial general intelligence. This multi-modal task requireslearning a question-dependent, structured reasoning process over images fromlanguage. Standard deep learning approaches tend to exploit biases in the datarather than learn this underlying structure, while leading methods learn tovisually reason successfully but are hand-crafted for reasoning. We show that ageneral-purpose, Conditional Batch Normalization approach achievesstate-of-the-art results on the CLEVR Visual Reasoning benchmark with a 2.4%error rate. We outperform the next best end-to-end method (4.5%) and evenmethods that use extra supervision (3.1%). We probe our model to shed light onhow it reasons, showing it has learned a question-dependent, multi-stepprocess. Previous work has operated under the assumption that visual reasoningcalls for a specialized architecture, but we show that a general architecturewith proper conditioning can learn to visually reason effectively.",Learning Visual Reasoning Without Strong Priors
254,Chemistry,Chemistry,,,,"Language is increasingly being used to define rich visual recognitionproblems with supporting image collections sourced from the web. Structuredprediction models are used in these tasks to take advantage of correlationsbetween co-occurring labels and visual input but risk inadvertently encodingsocial biases found in web corpora. In this work, we study data and modelsassociated with multilabel object classification and visual semantic rolelabeling. We find that (a) datasets for these tasks contain significant genderbias and (b) models trained on these datasets further amplify existing bias.For example, the activity cooking is over 33% more likely to involve femalesthan males in a training set, and a trained model further amplifies thedisparity to 68% at test time. We propose to inject corpus-level constraintsfor calibrating existing structured prediction models and design an algorithmbased on Lagrangian relaxation for collective inference. Our method results inalmost no performance loss for the underlying recognition task but decreasesthe magnitude of bias amplification by 47.5% and 40.5% for multilabelclassification and visual semantic role labeling, respectively.",Men Also Like Shopping: Reducing Gender Bias Amplification using  Corpus-level Constraints
255,,,,,,"Spatial understanding is a fundamental problem with wide-reaching real-worldapplications. The representation of spatial knowledge is often modeled withspatial templates, i.e., regions of acceptability of two objects under anexplicit spatial relationship (e.g., ""on"", ""below"", etc.). In contrast withprior work that restricts spatial templates to explicit spatial prepositions(e.g., ""glass on table""), here we extend this concept to implicit spatiallanguage, i.e., those relationships (generally actions) for which the spatialarrangement of the objects is only implicitly implied (e.g., ""man ridinghorse""). In contrast with explicit relationships, predicting spatialarrangements from implicit spatial language requires significant common sensespatial understanding. Here, we introduce the task of predicting spatialtemplates for two objects under a relationship, which can be seen as a spatialquestion-answering task with a (2D) continuous output (""where is the man w.r.t.a horse when the man is walking the horse?""). We present two simpleneural-based models that leverage annotated images and structured text to learnthis task. The good performance of these models reveals that spatial locationsare to a large extent predictable from implicit spatial language. Crucially,the models attain similar performance in a challenging generalized setting,where the object-relation-object combinations (e.g.,""man walking dog"") havenever been seen before. Next, we go one step further by presenting the modelswith unseen objects (e.g., ""dog""). In this scenario, we show that leveragingword embeddings enables the models to output accurate spatial predictions,proving that the models acquire solid common sense spatial knowledge allowingfor such generalization.",Acquiring Common Sense Spatial Knowledge through Implicit Spatial  Templates
256,Nuclear,,,Nuclear,,"We introduce a general-purpose conditioning method for neural networks calledFiLM: Feature-wise Linear Modulation. FiLM layers influence neural networkcomputation via a simple, feature-wise affine transformation based onconditioning information. We show that FiLM layers are highly effective forvisual reasoning - answering image-related questions which require amulti-step, high-level process - a task which has proven difficult for standarddeep learning methods that do not explicitly model reasoning. Specifically, weshow on visual reasoning tasks that FiLM layers 1) halve state-of-the-art errorfor the CLEVR benchmark, 2) modulate features in a coherent manner, 3) arerobust to ablations and architectural modifications, and 4) generalize well tochallenging, new data from few examples or even zero-shot.",FiLM: Visual Reasoning with a General Conditioning Layer
257,,,,,,"We introduce a new approach to unsupervised estimation of feature-richsemantic role labeling models. Our model consists of two components: (1) anencoding component: a semantic role labeling model which predicts roles given arich set of syntactic and lexical features; (2) a reconstruction component: atensor factorization model which relies on roles to predict argument fillers.When the components are estimated jointly to minimize errors in argumentreconstruction, the induced roles largely correspond to roles defined inannotated resources. Our method performs on par with most accurate roleinduction methods on English and German, even though, unlike these previousapproaches, we do not incorporate any prior linguistic knowledge about thelanguages.",Unsupervised Induction of Semantic Roles within a Reconstruction-Error  Minimization Framework
258,,,,,,"The blind application of machine learning runs the risk of amplifying biasespresent in data. Such a danger is facing us with word embedding, a popularframework to represent text data as vectors which has been used in many machinelearning and natural language processing tasks. We show that even wordembeddings trained on Google News articles exhibit female/male genderstereotypes to a disturbing extent. This raises concerns because theirwidespread use, as we describe, often tends to amplify these biases.Geometrically, gender bias is first shown to be captured by a direction in theword embedding. Second, gender neutral words are shown to be linearly separablefrom gender definition words in the word embedding. Using these properties, weprovide a methodology for modifying an embedding to remove gender stereotypes,such as the association between between the words receptionist and female,while maintaining desired associations such as between the words queen andfemale. We define metrics to quantify both direct and indirect gender biases inembeddings, and develop algorithms to ""debias"" the embedding. Usingcrowd-worker evaluation as well as standard benchmarks, we empiricallydemonstrate that our algorithms significantly reduce gender bias in embeddingswhile preserving the its useful properties such as the ability to clusterrelated concepts and to solve analogy tasks. The resulting embeddings can beused in applications without amplifying gender bias.",Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word  Embeddings
259,DV,DV,,,,"In this paper, we propose TopicR, a recurrent neural network (RNN)-basedlanguage model designed to directly capture the global semantic meaningrelating words in a document via latent topics. Because of their sequentialnature, RNNs are good at capturing the local structure of a word sequence -both semantic and syntactic - but might face difficulty remembering long-rangedependencies. Intuitively, these long-range dependencies are of semanticnature. In contrast, latent topic models are able to capture the globalunderlying semantic structure of a document but do not account for wordordering. The proposed TopicRNN model integrates the merits of RNNs and latenttopic models: it captures local (syntactic) dependencies using an RNN andglobal (semantic) dependencies using latent topics. Unlike previous work oncontextual RNN language modeling, our model is learned end-to-end. Empiricalresults on word prediction show that TopicRNN outperforms existing contextualRNN baselines. In addition, TopicRNN can be used as an unsupervised featureextractor for documents. We do this for sentiment analysis on the IMDB moviereview dataset and report an error rate of $6.28\%$. This is comparable to thestate-of-the-art $5.91\%$ resulting from a semi-supervised approach. Finally,TopicRNN also yields sensible topics, making it a useful alternative todocument models such as latent Dirichlet allocation.",TopicRNN: A Recurrent Neural Network with Long-Range Semantic Dependency
260,Physics,Physics,,,,"We propose the Gaussian attention model for content-based neural memoryaccess. With the proposed attention model, a neural network has the additionaldegree of freedom to control the focus of its attention from a laser sharpattention to a broad attention. It is applicable whenever we can assume thatthe distance in the latent space reflects some notion of semantics. We use theproposed attention model as a scoring function for the embedding of a knowledgebase into a continuous vector space and then train a model that performsquestion answering about the entities in the knowledge base. The proposedattention model can handle both the propagation of uncertainty when following aseries of relations and also the conjunction of conditions in a natural way. Ona dataset of soccer players who participated in the FIFA World Cup 2014, wedemonstrate that our model can handle both path queries and conjunctive querieswell.",Gaussian Attention Model and Its Application to Knowledge Base Embedding  and Question Answering
261,,,,,,"Recurrent neural networks (RNNs) have been used extensively and withincreasing success to model various types of sequential data. Much of thisprogress has been achieved through devising recurrent units and architectureswith the flexibility to capture complex statistics in the data, such as longrange dependency or localized attention phenomena. However, while manysequential data (such as video, speech or language) can have highly variableinformation flow, most recurrent models still consume input features at aconstant rate and perform a constant number of computations per time step,which can be detrimental to both speed and model capacity. In this paper, weexplore a modification to existing recurrent units which allows them to learnto vary the amount of computation they perform at each step, without priorknowledge of the sequence's time structure. We show experimentally that notonly do our models require fewer operations, they also lead to betterperformance overall on evaluation tasks.",Variable Computation in Recurrent Neural Networks
262,,,,,,"In this paper, we propose a method for training neural networks when we havea large set of data with weak labels and a small amount of data with truelabels. In our proposed model, we train two neural networks: a target network,the learner and a confidence network, the meta-learner. The target network isoptimized to perform a given task and is trained using a large set of unlabeleddata that are weakly annotated. We propose to control the magnitude of thegradient updates to the target network using the scores provided by the secondconfidence network, which is trained on a small amount of supervised data. Thuswe avoid that the weight updates computed from noisy labels harm the quality ofthe target network model.",Learning to Learn from Weak Supervision by Full Supervision
263,Nuclear,Nuclear,,,,"Chemical databases store information in text representations, and the SMILESformat is a universal standard used in many cheminformatics software. Encodedin each SMILES string is structural information that can be used to predictcomplex chemical properties. In this work, we develop SMILES2vec, a deep RNNthat automatically learns features from SMILES to predict chemical properties,without the need for additional explicit feature engineering. Using Bayesianoptimization methods to tune the network architecture, we show that anoptimized SMILES2vec model can serve as a general-purpose neural network forpredicting distinct chemical properties including toxicity, activity,solubility and solvation energy, while also outperforming contemporary MLPneural networks that uses engineered features. Furthermore, we demonstrateproof-of-concept of interpretability by developing an explanation mask thatlocalizes on the most important characters used in making a prediction. Whentested on the solubility dataset, it identified specific parts of a chemicalthat is consistent with established first-principles knowledge with an accuracyof 88%. Our work demonstrates that neural networks can learn technicallyaccurate chemical concept and provide state-of-the-art accuracy, makinginterpretable deep neural networks a useful tool of relevance to the chemicalindustry.",SMILES2Vec: An Interpretable General-Purpose Deep Neural Network for  Predicting Chemical Properties
264,,,,,,"In spoken dialogue systems, we aim to deploy artificial intelligence to buildautomated dialogue agents that can converse with humans. A part of this effortis the policy optimisation task, which attempts to find a policy describing howto respond to humans, in the form of a function taking the current state of thedialogue and returning the response of the system. In this paper, weinvestigate deep reinforcement learning approaches to solve this problem.Particular attention is given to actor-critic methods, off-policy reinforcementlearning with experience replay, and various methods aimed at reducing the biasand variance of estimators. When combined, these methods result in thepreviously proposed ACER algorithm that gave competitive results in gamingenvironments. These environments however are fully observable and have arelatively small action set so in this paper we examine the application of ACERto dialogue policy optimisation. We show that this method beats the currentstate-of-the-art in deep learning approaches for spoken dialogue systems. Thisnot only leads to a more sample efficient algorithm that can train faster, butalso allows us to apply the algorithm in more difficult environments thanbefore. We thus experiment with learning in a very large action space, whichhas two orders of magnitude more actions than previously considered. We findthat ACER trains significantly faster than the current state-of-the-art.",Sample Efficient Deep Reinforcement Learning for Dialogue Systems with  Large Action Spaces
265,DV,DV,,,,"In this paper we explore the ""vector semantics"" problem from the perspectiveof ""almost orthogonal"" property of high-dimensional random vectors. We showthat this intriguing property can be used to ""memorize"" random vectors bysimply adding them, and we provide an efficient probabilistic solution to theset membership problem. Also, we discuss several applications to word contextvector embeddings, document sentences similarity, and spam filtering.",High-Dimensional Vector Semantics
266,Nuclear,,,Nuclear,,"Induction of common sense knowledge about prototypical sequences of eventshas recently received much attention. Instead of inducing this knowledge in theform of graphs, as in much of the previous work, in our method, distributedrepresentations of event realizations are computed based on distributedrepresentations of predicates and their arguments, and then theserepresentations are used to predict prototypical event orderings. Theparameters of the compositional process for computing the event representationsand the ranking component of the model are jointly estimated from texts. Weshow that this approach results in a substantial boost in ordering performancewith respect to previous methods.",Learning Semantic Script Knowledge with Event Embeddings
267,Physics,Physics,,,,"While computer and communication technologies have provided effective meansto scale up many aspects of education, the submission and grading ofassessments such as homework assignments and tests remains a weak link. In thispaper, we study the problem of automatically grading the kinds of open responsemathematical questions that figure prominently in STEM (science, technology,engineering, and mathematics) courses. Our data-driven framework formathematical language processing (MLP) leverages solution data from a largenumber of learners to evaluate the correctness of their solutions, assignpartial-credit scores, and provide feedback to each learner on the likelylocations of any errors. MLP takes inspiration from the success of naturallanguage processing for text data and comprises three main steps. First, weconvert each solution to an open response mathematical question into a seriesof numerical features. Second, we cluster the features from several solutionsto uncover the structures of correct, partially correct, and incorrectsolutions. We develop two different clustering approaches, one that leveragesgeneric clustering algorithms and one based on Bayesian nonparametrics. Third,we automatically grade the remaining (potentially large number of) solutionsbased on their assigned cluster and one instructor-provided grade per cluster.As a bonus, we can track the cluster assignment of each step of a multistepsolution and determine when it departs from a cluster of correct solutions,which enables us to indicate the likely locations of errors to learners. Wetest and validate MLP on real-world MOOC data to demonstrate how it cansubstantially reduce the human effort required in large-scale educationalplatforms.",Mathematical Language Processing: Automatic Grading and Feedback for  Open Response Mathematical Questions
268,,,,,,"Human infants can discover words directly from unsegmented speech signalswithout any explicitly labeled data. In this paper, we develop a novel machinelearning method called nonparametric Bayesian double articulation analyzer(NPB-DAA) that can directly acquire language and acoustic models from observedcontinuous speech signals. For this purpose, we propose an integrativegenerative model that combines a language model and an acoustic model into asingle generative model called the ""hierarchical Dirichlet process hiddenlanguage model"" (HDP-HLM). The HDP-HLM is obtained by extending thehierarchical Dirichlet process hidden semi-Markov model (HDP-HSMM) proposed byJohnson et al. An inference procedure for the HDP-HLM is derived using theblocked Gibbs sampler originally proposed for the HDP-HSMM. This procedureenables the simultaneous and direct inference of language and acoustic modelsfrom continuous speech signals. Based on the HDP-HLM and its inferenceprocedure, we developed a novel double articulation analyzer. By assumingHDP-HLM as a generative model of observed time series data, and by inferringlatent variables of the model, the method can analyze latent doublearticulation structure, i.e., hierarchically organized latent words andphonemes, of the data in an unsupervised manner. The novel unsupervised doublearticulation analyzer is called NPB-DAA.  The NPB-DAA can automatically estimate double articulation structure embeddedin speech signals. We also carried out two evaluation experiments usingsynthetic data and actual human continuous speech signals representing Japanesevowel sequences. In the word acquisition and phoneme categorization tasks, theNPB-DAA outperformed a conventional double articulation analyzer (DAA) andbaseline automatic speech recognition system whose acoustic model was trainedin a supervised manner.",Nonparametric Bayesian Double Articulation Analyzer for Direct Language  Acquisition from Continuous Speech Signals
269,,,,,,"Combining deep neural networks with structured logic rules is desirable toharness flexibility and reduce uninterpretability of the neural models. Wepropose a general framework capable of enhancing various types of neuralnetworks (e.g., CNNs and RNNs) with declarative first-order logic rules.Specifically, we develop an iterative distillation method that transfers thestructured information of logic rules into the weights of neural networks. Wedeploy the framework on a CNN for sentiment analysis, and an RNN for namedentity recognition. With a few highly intuitive rules, we obtain substantialimprovements and achieve state-of-the-art or comparable results to previousbest-performing systems.",Harnessing Deep Neural Networks with Logic Rules
270,,,,,,"Generic generation and manipulation of text is challenging and has limitedsuccess compared to recent deep generative modeling in visual domain. Thispaper aims at generating plausible natural language sentences, whose attributesare dynamically controlled by learning disentangled latent representations withdesignated semantics. We propose a new neural generative model which combinesvariational auto-encoders and holistic attribute discriminators for effectiveimposition of semantic structures. With differentiable approximation todiscrete text samples, explicit constraints on independent attribute controls,and efficient collaborative learning of generator and discriminators, our modellearns highly interpretable representations from even only word annotations,and produces realistic sentences with desired attributes. Quantitativeevaluation validates the accuracy of sentence and attribute generation.",Toward Controlled Generation of Text
271,,,,,,"Implicit discourse relation classification is of great challenge due to thelack of connectives as strong linguistic cues, which motivates the use ofannotated implicit connectives to improve the recognition. We propose a featureimitation framework in which an implicit relation network is driven to learnfrom another neural network with access to connectives, and thus encouraged toextract similarly salient features for accurate classification. We develop anadversarial model to enable an adaptive imitation scheme through competitionbetween the implicit network and a rival feature discriminator. Our methodeffectively transfers discriminability of connectives to the implicit features,and achieves state-of-the-art performance on the PDTB benchmark.",Adversarial Connective-exploiting Networks for Implicit Discourse  Relation Classification
272,,,,,,"Tasks like code generation and semantic parsing require mapping unstructured(or partially structured) inputs to well-formed, executable outputs. Weintroduce abstract syntax networks, a modeling framework for these problems.The outputs are represented as abstract syntax trees (ASTs) and constructed bya decoder with a dynamically-determined modular structure paralleling thestructure of the output tree. On the benchmark Hearthstone dataset for codegeneration, our model obtains 79.2 BLEU and 22.7% exact match accuracy,compared to previous state-of-the-art values of 67.1 and 6.1%. Furthermore, weperform competitively on the Atis, Jobs, and Geo semantic parsing datasets withno task-specific engineering.",Abstract Syntax Networks for Code Generation and Semantic Parsing
273,Data,Data,,,,"Word embeddings provide point representations of words containing usefulsemantic information. We introduce multimodal word distributions formed fromGaussian mixtures, for multiple word meanings, entailment, and rich uncertaintyinformation. To learn these distributions, we propose an energy-basedmax-margin objective. We show that the resulting approach captures uniquelyexpressive semantic information, and outperforms alternatives, such as word2vecskip-grams, and Gaussian embeddings, on benchmark datasets such as wordsimilarity and entailment.",Multimodal Word Distributions
274,,,,,,"In this work we present a technique to use natural language to helpreinforcement learning generalize to unseen environments. This technique usesneural machine translation, specifically the use of encoder-decoder networks,to learn associations between natural language behavior descriptions andstate-action information. We then use this learned model to guide agentexploration using a modified version of policy shaping to make it moreeffective at learning in unseen environments. We evaluate this technique usingthe popular arcade game, Frogger, under ideal and non-ideal conditions. Thisevaluation shows that our modified policy shaping algorithm improves over aQ-learning agent as well as a baseline version of policy shaping.",Guiding Reinforcement Learning Exploration Using Natural Language
275,Data,,,Data,,"We investigate task clustering for deep-learning based multi-task andfew-shot learning in a many-task setting. We propose a new method to measuretask similarities with cross-task transfer performance matrix for the deeplearning scenario. Although this matrix provides us critical informationregarding similarity between tasks, its asymmetric property and unreliableperformance scores can affect conventional clustering methods adversely.Additionally, the uncertain task-pairs, i.e., the ones with extremelyasymmetric transfer scores, may collectively mislead clustering algorithms tooutput an inaccurate task-partition. To overcome these limitations, we proposea novel task-clustering algorithm by using the matrix completion technique. Theproposed algorithm constructs a partially-observed similarity matrix based onthe certainty of cluster membership of the task-pairs. We then use a matrixcompletion algorithm to complete the similarity matrix. Our theoreticalanalysis shows that under mild constraints, the proposed algorithm willperfectly recover the underlying ""true"" similarity matrix with a highprobability. Our results show that the new task clustering method can discovertask clusters for training flexible and superior neural network models in amulti-task learning setup for sentiment classification and dialog intentclassification tasks. Our task clustering approach also extends metric-basedfew-shot learning methods to adapt multiple metrics, which demonstratesempirical advantages when the tasks are diverse.",Robust Task Clustering for Deep Many-Task Learning
276,Physics,Physics,,,,"We train multi-task autoencoders on linguistic tasks and analyze the learnedhidden sentence representations. The representations change significantly whentranslation and part-of-speech decoders are added. The more decoders a modelemploys, the better it clusters sentences according to their syntacticsimilarity, as the representation space becomes less entangled. We explore thestructure of the representation space by interpolating between sentences, whichyields interesting pseudo-English sentences, many of which have recognizablesyntactic structure. Lastly, we point out an interesting property of ourmodels: The difference-vector between two sentences can be added to change athird sentence with similar features in a meaningful way.",Natural Language Multitasking: Analyzing and Improving Syntactic  Saliency of Hidden Representations
277,,,,,,"With the increasing popularity of video sharing websites such as YouTube andFacebook, multimodal sentiment analysis has received increasing attention fromthe scientific community. Contrary to previous works in multimodal sentimentanalysis which focus on holistic information in speech segments such as bag ofwords representations and average facial expression intensity, we develop anovel deep architecture for multimodal sentiment analysis that performsmodality fusion at the word level. In this paper, we propose the GatedMultimodal Embedding LSTM with Temporal Attention (GME-LSTM(A)) model that iscomposed of 2 modules. The Gated Multimodal Embedding alleviates thedifficulties of fusion when there are noisy modalities. The LSTM with TemporalAttention performs word level fusion at a finer fusion resolution between inputmodalities and attends to the most important time steps. As a result, theGME-LSTM(A) is able to better model the multimodal structure of speech throughtime and perform better sentiment comprehension. We demonstrate theeffectiveness of this approach on the publicly-available Multimodal Corpus ofSentiment Intensity and Subjectivity Analysis (CMU-MOSI) dataset by achievingstate-of-the-art sentiment classification and regression results. Qualitativeanalysis on our model emphasizes the importance of the Temporal Attention Layerin sentiment prediction because the additional acoustic and visual modalitiesare noisy. We also demonstrate the effectiveness of the Gated MultimodalEmbedding in selectively filtering these noisy modalities out. Our results andanalysis open new areas in the study of sentiment analysis in humancommunication and provide new models for multimodal fusion.",Multimodal Sentiment Analysis with Word-Level Fusion and Reinforcement  Learning
278,,,,,,"Automatic summarisation is a popular approach to reduce a document to itsmain arguments. Recent research in the area has focused on neural approaches tosummarisation, which can be very data-hungry. However, few large datasets existand none for the traditionally popular domain of scientific publications, whichopens up challenging research avenues centered on encoding large, complexdocuments. In this paper, we introduce a new dataset for summarisation ofcomputer science publications by exploiting a large resource of author providedsummaries and show straightforward ways of extending it further. We developmodels on the dataset making use of both neural sentence encoding andtraditionally used summarisation features and show that models which encodesentences as well as their local and global context perform best, significantlyoutperforming well-established baseline methods.",A Supervised Approach to Extractive Summarisation of Scientific Papers
279,,,,,,"Two recent approaches have achieved state-of-the-art results in imagecaptioning. The first uses a pipelined process where a set of candidate wordsis generated by a convolutional neural network (CNN) trained on images, andthen a maximum entropy (ME) language model is used to arrange these words intoa coherent sentence. The second uses the penultimate activation layer of theCNN as input to a recurrent neural network (RNN) that then generates thecaption sequence. In this paper, we compare the merits of these differentlanguage modeling approaches for the first time by using the samestate-of-the-art CNN as input. We examine issues in the different approaches,including linguistic irregularities, caption repetition, and data set overlap.By combining key aspects of the ME and RNN methods, we achieve a new recordperformance over previously published results on the benchmark COCO dataset.However, the gains we see in BLEU do not translate to human judgments.",Language Models for Image Captioning: The Quirks and What Works
280,Data,,,Data,,"This work aims to address the problem of image-based question-answering (QA)with new models and datasets. In our work, we propose to use neural networksand visual semantic embeddings, without intermediate stages such as objectdetection and image segmentation, to predict answers to simple questions aboutimages. Our model performs 1.8 times better than the only published results onan existing image QA dataset. We also present a question generation algorithmthat converts image descriptions, which are widely available, into QA form. Weused this algorithm to produce an order-of-magnitude larger dataset, with moreevenly distributed answers. A suite of baseline results on this new dataset arealso presented.",Exploring Models and Data for Image Question Answering
281,,,,,,"Problems at the intersection of vision and language are of significantimportance both as challenging research questions and for the rich set ofapplications they enable. However, inherent structure in our world and bias inour language tend to be a simpler signal for learning than visual modalities,resulting in models that ignore visual information, leading to an inflatedsense of their capability.  We propose to counter these language priors for the task of Visual QuestionAnswering (VQA) and make vision (the V in VQA) matter! Specifically, we balancethe popular VQA dataset by collecting complementary images such that everyquestion in our balanced dataset is associated with not just a single image,but rather a pair of similar images that result in two different answers to thequestion. Our dataset is by construction more balanced than the original VQAdataset and has approximately twice the number of image-question pairs. Ourcomplete balanced dataset is publicly available at www.visualqa.org as part ofthe 2nd iteration of the Visual Question Answering Dataset and Challenge (VQAv2.0).  We further benchmark a number of state-of-art VQA models on our balanceddataset. All models perform significantly worse on our balanced dataset,suggesting that these models have indeed learned to exploit language priors.This finding provides the first concrete empirical evidence for what seems tobe a qualitative sense among practitioners.  Finally, our data collection protocol for identifying complementary imagesenables us to develop a novel interpretable model, which in addition toproviding an answer to the given (image, question) pair, also provides acounter-example based explanation. Specifically, it identifies an image that issimilar to the original image, but it believes has a different answer to thesame question. This can help in building trust for machines among their users.",Making the V in VQA Matter: Elevating the Role of Image Understanding in  Visual Question Answering
282,DV,DV,,,,"We propose a method for automatically answering questions about images bybringing together recent advances from natural language processing and computervision. We combine discrete reasoning with uncertain predictions by amulti-world approach that represents uncertainty about the perceived world in abayesian framework. Our approach can handle human questions of high complexityabout realistic scenes and replies with range of answer like counts, objectclasses, instances and lists of them. The system is directly trained fromquestion-answer pairs. We establish a first benchmark for this task that can beseen as a modern attempt at a visual turing test.",A Multi-World Approach to Question Answering about Real-World Scenes  based on Uncertain Input
283,Physics,Physics,,,,"Progress in language and image understanding by machines has sparkled theinterest of the research community in more open-ended, holistic tasks, andrefueled an old AI dream of building intelligent machines. We discuss a fewprominent challenges that characterize such holistic tasks and argue for""question answering about images"" as a particular appealing instance of such aholistic task. In particular, we point out that it is a version of a TuringTest that is likely to be more robust to over-interpretations and contrast itwith tasks like grounding and generation of descriptions. Finally, we discusstools to measure progress in this field.",Hard to Cheat: A Turing Test based on Answering Questions about Images
284,,,,,,"Recently, a number of deep-learning based models have been proposed for thetask of Visual Question Answering (VQA). The performance of most models isclustered around 60-70%. In this paper we propose systematic methods to analyzethe behavior of these models as a first step towards recognizing theirstrengths and weaknesses, and identifying the most fruitful directions forprogress. We analyze two models, one each from two major classes of VQA models-- with-attention and without-attention and show the similarities anddifferences in the behavior of these models. We also analyze the winning entryof the VQA Challenge 2016.  Our behavior analysis reveals that despite recent progress, today's VQAmodels are ""myopic"" (tend to fail on sufficiently novel instances), often ""jumpto conclusions"" (converge on a predicted answer after 'listening' to just halfthe question), and are ""stubborn"" (do not change their answers across images).",Analyzing the Behavior of Visual Question Answering Models
285,,,,,,"Temporal common sense has applications in AI tasks such as QA, multi-documentsummarization, and human-AI communication. We propose the task of sequencing --given a jumbled set of aligned image-caption pairs that belong to a story, thetask is to sort them such that the output sequence forms a coherent story. Wepresent multiple approaches, via unary (position) and pairwise (order)predictions, and their ensemble-based combinations, achieving strong results onthis task. We use both text-based and image-based features, which depictcomplementary improvements. Using qualitative examples, we demonstrate that ourmodels have learnt interesting aspects of temporal common sense.",Sort Story: Sorting Jumbled Images and Captions into Stories
286,,,,,,"We present Mean Box Pooling, a novel visual representation that pools overCNN representations of a large number, highly overlapping object proposals. Weshow that such representation together with nCCA, a successful multimodalembedding technique, achieves state-of-the-art performance on the VisualMadlibs task. Moreover, inspired by the nCCA's objective function, we extendclassical CNN+LSTM approach to train the network by directly maximizing thesimilarity between the internal representation of the deep learningarchitecture and candidate answers. Again, such approach achieves a significantimprovement over the prior work that also uses CNN+LSTM approach on VisualMadlibs.",Mean Box Pooling: A Rich Image Representation and Output Embedding for  the Visual Madlibs Task
287,Data,Data,,,,"Recurrent neural networks have recently been used for learning to describeimages using natural language. However, it has been observed that these modelsgeneralize poorly to scenes that were not observed during training, possiblydepending too strongly on the statistics of the text in the training data. Herewe propose to describe images using short structured representations, aiming tocapture the crux of a description. These structured representations allow us totease-out and evaluate separately two types of generalization: standardgeneralization to new images with similar scenes, and generalization to newcombinations of known entities. We compare two learning approaches on theMS-COCO dataset: a state-of-the-art recurrent network based on an LSTM (Show,Attend and Tell), and a simple structured prediction model on top of a deepnetwork. We find that the structured model generalizes to new compositionssubstantially better than the LSTM, ~7 times the accuracy of predictingstructured representations. By providing a concrete method to quantifygeneralization for unseen combinations, we argue that structuredrepresentations and compositional splits are a useful benchmark for imagecaptioning, and advocate compositional models that capture linguistic andvisual structure.",Learning to generalize to new compositions in image understanding
288,Data,,,Data,,"As machines have become more intelligent, there has been a renewed interestin methods for measuring their intelligence. A common approach is to proposetasks for which a human excels, but one which machines find difficult. However,an ideal task should also be easy to evaluate and not be easily gameable. Webegin with a case study exploring the recently popular task of image captioningand its limitations as a task for measuring machine intelligence. Analternative and more promising task is Visual Question Answering that tests amachine's ability to reason about language and vision. We describe a datasetunprecedented in size created for the task that contains over 760,000 humangenerated questions about images. Using around 10 million human generatedanswers, machines may be easily evaluated.",Measuring Machine Intelligence Through Visual Question Answering
289,,,,,,"Deep neural networks have shown striking progress and obtainedstate-of-the-art results in many AI research fields in the recent years.However, it is often unsatisfying to not know why they predict what they do. Inthis paper, we address the problem of interpreting Visual Question Answering(VQA) models. Specifically, we are interested in finding what part of the input(pixels in images or words in questions) the VQA model focuses on whileanswering the question. To tackle this problem, we use two visualizationtechniques -- guided backpropagation and occlusion -- to find important wordsin the question and important regions in the image. We then present qualitativeand quantitative analyses of these importance maps. We found that even withoutexplicit attention mechanisms, VQA models may sometimes be implicitly attendingto relevant regions in the image, and often to appropriate words in thequestion.",Towards Transparent AI Systems: Interpreting Visual Question Answering  Models
290,Physics,Physics,,,,"We introduce the task of Visual Dialog, which requires an AI agent to hold ameaningful dialog with humans in natural, conversational language about visualcontent. Specifically, given an image, a dialog history, and a question aboutthe image, the agent has to ground the question in image, infer context fromhistory, and answer the question accurately. Visual Dialog is disentangledenough from a specific downstream task so as to serve as a general test ofmachine intelligence, while being grounded in vision enough to allow objectiveevaluation of individual responses and benchmark progress. We develop a noveltwo-person chat data-collection protocol to curate a large-scale Visual Dialogdataset (VisDial). VisDial v0.9 has been released and contains 1 dialog with 10question-answer pairs on ~120k images from COCO, with a total of ~1.2M dialogquestion-answer pairs.  We introduce a family of neural encoder-decoder models for Visual Dialog with3 encoders -- Late Fusion, Hierarchical Recurrent Encoder and Memory Network --and 2 decoders (generative and discriminative), which outperform a number ofsophisticated baselines. We propose a retrieval-based evaluation protocol forVisual Dialog where the AI agent is asked to sort a set of candidate answersand evaluated on metrics such as mean-reciprocal-rank of human response. Wequantify gap between machine and human performance on the Visual Dialog taskvia human studies. Putting it all together, we demonstrate the first 'visualchatbot'! Our dataset, code, trained models and visual chatbot are available onhttps://visualdialog.org",Visual Dialog
291,,,,,,"Multi-task learning (MTL) involves the simultaneous training of two or morerelated tasks over shared representations. In this work, we apply MTL toaudio-visual automatic speech recognition(AV-ASR). Our primary task is to learna mapping between audio-visual fused features and frame labels obtained fromacoustic GMM/HMM model. This is combined with an auxiliary task which mapsvisual features to frame labels obtained from a separate visual GMM/HMM model.The MTL model is tested at various levels of babble noise and the results arecompared with a base-line hybrid DNN-HMM AV-ASR model. Our results indicatethat MTL is especially useful at higher level of noise. Compared to base-line,upto 7\% relative improvement in WER is reported at -3 SNR dB",Multi-task Learning Of Deep Neural Networks For Audio Visual Automatic  Speech Recognition
292,Nuclear,,,Nuclear,,"We introduce the first goal-driven training for visual question answering anddialog agents. Specifically, we pose a cooperative 'image guessing' gamebetween two agents -- Qbot and Abot -- who communicate in natural languagedialog so that Qbot can select an unseen image from a lineup of images. We usedeep reinforcement learning (RL) to learn the policies of these agentsend-to-end -- from pixels to multi-agent multi-round dialog to game reward.  We demonstrate two experimental results.  First, as a 'sanity check' demonstration of pure RL (from scratch), we showresults on a synthetic world, where the agents communicate in ungroundedvocabulary, i.e., symbols with no pre-specified meanings (X, Y, Z). We findthat two bots invent their own communication protocol and start using certainsymbols to ask/answer about certain visual attributes (shape/color/style).Thus, we demonstrate the emergence of grounded language and communication among'visual' dialog agents with no human supervision.  Second, we conduct large-scale real-image experiments on the VisDial dataset,where we pretrain with supervised dialog data and show that the RL 'fine-tuned'agents significantly outperform SL agents. Interestingly, the RL Qbot learns toask questions that Abot is good at, ultimately resulting in more informativedialog and a better team.",Learning Cooperative Visual Dialog Agents with Deep Reinforcement  Learning
293,Nuclear,,,Nuclear,,"Visual question answering (QA) has attracted a lot of attention lately, seenessentially as a form of (visual) Turing test that artificial intelligenceshould strive to achieve. In this paper, we study a crucial component of thistask: how can we design good datasets for the task? We focus on the design ofmultiple-choice based datasets where the learner has to select the right answerfrom a set of candidate ones including the target (i.e. the correct one) andthe decoys (i.e. the incorrect ones). Through careful analysis of the resultsattained by state-of-the-art learning models and human annotators on existingdatasets, we show the design of the decoy answers has a significant impact onhow and what the learning models learn from the datasets. In particular, theresulting learner can ignore the visual information, the question, or the bothwhile still doing well on the task. Inspired by this, we propose automaticprocedures to remedy such design deficiencies. We apply the procedures tore-construct decoy answers for two popular visual QA datasets as well as tocreate a new visual QA dataset from the Visual Genome project, resulting in thelargest dataset for this task. Extensive empirical studies show that the designdeficiencies have been alleviated in the remedied datasets and the performanceon them is likely a more faithful indicator of the difference among learningmodels. The datasets are released and publicly available viahttp://www.teds.usc.edu/website_vqa/.",Being Negative but Constructively: Lessons Learnt from Creating Better  Visual Question Answering Datasets
294,,,,,,"Visual Question Answering (VQA) has received a lot of attention over the pastcouple of years. A number of deep learning models have been proposed for thistask. However, it has been shown that these models are heavily driven bysuperficial correlations in the training data and lack compositionality -- theability to answer questions about unseen compositions of seen concepts. Thiscompositionality is desirable and central to intelligence. In this paper, wepropose a new setting for Visual Question Answering where the testquestion-answer pairs are compositionally novel compared to trainingquestion-answer pairs. To facilitate developing models under this setting, wepresent a new compositional split of the VQA v1.0 dataset, which we callCompositional VQA (C-VQA). We analyze the distribution of questions and answersin the C-VQA splits. Finally, we evaluate several existing VQA models underthis new setting and show that the performances of these models degrade by asignificant amount compared to the original VQA setting.",C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0  Dataset
295,DV,DV,,,,"We discuss problems with the standard approaches to evaluation for tasks likevisual question answering, and argue that artificial data can be used toaddress these as a complement to current practice. We demonstrate that with thehelp of existing 'deep' linguistic processing technology we are able to createchallenging abstract datasets, which enable us to investigate the languageunderstanding abilities of multimodal deep learning models in detail.",Deep learning evaluation using deep linguistic processing
296,,,,,,"We propose a simple yet effective technique for neural network learning. Theforward propagation is computed as usual. In back propagation, only a smallsubset of the full gradient is computed to update the model parameters. Thegradient vectors are sparsified in such a way that only the top-$k$ elements(in terms of magnitude) are kept. As a result, only $k$ rows or columns(depending on the layout) of the weight matrix are modified, leading to alinear reduction ($k$ divided by the vector dimension) in the computationalcost. Surprisingly, experimental results demonstrate that we can update only1--4\% of the weights at each back propagation pass. This does not result in alarger number of training iterations. More interestingly, the accuracy of theresulting models is actually improved rather than degraded, and a detailedanalysis is given. The code is available at https://github.com/jklj077/meProp",meProp: Sparsified Back Propagation for Accelerated Deep Learning with  Reduced Overfitting
297,,,,,,"Adversarial samples are strategically modified samples, which are craftedwith the purpose of fooling a classifier at hand. An attacker introducesspecially crafted adversarial samples to a deployed classifier, which are beingmis-classified by the classifier. However, the samples are perceived to bedrawn from entirely different classes and thus it becomes hard to detect theadversarial samples. Most of the prior works have been focused on synthesizingadversarial samples in the image domain. In this paper, we propose a new methodof crafting adversarial text samples by modification of the original samples.Modifications of the original text samples are done by deleting or replacingthe important or salient words in the text or by introducing new words in thetext sample. Our algorithm works best for the datasets which havesub-categories within each of the classes of examples. While craftingadversarial samples, one of the key constraint is to generate meaningfulsentences which can at pass off as legitimate from language (English)viewpoint. Experimental results on IMDB movie review dataset for sentimentanalysis and Twitter dataset for gender detection show the efficiency of ourproposed method.",Towards Crafting Text Adversarial Samples
298,,,,,,"Sequence-to-sequence models have shown promising improvements on the temporaltask of video captioning, but they optimize word-level cross-entropy lossduring training. First, using policy gradient and mixed-loss methods forreinforcement learning, we directly optimize sentence-level task-based metrics(as rewards), achieving significant improvements over the baseline, based onboth automatic metrics and human evaluation on multiple datasets. Next, wepropose a novel entailment-enhanced reward (CIDEnt) that correctsphrase-matching based metrics (such as CIDEr) to only allow forlogically-implied partial matches and avoid contradictions, achieving furthersignificant improvements over the CIDEr-reward model. Overall, ourCIDEnt-reward model achieves the new state-of-the-art on the MSR-VTT dataset.",Reinforced Video Captioning with Entailment Rewards
299,,,,,,"We address the problem of end-to-end visual storytelling. Given a photoalbum, our model first selects the most representative (summary) photos, andthen composes a natural language story for the album. For this task, we makeuse of the Visual Storytelling dataset and a model composed of threehierarchically-attentive Recurrent Neural Nets (RNNs) to: encode the albumphotos, select representative (summary) photos, and compose the story.Automatic and human evaluations show our model achieves better performance onselection, generation, and retrieval than baselines.",Hierarchically-Attentive RNN for Album Summarization and Storytelling
300,,,,,,"Due to their complex nature, it is hard to characterize the ways in whichmachine learning models can misbehave or be exploited when deployed. Recentwork on adversarial examples, i.e. inputs with minor perturbations that resultin substantially different model predictions, is helpful in evaluating therobustness of these models by exposing the adversarial scenarios where theyfail. However, these malicious perturbations are often unnatural, notsemantically meaningful, and not applicable to complicated domains such aslanguage. In this paper, we propose a framework to generate natural and legibleadversarial examples that lie on the data manifold, by searching in semanticspace of dense and continuous data representation, utilizing the recentadvances in generative adversarial networks. We present generated adversariesto demonstrate the potential of the proposed approach for black-box classifiersfor a wide range of applications such as image classification, textualentailment, and machine translation. We include experiments to show that thegenerated adversaries are natural, legible to humans, and useful in evaluatingand analyzing black-box classifiers.",Generating Natural Adversarial Examples
301,,,,,,"We propose a simple yet effective technique to simplify the training and theresulting model of neural networks. In back propagation, only a small subset ofthe full gradient is computed to update the model parameters. The gradientvectors are sparsified in such a way that only the top-$k$ elements (in termsof magnitude) are kept. As a result, only $k$ rows or columns (depending on thelayout) of the weight matrix are modified, leading to a linear reduction in thecomputational cost. Based on the sparsified gradients, we further simplify themodel by eliminating the rows or columns that are seldom updated, which willreduce the computational cost both in the training and decoding, andpotentially accelerate decoding in real-world applications. Surprisingly,experimental results demonstrate that most of time we only need to update fewerthan 5% of the weights at each back propagation pass. More interestingly, theaccuracy of the resulting models is actually improved rather than degraded, anda detailed analysis is given. The model simplification results show that wecould adaptively simplify the model which could often be reduced by around 9x,without any loss on accuracy or even with improved accuracy.",Training Simplification and Model Simplification for Deep Learning: A  Minimal Effort Back Propagation Method
302,,,,,,"We present a new AI task -- Embodied Question Answering (EmbodiedQA) -- wherean agent is spawned at a random location in a 3D environment and asked aquestion (""What color is the car?""). In order to answer, the agent must firstintelligently navigate to explore the environment, gather information throughfirst-person (egocentric) vision, and then answer the question (""orange"").  This challenging task requires a range of AI skills -- active perception,language understanding, goal-driven navigation, commonsense reasoning, andgrounding of language into actions. In this work, we develop the environments,end-to-end-trained reinforcement learning agents, and evaluation protocols forEmbodiedQA.",Embodied Question Answering
303,Nuclear,,,Nuclear,,"A number of studies have found that today's Visual Question Answering (VQA)models are heavily driven by superficial correlations in the training data andlack sufficient image grounding. To encourage development of models gearedtowards the latter, we propose a new setting for VQA where for every questiontype, train and test sets have different prior distributions of answers.Specifically, we present new splits of the VQA v1 and VQA v2 datasets, which wecall Visual Question Answering under Changing Priors (VQA-CP v1 and VQA-CP v2respectively). First, we evaluate several existing VQA models under this newsetting and show that their performance degrades significantly compared to theoriginal VQA setting. Second, we propose a novel Grounded Visual QuestionAnswering model (GVQA) that contains inductive biases and restrictions in thearchitecture specifically designed to prevent the model from 'cheating' byprimarily relying on priors in the training data. Specifically, GVQA explicitlydisentangles the recognition of visual concepts present in the image from theidentification of plausible answer space for a given question, enabling themodel to more robustly generalize across different distributions of answers.GVQA is built off an existing VQA model -- Stacked Attention Networks (SAN).Our experiments demonstrate that GVQA significantly outperforms SAN on bothVQA-CP v1 and VQA-CP v2 datasets. Interestingly, it also outperforms morepowerful VQA models such as Multimodal Compact Bilinear Pooling (MCB) inseveral cases. GVQA offers strengths complementary to SAN when trained andevaluated on the original VQA v1 and VQA v2 datasets. Finally, GVQA is moretransparent and interpretable than existing VQA models.",Don't Just Assume; Look and Answer: Overcoming Priors for Visual  Question Answering
304,Physics,Physics,,,,"In this work, we propose a goal-driven collaborative task that containsvision, language, and action in a virtual environment as its core components.Specifically, we develop a collaborative `Image Drawing' game between twoagents, called CoDraw. Our game is grounded in a virtual world that containsmovable clip art objects. Two players, Teller and Drawer, are involved. TheTeller sees an abstract scene containing multiple clip arts in a semanticallymeaningful configuration, while the Drawer tries to reconstruct the scene on anempty canvas using available clip arts. The two players communicate via two-waycommunication using natural language. We collect the CoDraw dataset of ~10Kdialogs consisting of 138K messages exchanged between a Teller and a Drawerfrom Amazon Mechanical Turk (AMT). We analyze our dataset and present threemodels to model the players' behaviors, including an attention model todescribe and draw multiple clip arts at each round. The attention models arequantitatively compared to the other models to show how the conventionalapproaches work for this new task. We also present qualitative visualizations.",CoDraw: Visual Dialog for Collaborative Drawing
305,,,,,,"Goal-oriented dialogue has been paid attention for its numerous applicationsin artificial intelligence. To solve this task, deep learning and reinforcementlearning have recently been applied. However, these approaches struggle to finda competent recurrent neural questioner, owing to the complexity of learning aseries of sentences. Motivated by theory of mind, we propose ""Answerer inQuestioner's Mind"" (AQM), a novel algorithm for goal-oriented dialogue. WithAQM, a questioner asks and infers based on an approximated probabilistic modelof the answerer. The questioner figures out the answerer's intent via selectinga plausible question by explicitly calculating the information gain of thecandidate intentions and possible answers to each question. We test ourframework on two goal-oriented visual dialogue tasks: ""MNIST Counting Dialog""and ""GuessWhat?!."" In our experiments, AQM outperforms comparative algorithmsand makes human-like dialogue. We further use AQM as a tool for analyzing themechanism of deep reinforcement learning approach and discuss the futuredirection of practical goal-oriented neural dialogue systems.",Answerer in Questioner's Mind for Goal-Oriented Visual Dialogue
306,,,,,,"We study the problem of structured prediction under test-time budgetconstraints. We propose a novel approach applicable to a wide range ofstructured prediction problems in computer vision and natural languageprocessing. Our approach seeks to adaptively generate computationally costlyfeatures during test-time in order to reduce the computational cost ofprediction while maintaining prediction performance. We show that training theadaptive feature generation system can be reduced to a series of structuredlearning problems, resulting in efficient training using existing structuredlearning algorithms. This framework provides theoretical justification forseveral existing heuristic approaches found in literature. We evaluate ourproposed adaptive system on two structured prediction tasks, optical characterrecognition (OCR) and dependency parsing and show strong performance inreduction of the feature costs without degrading accuracy.",Resource Constrained Structured Prediction
307,Nuclear,Nuclear,,,,"We propose a neural sequence-to-sequence model for direction following, atask that is essential to realizing effective autonomous agents. Ouralignment-based encoder-decoder model with long short-term memory recurrentneural networks (LSTM-RNN) translates natural language instructions to actionsequences based upon a representation of the observable world state. Weintroduce a multi-level aligner that empowers our model to focus on sentence""regions"" salient to the current world state by using multiple abstractions ofthe input sentence. In contrast to existing methods, our model uses nospecialized linguistic resources (e.g., parsers) or task-specific annotations(e.g., seed lexicons). It is therefore generalizable, yet still achieves thebest results reported to-date on a benchmark single-sentence dataset andcompetitive results for the limited-training multi-sentence setting. We analyzeour model through a series of ablations that elucidate the contributions of theprimary components of our model.","Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to  Action Sequences"
308,Physics,Physics,,,,"Building neural networks to query a knowledge base (a table) with naturallanguage is an emerging research topic in deep learning. An executor for tablequerying typically requires multiple steps of execution because queries mayhave complicated structures. In previous studies, researchers have developedeither fully distributed executors or symbolic executors for table querying. Adistributed executor can be trained in an end-to-end fashion, but is weak interms of execution efficiency and explicit interpretability. A symbolicexecutor is efficient in execution, but is very difficult to train especiallyat initial stages. In this paper, we propose to couple distributed and symbolicexecution for natural language queries, where the symbolic executor ispretrained with the distributed executor's intermediate execution results in astep-by-step fashion. Experiments show that our approach significantlyoutperforms both distributed and symbolic executors, exhibiting high accuracy,high learning efficiency, high execution efficiency, and high interpretability.",Coupling Distributed and Symbolic Execution for Natural Language Queries
309,,,,,,"Due to the huge availability of documents in digital form, and the deceptionpossibility raise bound to the essence of digital documents and the way theyare spread, the authorship attribution problem has constantly increased itsrelevance. Nowadays, authorship attribution,for both information retrieval andanalysis, has gained great importance in the context of security, trust andcopyright preservation. This work proposes an innovative multi-agent drivenmachine learning technique that has been developed for authorship attribution.By means of a preprocessing for word-grouping and time-period related analysisof the common lexicon, we determine a bias reference level for the recurrencefrequency of the words within analysed texts, and then train a Radial BasisNeural Networks (RBPNN)-based classifier to identify the correct author. Themain advantage of the proposed approach lies in the generality of the semanticanalysis, which can be applied to different contexts and lexical domains,without requiring any modification. Moreover, the proposed system is able toincorporate an external input, meant to tune the classifier, and thenself-adjust by means of continuous learning reinforcement.",An agent-driven semantical identifier using radial basis neural networks  and reinforcement learning
310,,,,,,"Humans and animals are constantly exposed to a continuous stream of sensoryinformation from different modalities. At the same time, they form morecompressed representations like concepts or symbols. In species that uselanguage, this process is further structured by this interaction, where amapping between the sensorimotor concepts and linguistic elements needs to beestablished. There is evidence that children might be learning language bysimply disambiguating potential meanings based on multiple exposures toutterances in different contexts (cross-situational learning). In existingmodels, the mapping between modalities is usually found in a single step bydirectly using frequencies of referent and meaning co-occurrences. In thispaper, we present an extension of this one-step mapping and introduce a newlyproposed sequential mapping algorithm together with a publicly available Matlabimplementation. For demonstration, we have chosen a less typical scenario:instead of learning to associate objects with their names, we focus on bodyrepresentations. A humanoid robot is receiving tactile stimulations on itsbody, while at the same time listening to utterances of the body part names(e.g., hand, forearm and torso). With the goal at arriving at the correct ""bodycategories"", we demonstrate how a sequential mapping algorithm outperformsone-step mapping. In addition, the effect of data set size and noise in thelinguistic input are studied.",Where is my forearm? Clustering of body parts from simultaneous tactile  and linguistic input using sequential mapping
311,DV,DV,,,,"Deep Convolutional Neural Networks (CNNs) are more powerful than Deep NeuralNetworks (DNN), as they are able to better reduce spectral variation in theinput signal. This has also been confirmed experimentally, with CNNs showingimprovements in word error rate (WER) between 4-12% relative compared to DNNsacross a variety of LVCSR tasks. In this paper, we describe different methodsto further improve CNN performance. First, we conduct a deep analysis comparinglimited weight sharing and full weight sharing with state-of-the-art features.Second, we apply various pooling strategies that have shown improvements incomputer vision to an LVCSR speech task. Third, we introduce a method toeffectively incorporate speaker adaptation, namely fMLLR, into log-melfeatures. Fourth, we introduce an effective strategy to use dropout duringHessian-free sequence training. We find that with these improvements,particularly with fMLLR and dropout, we are able to achieve an additional 2-3%relative improvement in WER on a 50-hour Broadcast News task over our previousbest CNN baseline. On a larger 400-hour BN task, we find an additional 4-5%relative improvement over our previous best CNN baseline.",Improvements to deep convolutional neural networks for LVCSR
312,Physics,Physics,,,,"Collaborative filtering (CF) is a successful approach commonly used by manyrecommender systems. Conventional CF-based methods use the ratings given toitems by users as the sole source of information for learning to makerecommendation. However, the ratings are often very sparse in manyapplications, causing CF-based methods to degrade significantly in theirrecommendation performance. To address this sparsity problem, auxiliaryinformation such as item content information may be utilized. Collaborativetopic regression (CTR) is an appealing recent method taking this approach whichtightly couples the two components that learn from two different sources ofinformation. Nevertheless, the latent representation learned by CTR may not bevery effective when the auxiliary information is very sparse. To address thisproblem, we generalize recent advances in deep learning from i.i.d. input tonon-i.i.d. (CF-based) input and propose in this paper a hierarchical Bayesianmodel called collaborative deep learning (CDL), which jointly performs deeprepresentation learning for the content information and collaborative filteringfor the ratings (feedback) matrix. Extensive experiments on three real-worlddatasets from different domains show that CDL can significantly advance thestate of the art.",Collaborative Deep Learning for Recommender Systems
313,Physics,Physics,,,,"Layer-wise relevance propagation (LRP) is a recently proposed technique forexplaining predictions of complex non-linear classifiers in terms of inputvariables. In this paper, we apply LRP for the first time to natural languageprocessing (NLP). More precisely, we use it to explain the predictions of aconvolutional neural network (CNN) trained on a topic categorization task. Ouranalysis highlights which words are relevant for a specific prediction of theCNN. We compare our technique to standard sensitivity analysis, bothqualitatively and quantitatively, using a ""word deleting"" perturbationexperiment, a PCA analysis, and various visualizations. All experimentsvalidate the suitability of LRP for explaining the CNN predictions, which isalso in line with results reported in recent image classification studies.",Explaining Predictions of Non-Linear Classifiers in NLP
314,Physics,Physics,,,,"We propose a new statistical model suitable for machine learning of systemswith long distance correlations such as natural languages. The model is basedon directed acyclic graph decorated by multi-linear tensor maps in the verticesand vector spaces in the edges, called tensor network. Such tensor networkshave been previously employed for effective numerical computation of therenormalization group flow on the space of effective quantum field theories andlattice models of statistical mechanics. We provide explicit algebro-geometricanalysis of the parameter moduli space for tree graphs, discuss modelproperties and applications such as statistical translation.",Tensor network language model
315,Physics,Physics,,,,"We propose a statistical model for natural language that begins byconsidering language as a monoid, then representing it in complex matrices witha compatible translation invariant probability measure. We interpret theprobability measure as arising via the Born rule from a translation invariantmatrix product state.",Language as a matrix product state
316,,,,,,"Hessian-free training has become a popular parallel second or- deroptimization technique for Deep Neural Network training. This study aims atspeeding up Hessian-free training, both by means of decreasing the amount ofdata used for training, as well as through reduction of the number of Krylovsubspace solver iterations used for implicit estimation of the Hessian. In thispaper, we develop an L-BFGS based preconditioning scheme that avoids the needto access the Hessian explicitly. Since L-BFGS cannot be regarded as afixed-point iteration, we further propose the employment of flexible Krylovsubspace solvers that retain the desired theoretical convergence guarantees oftheir conventional counterparts. Second, we propose a new sampling algorithm,which geometrically increases the amount of data utilized for gradient andKrylov subspace iteration calculations. On a 50-hr English Broadcast News task,we find that these methodologies provide roughly a 1.5x speed-up, whereas, on a300-hr Switchboard task, these techniques provide over a 2.3x speedup, with noloss in WER. These results suggest that even further speed-up is expected, asproblems scale and complexity grows.",Accelerating Hessian-free optimization for deep neural networks by  implicit preconditioning and sampling
317,Nuclear,Nuclear,,,,"While textual reviews have become prominent in many recommendation-basedsystems, automated frameworks to provide relevant visual cues against textreviews where pictures are not available is a new form of task confronted bydata mining and machine learning researchers. Suggestions of pictures that arerelevant to the content of a review could significantly benefit the users byincreasing the effectiveness of a review. We propose a deep learning-basedframework to automatically: (1) tag the images available in a review dataset,(2) generate a caption for each image that does not have one, and (3) enhanceeach review by recommending relevant images that might not be uploaded by thecorresponding reviewer. We evaluate the proposed framework using the YelpChallenge Dataset. While a subset of the images in this particular dataset arecorrectly captioned, the majority of the pictures do not have any associatedtext. Moreover, there is no mapping between reviews and images. Each image hasa corresponding business-tag where the picture was taken, though. The overalldata setting and unavailability of crucial pieces required for a mapping makethe problem of recommending images for reviews a major challenge. Qualitativeand quantitative evaluations indicate that our proposed framework provides highquality enhancements through automatic captioning, tagging, and recommendationfor mapping reviews and images.",Is a Picture Worth Ten Thousand Words in a Review Dataset?
318,,,,,,"Linear principal component analysis (PCA) can be extended to a nonlinear PCAby using artificial neural networks. But the benefit of curved componentsrequires a careful control of the model complexity. Moreover, standardtechniques for model selection, including cross-validation and more generallythe use of an independent test set, fail when applied to nonlinear PCA becauseof its inherent unsupervised characteristics. This paper presents a newapproach for validating the complexity of nonlinear PCA models by using theerror in missing data estimation as a criterion for model selection. It ismotivated by the idea that only the model of optimal complexity is able topredict missing values with the highest accuracy. While standard test setvalidation usually favours over-fitted nonlinear PCA models, the proposed modelvalidation approach correctly selects the optimal model complexity.",Validation of nonlinear PCA
319,Physics,Physics,,,,"We consider the problem of learning from a similarity matrix (such asspectral clustering and lowd imensional embedding), when computing pairwisesimilarities are costly, and only a limited number of entries can be observed.We provide a theoretical analysis using standard notions of graphapproximation, significantly generalizing previous results (which focused onspectral clustering with two clusters). We also propose a new algorithmicapproach based on adaptive sampling, which experimentally matches or improveson previous methods, while being considerably more general and computationallycheaper.",Graph Approximation and Clustering on a Budget
320,,,,,,"Multiclass prediction is the problem of classifying an object into a relevanttarget class. We consider the problem of learning a multiclass predictor thatuses only few features, and in particular, the number of used features shouldincrease sub-linearly with the number of possible classes. This implies thatfeatures should be shared by several classes. We describe and analyze theShareBoost algorithm for learning a multiclass predictor that uses few sharedfeatures. We prove that ShareBoost efficiently finds a predictor that uses fewshared features (if such a predictor exists) and that it has a smallgeneralization error. We also describe how to use ShareBoost for learning anon-linear predictor that has a fast evaluation time. In a series ofexperiments with natural data sets we demonstrate the benefits of ShareBoostand evaluate its success relatively to other state-of-the-art approaches.",ShareBoost: Efficient Multiclass Learning with Feature Sharing
321,Nuclear,,,Nuclear,,"Due to advances in sensors, growing large and complex medical image data havethe ability to visualize the pathological change in the cellular or even themolecular level or anatomical changes in tissues and organs. As a consequence,the medical images have the potential to enhance diagnosis of disease,prediction of clinical outcomes, characterization of disease progression,management of health care and development of treatments, but also pose greatmethodological and computational challenges for representation and selection offeatures in image cluster analysis. To address these challenges, we firstextend one dimensional functional principal component analysis to the twodimensional functional principle component analyses (2DFPCA) to fully capturespace variation of image signals. Image signals contain a large number ofredundant and irrelevant features which provide no additional or no usefulinformation for cluster analysis. Widely used methods for removing redundantand irrelevant features are sparse clustering algorithms using a lasso-typepenalty to select the features. However, the accuracy of clustering using alasso-type penalty depends on how to select penalty parameters and a thresholdfor selecting features. In practice, they are difficult to determine. Recently,randomized algorithms have received a great deal of attention in big dataanalysis. This paper presents a randomized algorithm for accurate featureselection in image cluster analysis. The proposed method is applied to ovarianand kidney cancer histology image data from the TCGA database. The resultsdemonstrate that the randomized feature selection method coupled withfunctional principal component analysis substantially outperforms the currentsparse clustering algorithms in image cluster analysis.",Functional Principal Component Analysis and Randomized Sparse Clustering  Algorithm for Medical Image Analysis
322,Chemistry,Chemistry,,,,"Similarity between objects is multi-faceted and it can be easier for humanannotators to measure it when the focus is on a specific aspect. We considerthe problem of mapping objects into view-specific embeddings where the distancebetween them is consistent with the similarity comparisons of the form ""fromthe t-th view, object A is more similar to B than to C"". Our framework jointlylearns view-specific embeddings exploiting correlations between views.Experiments on a number of datasets, including one of multi-view crowdsourcedcomparison on bird images, show the proposed method achieves lower tripletgeneralization error when compared to both learning embeddings independentlyfor each view and all views pooled into one view. Our method can also be usedto learn multiple measures of similarity over input features taking classlabels into account and compares favorably to existing approaches formulti-task metric learning on the ISOLET dataset.",Jointly Learning Multiple Measures of Similarities from Triplet  Comparisons
323,,,,,,"The Gaussian process latent variable model (GP-LVM) provides a flexibleapproach for non-linear dimensionality reduction that has been widely applied.However, the current approach for training GP-LVMs is based on maximumlikelihood, where the latent projection variables are maximized over ratherthan integrated out. In this paper we present a Bayesian method for trainingGP-LVMs by introducing a non-standard variational inference framework thatallows to approximately integrate out the latent variables and subsequentlytrain a GP-LVM by maximizing an analytic lower bound on the exact marginallikelihood. We apply this method for learning a GP-LVM from iid observationsand for learning non-linear dynamical systems where the observations aretemporally correlated. We show that a benefit of the variational Bayesianprocedure is its robustness to overfitting and its ability to automaticallyselect the dimensionality of the nonlinear latent space. The resultingframework is generic, flexible and easy to extend for other purposes, such asGaussian process regression with uncertain inputs and semi-supervised Gaussianprocesses. We demonstrate our method on synthetic data and standard machinelearning benchmarks, as well as challenging real world datasets, including highresolution video data.",Variational Inference for Uncertainty on the Inputs of Gaussian Process  Models
324,,,,,,"Generative Adversarial Nets [8] were recently introduced as a novel way totrain generative models. In this work we introduce the conditional version ofgenerative adversarial nets, which can be constructed by simply feeding thedata, y, we wish to condition on to both the generator and discriminator. Weshow that this model can generate MNIST digits conditioned on class labels. Wealso illustrate how this model could be used to learn a multi-modal model, andprovide preliminary examples of an application to image tagging in which wedemonstrate how this approach can generate descriptive tags which are not partof training labels.",Conditional Generative Adversarial Nets
325,,,,,,"We provide a rigorous definition of the visual cause of a behavior that isbroadly applicable to the visually driven behavior in humans, animals, neurons,robots and other perceiving systems. Our framework generalizes standardaccounts of causal learning to settings in which the causal variables need tobe constructed from micro-variables. We prove the Causal Coarsening Theorem,which allows us to gain causal knowledge from observational data with minimalexperimental effort. The theorem provides a connection to standard inferencetechniques in machine learning that identify features of an image thatcorrelate with, but may not cause, the target behavior. Finally, we propose anactive learning scheme to learn a manipulator function that performs optimalmanipulations on the image to automatically identify the visual cause of atarget behavior. We illustrate our inference and learning algorithms inexperiments based on both synthetic and real data.",Visual Causal Feature Learning
326,Physics,Physics,,,,"We present experiments demonstrating that some other form of capacitycontrol, different from network size, plays a central role in learningmultilayer feed-forward networks. We argue, partially through analogy to matrixfactorization, that this is an inductive bias that can help shed light on deeplearning.",In Search of the Real Inductive Bias: On the Role of Implicit  Regularization in Deep Learning
327,,,,,,"The problem of domain generalization is to take knowledge acquired from anumber of related domains where training data is available, and to thensuccessfully apply it to previously unseen domains. We propose a new featurelearning algorithm, Multi-Task Autoencoder (MTAE), that provides goodgeneralization performance for cross-domain object recognition.  Our algorithm extends the standard denoising autoencoder framework bysubstituting artificially induced corruption with naturally occurringinter-domain variability in the appearance of objects. Instead ofreconstructing images from noisy versions, MTAE learns to transform theoriginal image into analogs in multiple related domains. It thereby learnsfeatures that are robust to variations across domains. The learnt features arethen used as inputs to a classifier.  We evaluated the performance of the algorithm on benchmark image recognitiondatasets, where the task is to learn features from multiple datasets and tothen predict the image label from unseen datasets. We found that (denoising)MTAE outperforms alternative autoencoder-based models as well as the currentstate-of-the-art algorithms for domain generalization.",Domain Generalization for Object Recognition with Multi-task  Autoencoders
328,Nuclear,,,Nuclear,,"Data-efficient reinforcement learning (RL) in continuous state-action spacesusing very high-dimensional observations remains a key challenge in developingfully autonomous systems. We consider a particularly important instance of thischallenge, the pixels-to-torques problem, where an RL agent learns aclosed-loop control policy (""torques"") from pixel information only. Weintroduce a data-efficient, model-based reinforcement learning algorithm thatlearns such a closed-loop policy directly from pixel information. The keyingredient is a deep dynamical model for learning a low-dimensional featureembedding of images jointly with a predictive model in this low-dimensionalfeature space. Joint learning is crucial for long-term predictions, which lieat the core of the adaptive nonlinear model predictive control strategy that weuse for closed-loop control. Compared to state-of-the-art RL methods forcontinuous states and actions, our approach learns quickly, scales tohigh-dimensional state spaces, is lightweight and an important step towardfully autonomous end-to-end learning from pixels to torques.",Data-Efficient Learning of Feedback Policies from Image Pixels using  Deep Dynamical Models
329,,,,,,"This paper addresses classification tasks on a particular target domain inwhich labeled training data are only available from source domains differentfrom (but related to) the target. Two closely related frameworks, domainadaptation and domain generalization, are concerned with such tasks, where theonly difference between those frameworks is the availability of the unlabeledtarget data: domain adaptation can leverage unlabeled target information, whiledomain generalization cannot. We propose Scatter Component Analyis (SCA), afast representation learning algorithm that can be applied to both domainadaptation and domain generalization. SCA is based on a simple geometricalmeasure, i.e., scatter, which operates on reproducing kernel Hilbert space. SCAfinds a representation that trades between maximizing the separability ofclasses, minimizing the mismatch between domains, and maximizing theseparability of data; each of which is quantified through scatter. Theoptimization problem of SCA can be reduced to a generalized eigenvalue problem,which results in a fast and exact solution. Comprehensive experiments onbenchmark cross-domain object recognition datasets verify that SCA performsmuch faster than several state-of-the-art algorithms and also providesstate-of-the-art classification accuracy in both domain adaptation and domaingeneralization. We also show that scatter can be used to establish atheoretical generalization bound in the case of domain adaptation.",Scatter Component Analysis: A Unified Framework for Domain Adaptation  and Domain Generalization
330,Physics,Physics,,,,"Matrix rank minimization problem is in general NP-hard. The nuclear norm isused to substitute the rank function in many recent studies. Nevertheless, thenuclear norm approximation adds all singular values together and theapproximation error may depend heavily on the magnitudes of singular values.This might restrict its capability in dealing with many practical problems. Inthis paper, an arctangent function is used as a tighter approximation to therank function. We use it on the challenging subspace clustering problem. Forthis nonconvex minimization problem, we develop an effective optimizationprocedure based on a type of augmented Lagrange multipliers (ALM) method.Extensive experiments on face clustering and motion segmentation show that theproposed method is effective for rank approximation.",Robust Subspace Clustering via Tighter Rank Approximation
331,,,,,,"The human face constantly conveys information, both consciously andsubconsciously. However, as basic as it is for humans to visually interpretthis information, it is quite a big challenge for machines. Conventionalsemantic facial feature recognition and analysis techniques are already in useand are based on physiological heuristics, but they suffer from lack ofrobustness and high computation time. This thesis aims to explore ways formachines to learn to interpret semantic information available in faces in anautomated manner without requiring manual design of feature detectors, usingthe approach of Deep Learning. This thesis provides a study of the effects ofvarious factors and hyper-parameters of deep neural networks in the process ofdetermining an optimal network configuration for the task of semantic facialfeature recognition. This thesis explores the effectiveness of the system torecognize the various semantic features (like emotions, age, gender, ethnicityetc.) present in faces. Furthermore, the relation between the effect ofhigh-level concepts on low level features is explored through an analysis ofthe similarities in low-level descriptors of different semantic features. Thisthesis also demonstrates a novel idea of using a deep network to generate 3-DActive Appearance Models of faces from real-world 2-D images.  For a more detailed report on this work, please see [arXiv:1512.00743v1].",Recognizing Semantic Features in Faces using Deep Learning
332,,,,,,"In this paper, we propose a novel unsupervised domain adaptation algorithmbased on deep learning for visual object recognition. Specifically, we design anew model called Deep Reconstruction-Classification Network (DRCN), whichjointly learns a shared encoding representation for two tasks: i) supervisedclassification of labeled source data, and ii) unsupervised reconstruction ofunlabeled target data.In this way, the learnt representation not only preservesdiscriminability, but also encodes useful information from the target domain.Our new DRCN model can be optimized by using backpropagation similarly as thestandard neural networks.  We evaluate the performance of DRCN on a series of cross-domain objectrecognition tasks, where DRCN provides a considerable improvement (up to ~8% inaccuracy) over the prior state-of-the-art algorithms. Interestingly, we alsoobserve that the reconstruction pipeline of DRCN transforms images from thesource domain into images whose appearance resembles the target dataset. Thissuggests that DRCN's performance is due to constructing a single compositerepresentation that encodes information about both the structure of targetimages and the classification of source images. Finally, we provide a formalanalysis to justify the algorithm's objective in domain adaptation context.",Deep Reconstruction-Classification Networks for Unsupervised Domain  Adaptation
333,Physics,Physics,,,,Finding the most effective way to aggregate multi-subject fMRI data is along-standing and challenging problem. It is of increasing interest incontemporary fMRI studies of human cognition due to the scarcity of data persubject and the variability of brain anatomy and functional response acrosssubjects. Recent work on latent factor models shows promising results in thistask but this approach does not preserve spatial locality in the brain. Weexamine two ways to combine the ideas of a factor model and a searchlight basedanalysis to aggregate multi-subject fMRI data while preserving spatiallocality. We first do this directly by combining a recent factor method knownas a shared response model with searchlight analysis. Then we design amulti-view convolutional autoencoder for the same task. Both approachespreserve spatial locality and have competitive or better performance comparedwith standard searchlight analysis and the shared response model applied acrossthe whole brain. We also report a system design to handle the computationalchallenge of training the convolutional autoencoder.,A Convolutional Autoencoder for Multi-Subject fMRI Data Aggregation
334,,,,,,"One way to solve lasso problems when the dictionary does not fit intoavailable memory is to first screen the dictionary to remove unneeded features.Prior research has shown that sequential screening methods offer the greatestpromise in this endeavor. Most existing work on sequential screening targetsthe context of tuning parameter selection, where one screens and solves asequence of $N$ lasso problems with a fixed grid of geometrically spacedregularization parameters. In contrast, we focus on the scenario where a targetregularization parameter has already been chosen via cross-validated modelselection, and we then need to solve many lasso instances using this fixedvalue. In this context, we propose and explore a feedback controlled sequentialscreening scheme. Feedback is used at each iteration to select the next problemto be solved. This allows the sequence of problems to be adapted to theinstance presented and the number of intermediate problems to be automaticallyselected. We demonstrate our feedback scheme using several datasets including adictionary of approximate size 100,000 by 300,000.",Feedback-Controlled Sequential Lasso Screening
335,,,,,,"Recently dictionary screening has been proposed as an effective way toimprove the computational efficiency of solving the lasso problem, which is oneof the most commonly used method for learning sparse representations. Toaddress today's ever increasing large dataset, effective screening relies on atight region bound on the solution to the dual lasso. Typical region bounds arein the form of an intersection of a sphere and multiple half spaces. One way totighten the region bound is using more half spaces, which however, adds to theoverhead of solving the high dimensional optimization problem in lassoscreening. This paper reveals the interesting property that the optimizationproblem only depends on the projection of features onto the subspace spanned bythe normals of the half spaces. This property converts an optimization problemin high dimension to much lower dimension, and thus sheds light on reducing thecomputation overhead of lasso screening based on tighter region bounds.",The Symmetry of a Simple Optimization Problem in Lasso Screening
336,,,,,,"Zero-Shot learning has been shown to be an efficient strategy for domainadaptation. In this context, this paper builds on the recent work of Bucher etal. [1], which proposed an approach to solve Zero-Shot classification problems(ZSC) by introducing a novel metric learning based objective function. Thisobjective function allows to learn an optimal embedding of the attributesjointly with a measure of similarity between images and attributes. This paperextends their approach by proposing several schemes to control the generationof the negative pairs, resulting in a significant improvement of theperformance and giving above state-of-the-art results on three challenging ZSCdatasets.",Hard Negative Mining for Metric Learning Based Zero-Shot Classification
337,,,,,,"In this paper, we deal with two challenges for measuring the similarity ofthe subject identities in practical video-based face recognition - thevariation of the head pose in uncontrolled environments and the computationalexpense of processing videos. Since the frame-wise feature mean is unable tocharacterize the pose diversity among frames, we define and preserve theoverall pose diversity and closeness in a video. Then, identity will be theonly source of variation across videos since the pose varies even within asingle video. Instead of simply using all the frames, we select those faceswhose pose point is closest to the centroid of the K-means cluster containingthat pose point. Then, we represent a video as a bag of frame-wise deep facefeatures while the number of features has been reduced from hundreds to K.Since the video representation can well represent the identity, now we measurethe subject similarity between two videos as the max correlation among allpossible pairs in the two bags of features. On the official 5,000 video-pairsof the YouTube Face dataset for face verification, our algorithm achieves acomparable performance with VGG-face that averages over deep features of allframes. Other vision tasks can also benefit from the generic idea of employinggeometric cues to improve the descriptiveness of deep features.",Pose-Selective Max Pooling for Measuring Similarity
338,Chemistry,,,Chemistry,,"A fall is an abnormal activity that occurs rarely, so it is hard to collectreal data for falls. It is, therefore, difficult to use supervised learningmethods to automatically detect falls. Another challenge in using machinelearning methods to automatically detect falls is the choice of engineeredfeatures. In this paper, we propose to use an ensemble of autoencoders toextract features from different channels of wearable sensor data trained onlyon normal activities. We show that the traditional approach of choosing athreshold as the maximum of the reconstruction error on the training normaldata is not the right way to identify unseen falls. We propose two methods forautomatic tightening of reconstruction error from only the normal activitiesfor better identification of unseen falls. We present our results on twoactivity recognition datasets and show the efficacy of our proposed methodagainst traditional autoencoder models and two standard one-classclassification methods.",Detecting Unseen Falls from Wearable Devices using Channel-wise Ensemble  of Autoencoders
339,,,,,,"This paper studies the generalization error of invariant classifiers. Inparticular, we consider the common scenario where the classification task isinvariant to certain transformations of the input, and that the classifier isconstructed (or learned) to be invariant to these transformations. Our approachrelies on factoring the input space into a product of a base space and a set oftransformations. We show that whereas the generalization error of anon-invariant classifier is proportional to the complexity of the input space,the generalization error of an invariant classifier is proportional to thecomplexity of the base space. We also derive a set of sufficient conditions onthe geometry of the base space and the set of transformations that ensure thatthe complexity of the base space is much smaller than the complexity of theinput space. Our analysis applies to general classifiers such as convolutionalneural networks. We demonstrate the implications of the developed theory forsuch classifiers with experiments on the MNIST and CIFAR-10 datasets.",Generalization Error of Invariant Classifiers
340,DV,DV,,,,"Given a state-of-the-art deep neural network classifier, we show theexistence of a universal (image-agnostic) and very small perturbation vectorthat causes natural images to be misclassified with high probability. Wepropose a systematic algorithm for computing universal perturbations, and showthat state-of-the-art deep neural networks are highly vulnerable to suchperturbations, albeit being quasi-imperceptible to the human eye. We furtherempirically analyze these universal perturbations and show, in particular, thatthey generalize very well across neural networks. The surprising existence ofuniversal perturbations reveals important geometric correlations among thehigh-dimensional decision boundary of classifiers. It further outlinespotential security breaches with the existence of single directions in theinput space that adversaries can possibly exploit to break a classifier on mostnatural images.",Universal adversarial perturbations
341,,,,,,"Limited annotated data available for the recognition of facial expression andaction units embarrasses the training of deep networks, which can learndisentangled invariant features. However, a linear model with just severalparameters normally is not demanding in terms of training data. In this paper,we propose an elegant linear model to untangle confounding factors inchallenging realistic multichannel signals such as 2D face videos. The simpleyet powerful model does not rely on huge training data and is natural forrecognizing facial actions without explicitly disentangling the identity. Baseon well-understood intuitive linear models such as Sparse Representation basedClassification (SRC), previous attempts require a prepossessing of explicitdecoupling which is practically inexact. Instead, we exploit the low-rankproperty across frames to subtract the underlying neutral faces which aremodeled jointly with sparse representation on the action components with groupsparsity enforced. On the extended Cohn-Kanade dataset (CK+), our one-shotautomatic method on raw face videos performs as competitive as SRC applied onmanually prepared action components and performs even better than SRC in termsof true positive rate. We apply the model to the even more challenging task offacial action unit recognition, verified on the MPI Face Video Database(MPI-VDB) achieving a decent performance. All the programs and data have beenmade publicly available.",Linear Disentangled Representation Learning for Facial Actions
342,,,,,,"Machine learning and deep learning in particular has advanced tremendously onperceptual tasks in recent years. However, it remains vulnerable againstadversarial perturbations of the input that have been crafted specifically tofool the system while being quasi-imperceptible to a human. In this work, wepropose to augment deep neural networks with a small ""detector"" subnetworkwhich is trained on the binary classification task of distinguishing genuinedata from data containing adversarial perturbations. Our method is orthogonalto prior work on addressing adversarial perturbations, which has mostly focusedon making the classification network itself more robust. We show empiricallythat adversarial perturbations can be detected surprisingly well even thoughthey are quasi-imperceptible to humans. Moreover, while the detectors have beentrained to detect only a specific adversary, they generalize to similar andweaker adversaries. In addition, we propose an adversarial attack that foolsboth the classifier and the detector and a novel training procedure for thedetector that counteracts this attack.",On Detecting Adversarial Perturbations
343,Chemistry,,,Chemistry,,"Class labels have been empirically shown useful in improving the samplequality of generative adversarial nets (GANs). In this paper, we mathematicallystudy the properties of the current variants of GANs that make use of classlabel information. With class aware gradient and cross-entropy decomposition,we reveal how class labels and associated losses influence GAN's training.Based on that, we propose Activation Maximization Generative AdversarialNetworks (AM-GAN) as an advanced solution. Comprehensive experiments have beenconducted to validate our analysis and evaluate the effectiveness of oursolution, where AM-GAN outperforms other strong baselines and achievesstate-of-the-art Inception Score (8.91) on CIFAR-10. In addition, wedemonstrate that, with the Inception ImageNet classifier, Inception Scoremainly tracks the diversity of the generator, and there is, however, noreliable evidence that it can reflect the true sample quality. We thus proposea new metric, called AM Score, to provide more accurate estimation on thesample quality. Our proposed model also outperforms the baseline methods in thenew metric.",Activation Maximization Generative Adversarial Nets
344,,,,,,"As machine learning algorithms are increasingly applied to high impact yethigh risk tasks, such as medical diagnosis or autonomous driving, it iscritical that researchers can explain how such algorithms arrived at theirpredictions. In recent years, a number of image saliency methods have beendeveloped to summarize where highly complex neural networks ""look"" in an imagefor evidence for their predictions. However, these techniques are limited bytheir heuristic nature and architectural constraints. In this paper, we maketwo main contributions: First, we propose a general framework for learningdifferent kinds of explanations for any black box algorithm. Second, wespecialise the framework to find the part of an image most responsible for aclassifier decision. Unlike previous works, our method is model-agnostic andtestable because it is grounded in explicit and interpretable imageperturbations.",Interpretable Explanations of Black Boxes by Meaningful Perturbation
345,,,,,,"Though the deep learning is pushing the machine learning to a new stage,basic theories of machine learning are still limited. The principle oflearning, the role of the a prior knowledge, the role of neuron bias, and thebasis for choosing neural transfer function and cost function, etc., are stillfar from clear. In this paper, we present a general theoretical framework formachine learning. We classify the prior knowledge into common andproblem-dependent parts, and consider that the aim of learning is to maximallyincorporate them. The principle we suggested for maximizing the former is thedesign risk minimization principle, while the neural transfer function, thecost function, as well as pretreatment of samples, are endowed with the rolefor maximizing the latter. The role of the neuron bias is explained from adifferent angle. We develop a Monte Carlo algorithm to establish theinput-output responses, and we control the input-output sensitivity of alearning machine by controlling that of individual neurons. Applications offunction approaching and smoothing, pattern recognition and classification, areprovided to illustrate how to train general learning machines based on ourtheory and algorithm. Our method may in addition induce new applications, suchas the transductive inference.",A General Theory for Training Learning Machine
346,,,,,,"This paper introduces a generalization of Convolutional Neural Networks(CNNs) from low-dimensional grid data, such as images, to graph-structureddata. We propose a novel spatial convolution utilizing a random walk to uncoverthe relations within the input, analogous to the way the standard convolutionuses the spatial neighborhood of a pixel on the grid. The convolution has anintuitive interpretation, is efficient and scalable and can also be used ondata with varying graph structure. Furthermore, this generalization can beapplied to many standard regression or classification problems, by learning thethe underlying graph. We empirically demonstrate the performance of theproposed CNN on MNIST, and challenge the state-of-the-art on Merck molecularactivity data set.",A Generalization of Convolutional Neural Networks to Graph-Structured  Data
347,Chemistry,,,Chemistry,,"Recent work has shown that state-of-the-art classifiers are quite brittle, inthe sense that a small adversarial change of an originally with high confidencecorrectly classified input leads to a wrong classification again with highconfidence. This raises concerns that such classifiers are vulnerable toattacks and calls into question their usage in safety-critical systems. We showin this paper for the first time formal guarantees on the robustness of aclassifier by giving instance-specific lower bounds on the norm of the inputmanipulation required to change the classifier decision. Based on this analysiswe propose the Cross-Lipschitz regularization functional. We show that usingthis form of regularization in kernel methods resp. neural networks improvesthe robustness of the classifier without any loss in prediction performance.",Formal Guarantees on the Robustness of a Classifier against Adversarial  Manipulation
348,,,,,,"The goal of this paper is to analyze the geometric properties of deep neuralnetwork classifiers in the input space. We specifically study the topology ofclassification regions created by deep networks, as well as their associateddecision boundary. Through a systematic empirical investigation, we show thatstate-of-the-art deep nets learn connected classification regions, and that thedecision boundary in the vicinity of datapoints is flat along most directions.We further draw an essential connection between two seemingly unrelatedproperties of deep networks: their sensitivity to additive perturbations in theinputs, and the curvature of their decision boundary. The directions where thedecision boundary is curved in fact remarkably characterize the directions towhich the classifier is the most vulnerable. We finally leverage a fundamentalasymmetry in the curvature of the decision boundary of deep nets, and propose amethod to discriminate between original images, and images perturbed with smalladversarial examples. We show the effectiveness of this purely geometricapproach for detecting small adversarial perturbations in images, and forrecovering the labels of perturbed images.",Classification regions of deep neural networks
349,Chemistry,Chemistry,,,,"Deep networks have recently been shown to be vulnerable to universalperturbations: there exist very small image-agnostic perturbations that causemost natural images to be misclassified by such classifiers. In this paper, wepropose the first quantitative analysis of the robustness of classifiers touniversal perturbations, and draw a formal link between the robustness touniversal perturbations, and the geometry of the decision boundary.Specifically, we establish theoretical bounds on the robustness of classifiersunder two decision boundary models (flat and curved models). We show inparticular that the robustness of deep networks to universal perturbations isdriven by a key property of their curvature: there exists shared directionsalong which the decision boundary of deep networks is systematically positivelycurved. Under such conditions, we prove the existence of small universalperturbations. Our analysis further provides a novel geometric method forcomputing universal perturbations, in addition to explaining their properties.",Analysis of universal adversarial perturbations
350,DV,DV,,,,"Generative adversarial networks (GANs) can implicitly learn richdistributions over images, audio, and data which are hard to model with anexplicit likelihood. We present a practical Bayesian formulation forunsupervised and semi-supervised learning with GANs. Within this framework, weuse stochastic gradient Hamiltonian Monte Carlo to marginalize the weights ofthe generator and discriminator networks. The resulting approach isstraightforward and obtains good performance without any standard interventionssuch as feature matching, or mini-batch discrimination. By exploring anexpressive posterior over the parameters of the generator, the Bayesian GANavoids mode-collapse, produces interpretable and diverse candidate samples, andprovides state-of-the-art quantitative results for semi-supervised learning onbenchmarks including SVHN, CelebA, and CIFAR-10, outperforming DCGAN,Wasserstein GANs, and DCGAN ensembles.",Bayesian GAN
351,,,,,,"We present a new model DrNET that learns disentangled image representationsfrom video. Our approach leverages the temporal coherence of video and a noveladversarial loss to learn a representation that factorizes each frame into astationary part and a temporally varying component. The disentangledrepresentation can be used for a range of tasks. For example, applying astandard LSTM to the time-vary components enables prediction of future frames.We evaluate our approach on a range of synthetic and real videos, demonstratingthe ability to coherently generate hundreds of steps into the future.",Unsupervised Learning of Disentangled Representations from Video
352,Data,,,Data,,"Generative adversarial nets (GANs) are a promising technique for modeling adistribution from samples. It is however well known that GAN training suffersfrom instability due to the nature of its maximin formulation. In this paper,we explore ways to tackle the instability problem by dualizing thediscriminator. We start from linear discriminators in which case conjugateduality provides a mechanism to reformulate the saddle point objective into amaximization problem, such that both the generator and the discriminator ofthis 'dualing GAN' act in concert. We then demonstrate how to extend thisintuition to non-linear formulations. For GANs with linear discriminators ourapproach is able to remove the instability in training, while for GANs withnonlinear discriminators our approach provides an alternative to the commonlyused GAN training algorithm.",Dualing GANs
353,Nuclear,Nuclear,,,,"Model based iterative reconstruction (MBIR) algorithms for low-dose X-ray CTare computationally expensive. To address this problem, we recently proposedthe world-first deep convolutional neural network (CNN) for low-dose X-ray CTand won the second place in 2016 AAPM Low-Dose CT Grand Challenge. However,some of the texture were not fully recovered. To cope with this problem, herewe propose a deep residual learning approach in directional wavelet domain. Theproposed method is motivated by an observation that a deep convolutional neuralnetwork can be interpreted as a multilayer convolutional framelets expansionusing non-local basis convolved with data-driven local basis. We further extendthe idea to derive a deep convolutional framelet expansion by combining globalredundant transforms and signal boosting from multiple signal representations.Extensive experimental results confirm that the proposed network hassignificantly improved performance and preserves the detail texture of theoriginal images",Wavelet Residual Network for Low-Dose CT via Deep Convolutional  Framelets
354,DV,DV,,,,"The success of various applications including robotics, digital contentcreation, and visualization demand a structured and abstract representation ofthe 3D world from limited sensor data. Inspired by the nature of humanperception of 3D shapes as a collection of simple parts, we explore such anabstract shape representation based on primitives. Given a single depth imageof an object, we present 3D-PR, a generative recurrent neural network thatsynthesizes multiple plausible shapes composed of a set of primitives. Ourgenerative model encodes symmetry characteristics of common man-made objects,preserves long-range structural coherence, and describes objects of varyingcomplexity with a compact representation. We also propose a method based onGaussian Fields to generate a large scale dataset of primitive-based shaperepresentations to train our network. We evaluate our approach on a wide rangeof examples and show that it outperforms nearest-neighbor based shape retrievalmethods and is on-par with voxel-based generative models while using asignificantly reduced parameter space.",3D-PRNN: Generating Shape Primitives with Recurrent Neural Networks
355,DV,DV,,,,"In this article, we mathematically study several GAN related topics,including Inception score, label smoothing, gradient vanishing and the-log(D(x)) alternative.  --- An advanced version is included in arXiv:1703.02000 ""ActivationMaximization Generative Adversarial Nets"". Please refer Section 6 in 1703.02000for detailed analysis on Inception Score, and refer its appendix for thediscussions on Label Smoothing, Gradient Vanishing and -log(D(x)) Alternative.---","Inception Score, Label Smoothing, Gradient Vanishing and -log(D(x))  Alternative"
356,,,,,,"Deep reinforcement learning is poised to revolutionise the field of AI andrepresents a step towards building autonomous systems with a higher levelunderstanding of the visual world. Currently, deep learning is enablingreinforcement learning to scale to problems that were previously intractable,such as learning to play video games directly from pixels. Deep reinforcementlearning algorithms are also applied to robotics, allowing control policies forrobots to be learned directly from camera inputs in the real world. In thissurvey, we begin with an introduction to the general field of reinforcementlearning, then progress to the main streams of value-based and policy-basedmethods. Our survey will cover central algorithms in deep reinforcementlearning, including the deep $Q$-network, trust region policy optimisation, andasynchronous advantage actor-critic. In parallel, we highlight the uniqueadvantages of deep neural networks, focusing on visual understanding viareinforcement learning. To conclude, we describe several current areas ofresearch within the field.",A Brief Survey of Deep Reinforcement Learning
357,,,,,,"Large-scale deep neural networks (DNNs) are both compute and memoryintensive. As the size of DNNs continues to grow, it is critical to improve theenergy efficiency and performance while maintaining accuracy. For DNNs, themodel size is an important factor affecting performance, scalability and energyefficiency. Weight pruning achieves good compression ratios but suffers fromthree drawbacks: 1) the irregular network structure after pruning; 2) theincreased training complexity; and 3) the lack of rigorous guarantee ofcompression ratio and inference accuracy. To overcome these limitations, thispaper proposes CirC, a principled approach to represent weights and processneural networks using block-circulant matrices. CirCNN utilizes the FastFourier Transform (FFT)-based fast multiplication, simultaneously reducing thecomputational complexity (both in inference and training) from O(n2) toO(nlogn) and the storage complexity from O(n2) to O(n), with negligibleaccuracy loss. Compared to other approaches, CirCNN is distinct due to itsmathematical rigor: it can converge to the same effectiveness as DNNs withoutcompression. The CirCNN architecture, a universal DNN inference engine that canbe implemented on various hardware/software platforms with configurable networkarchitecture. To demonstrate the performance and energy efficiency, we testCirCNN in FPGA, ASIC and embedded processors. Our results show that CirCNNarchitecture achieves very high energy efficiency and performance with a smallhardware footprint. Based on the FPGA implementation and ASIC synthesisresults, CirCNN achieves 6-102X energy efficiency improvements compared withthe best state-of-the-art results.",CirCNN: Accelerating and Compressing Deep Neural Networks Using  Block-CirculantWeight Matrices
358,Physics,Physics,,,,"We propose two multimodal deep learning architectures that allow forcross-modal dataflow (XFlow) between the feature extractors, thereby extractingmore interpretable features and obtaining a better representation than throughunimodal learning, for the same amount of training data. These models canusefully exploit correlations between audio and visual data, which have adifferent dimensionality and are therefore nontrivially exchangeable. Our workimproves on existing multimodal deep learning metholodogies in two essentialways: (1) it presents a novel method for performing cross-modality (beforefeatures are learned from individual modalities) and (2) extends the previouslyproposed cross-connections, which only transfer information between streamsthat process compatible data. Both cross-modal architectures outperformed theirbaselines (by up to 7.5%) when evaluated on the AVletters dataset.",XFlow: 1D-2D Cross-modal Deep Neural Networks for Audiovisual  Classification
359,,,,,,"Low dimensional embeddings that capture the main variations of interest incollections of data are important for many applications. One way to constructthese embeddings is to acquire estimates of similarity from the crowd. However,similarity is a multi-dimensional concept that varies from individual toindividual. Existing models for learning embeddings from the crowd typicallymake simplifying assumptions such as all individuals estimate similarity usingthe same criteria, the list of criteria is known in advance, or that the crowdworkers are not influenced by the data that they see. To overcome theselimitations we introduce Context Embedding Networks (CENs). In addition tolearning interpretable embeddings from images, CENs also model worker biasesfor different attributes along with the visual context i.e. the visualattributes highlighted by a set of images. Experiments on two noisy crowdannotated datasets show that modeling both worker bias and visual contextresults in more interpretable embeddings compared to existing approaches.",Context Embedding Networks
360,DV,DV,,,,"The meteoric rise of deep learning models in computer vision research, havingachieved human-level accuracy in image recognition tasks is firm evidence ofthe impact of representation learning of deep neural networks. In the chemistrydomain, recent advances have also led to the development of similar CNN models,such as Chemception, that is trained to predict chemical properties usingimages of molecular drawings. In this work, we investigate the effects ofsystematically removing and adding localized domain-specific information to theimage channels of the training data. By augmenting images with only 3additional basic information, and without introducing any architecturalchanges, we demonstrate that an augmented Chemception (AugChemception)outperforms the original model in the prediction of toxicity, activity, andsolvation free energy. Then, by altering the information content in the images,and examining the resulting model's performance, we also identify two distinctlearning patterns in predicting toxicity/activity as compared to solvation freeenergy. These patterns suggest that Chemception is learning about its tasks inthe manner that is consistent with established knowledge. Thus, our workdemonstrates that advanced chemical knowledge is not a pre-requisite for deeplearning models to accurately predict complex chemical properties.",How Much Chemistry Does a Deep Neural Network Need to Know to Make  Accurate Predictions?
361,DV,DV,,,,"Disentangled representations, where the higher level data generative factorsare reflected in disjoint latent dimensions, offer several benefits such asease of deriving invariant representations, transferability to other tasks,interpretability, etc. We consider the problem of unsupervised learning ofdisentangled representations from large pool of unlabeled observations, andpropose a variational inference based approach to infer disentangled latentfactors. We introduce a regularizer on the expectation of the approximateposterior over observed data that encourages the disentanglement. We evaluatethe proposed approach using several quantitative metrics and empiricallyobserve significant gains over existing methods in terms of bothdisentanglement and data likelihood (reconstruction quality).",Variational Inference of Disentangled Latent Concepts from Unlabeled  Observations
362,,,,,,"We study the properties of the endpoint of stochastic gradient descent (SGD).By approximating SGD as a stochastic differential equation (SDE) we considerthe Boltzmann-Gibbs equilibrium distribution of that SDE under the assumptionof isotropic variance in loss gradients. Through this analysis, we find thatthree factors - learning rate, batch size and the variance of the lossgradients - control the trade-off between the depth and width of the minimafound by SGD, with wider minima favoured by a higher ratio of learning rate tobatch size. We have direct control over the learning rate and batch size, whilethe variance is determined by the choice of model architecture, modelparameterization and dataset. In the equilibrium distribution only the ratio oflearning rate to batch size appears, implying that the equilibrium distributionis invariant under a simultaneous rescaling of learning rate and batch size bythe same amount. We then explore experimentally how learning rate and batchsize affect SGD from two perspectives: the endpoint of SGD and the dynamicsthat lead up to it. For the endpoint, the experiments suggest the endpoint ofSGD is invariant under simultaneous rescaling of batch size and learning rate,and also that a higher ratio leads to flatter minima, both findings areconsistent with our theoretical analysis. We note experimentally that thedynamics also seem to be invariant under the same rescaling of learning rateand batch size, which we explore showing that one can exchange batch size andlearning rate for cyclical learning rate schedule. Next, we illustrate hownoise affects memorization, showing that high noise levels lead to bettergeneralization. Finally, we find experimentally that the invariance undersimultaneous rescaling of learning rate and batch size breaks down if thelearning rate gets too large or the batch size gets too small.",Three Factors Influencing Minima in SGD
363,,,,,,"Achieving superhuman playing level by AlphaGo corroborated the capabilitiesof convolutional neural architectures (CNNs) for capturing complex spatialpatterns. This result was to a great extent due to several analogies between Goboard states and 2D images CNNs have been designed for, in particulartranslational invariance and a relatively large board. In this paper, we verifywhether CNN-based move predictors prove effective for Othello, a game withsignificantly different characteristics, including a much smaller board sizeand complete lack of translational invariance. We compare several CNNarchitectures and board encodings, augment them with state-of-the-artextensions, train on an extensive database of experts' moves, and examine themwith respect to move prediction accuracy and playing strength. The empiricalevaluation confirms high capabilities of neural move predictors and suggests astrong correlation between prediction accuracy and playing strength. The bestCNNs not only surpass all other 1-ply Othello players proposed to date butdefeat (2-ply) Edax, the best open-source Othello player.",Learning to Play Othello with Deep Neural Networks
364,,,,,,"Can artificial intelligence (AI) learn complicated non-linear physics? Herewe propose a novel deep learning approach that learns non-linear photonscattering physics and obtains accurate 3D distribution of optical anomalies.In contrast to the traditional black-box deep learning approaches to inverseproblems, our deep network learns to invert the Lippmann-Schwinger integralequation which describes the essential physics of photon migration of diffusenear-infrared (NIR) photons in turbid media. As an example for clinicalrelevance, we applied the method to our prototype diffuse optical tomography(DOT). We show that our deep neural network, trained with only simulation data,can accurately recover the location of anomalies within biomimetic phantoms andlive animals without the use of an exogenous contrast agent.",Deep Learning Can Reverse Photon Migration for Diffuse Optical  Tomography
365,Data,Data,,,,"With access to large datasets, deep neural networks (DNN) have achievedhuman-level accuracy in image and speech recognition tasks. However, inchemistry, data is inherently small and fragmented. In this work, we develop anapproach of using rule-based knowledge for training ChemNet, a transferable andgeneralizable deep neural network for chemical property prediction that learnsin a weak-supervised manner from large unlabeled chemical databases. Whencoupled with transfer learning approaches to predict other smaller datasets forchemical properties that it was not originally trained on, we show thatChemNet's accuracy outperforms contemporary DNN models that were trained usingconventional supervised learning. Furthermore, we demonstrate that the ChemNetpre-training approach is equally effective on both CNN (Chemception) and RNN(SMILES2vec) models, indicating that this approach is network architectureagnostic and is effective across multiple data modalities. Our results indicatea pre-trained ChemNet that incorporates chemistry domain knowledge, enables thedevelopment of generalizable neural networks for more accurate prediction ofnovel chemical properties.",Using Rule-Based Labels for Weak Supervised Learning: A ChemNet for  Transferable Chemical Property Prediction
366,,,,,,"In portable, three dimensional, and ultra-fast ultrasound (US) imagingsystems, there is an increasing need to reconstruct high quality images from alimited number of RF data from receiver (Rx) or scan-line (SC) sub-sampling.However, due to the severe side lobe artifacts from RF sub-sampling, thestandard beam-former often produces blurry images with less contrast that arenot suitable for diagnostic purpose. To address this problem, some researchershave studied compressed sensing (CS) to exploit the sparsity of the image or RFdata in some domains. However, the existing CS approaches require eitherhardware changes or computationally expensive algorithms. To overcome theselimitations, here we propose a novel deep learning approach that directlyinterpolates the missing RF data by utilizing redundancy in the Rx-SC plane. Inparticular, the network design principle derives from a novel interpretation ofthe deep neural network as a cascaded convolution framelets that learns thedata-driven bases for Hankel matrix decomposition. Our extensive experimentalresults from sub-sampled RF data from a real US system confirmed that theproposed method can effectively reduce the data rate without sacrificing theimage quality.",Deep Learning in RF Sub-sampled B-mode Ultrasound Imaging
367,,,,,,"Interior tomography for the region-of-interest (ROI) imaging has advantagesof using a small detector and reducing X-ray radiation dose. However, standardanalytic reconstruction suffers from severe cupping artifacts due to existenceof null space in the truncated Radon transform. Existing penalizedreconstruction methods may address this problem but they require extensivecomputations due to the iterative reconstruction. Inspired by the recent deeplearning approaches to low-dose and sparse view CT, here we propose a deeplearning architecture that removes null space signals from the FBPreconstruction. Experimental results have shown that the proposed methodprovides near-perfect reconstruction with about 7-10 dB improvement in PSNRover existing methods in spite of significantly reduced run-time complexity.",Deep Learning Interior Tomography for Region-of-Interest Reconstruction
368,,,,,,"For homeland and transportation security applications, 2D X-ray explosivedetection system (EDS) have been widely used, but they have limitations inrecognizing 3D shape of the hidden objects. Among various types of 3D computedtomography (CT) systems to address this issue, this paper is interested in astationary CT using fixed X-ray sources and detectors. However, due to thelimited number of projection views, analytic reconstruction algorithms producesevere streaking artifacts. Inspired by recent success of deep learningapproach for sparse view CT reconstruction, here we propose a novel image andsinogram domain deep learning architecture for 3D reconstruction from verysparse view measurement. The algorithm has been tested with the real data froma prototype 9-view dual energy stationary CT EDS carry-on baggage scannerdeveloped by GEMSS Medical Systems, Korea, which confirms the superiorreconstruction performance over the existing approaches.",Deep Learning Reconstruction for 9-View Dual Energy CT Baggage Scanner
369,Nuclear,,,Nuclear,,"Deep learning has shown promising results on many machine learning tasks butDL models are often complex networks with large number of neurons and layers,and recently, complex layer structures known as building blocks. Finding thebest deep model requires a combination of finding both the right architectureand the correct set of parameters appropriate for that architecture. Inaddition, this complexity (in terms of layer types, number of neurons, andnumber of layers) also present problems with generalization since largernetworks are easier to overfit to the data. In this paper, we propose a searchframework for finding effective architectural building blocks for convolutionalneural networks (CNN). Our approach is much faster at finding models that areclose to state-of-the-art in performance. In addition, the models discovered byour approach are also smaller than models discovered by similar techniques. Weachieve these twin advantages by designing our search space in such a way thatit searches over a reduced set of state-of-the-art building blocks for CNNsincluding residual block, inception block, inception-residual block, ResNeXtblock and many others. We apply this technique to generate models for multipleimage datasets and show that these models achieve performance comparable tostate-of-the-art (and even surpassing the state-of-the-art in one case). Wealso show that learned models are transferable between datasets.",Effective Building Block Design for Deep Convolutional Neural Networks  using Search
370,Nuclear,,,Nuclear,,"Deep metric learning has been demonstrated to be highly effective in learningsemantic representation and encoding information that can be used to measuredata similarity, by relying on the embedding learned from metric learning. Atthe same time, variational autoencoder (VAE) has widely been used toapproximate inference and proved to have a good performance for directedprobabilistic models. However, for traditional VAE, the data label or featureinformation are intractable. Similarly, traditional representation learningapproaches fail to represent many salient aspects of the data. In this project,we propose a novel integrated framework to learn latent embedding in VAE byincorporating deep metric learning. The features are learned by optimizing atriplet loss on the mean vectors of VAE in conjunction with standard evidencelower bound (ELBO) of VAE. This approach, which we call Triplet basedVariational Autoencoder (TVAE), allows us to capture more fine-grainedinformation in the latent embedding. Our model is tested on MNIST data set andachieves a high triplet accuracy of 95.60% while the traditional VAE (Kingma &Welling, 2013) achieves triplet accuracy of 75.08%.",TVAE: Triplet-Based Variational Autoencoder using Metric Learning
371,,,,,,"Infants are experts at playing, with an amazing ability to generate novelstructured behaviors in unstructured environments that lack clear extrinsicreward signals. We seek to mathematically formalize these abilities using aneural network that implements curiosity-driven intrinsic motivation. Using asimple but ecologically naturalistic simulated environment in which an agentcan move and interact with objects it sees, we propose a ""world-model"" networkthat learns to predict the dynamic consequences of the agent's actions.Simultaneously, we train a separate explicit ""self-model"" that allows the agentto track the error map of its own world-model, and then uses the self-model toadversarially challenge the developing world-model. We demonstrate that thispolicy causes the agent to explore novel and informative interactions with itsenvironment, leading to the generation of a spectrum of complex behaviors,including ego-motion prediction, object attention, and object gathering.Moreover, the world-model that the agent learns supports improved performanceon object dynamics prediction, detection, localization and recognition tasks.Taken together, our results are initial steps toward creating flexibleautonomous agents that self-supervise in complex novel physical environments.",Learning to Play with Intrinsically-Motivated Self-Aware Agents
372,Nuclear,,,Nuclear,,"Infants are experts at playing, with an amazing ability to generate novelstructured behaviors in unstructured environments that lack clear extrinsicreward signals. We seek to replicate some of these abilities with a neuralnetwork that implements curiosity-driven intrinsic motivation. Using a simplebut ecologically naturalistic simulated environment in which the agent can moveand interact with objects it sees, the agent learns a world model predictingthe dynamic consequences of its actions. Simultaneously, the agent learns totake actions that adversarially challenge the developing world model, pushingthe agent to explore novel and informative interactions with its environment.We demonstrate that this policy leads to the self-supervised emergence of aspectrum of complex behaviors, including ego motion prediction, objectattention, and object gathering. Moreover, the world model that the agentlearns supports improved performance on object dynamics prediction andlocalization tasks. Our results are a proof-of-principle that computationalmodels of intrinsic motivation might account for key features of developmentalvisuomotor learning in infants.",Emergence of Structured Behaviors from Curiosity-Based Intrinsic  Motivation
373,,,,,,"Generating video frames that accurately predict future world states ischallenging. Existing approaches either fail to capture the full distributionof outcomes, or yield blurry generations, or both. In this paper we introducean unsupervised video generation model that learns a prior model of uncertaintyin a given environment. Video frames are generated by drawing samples from thisprior and combining them with a deterministic estimate of the future frame. Theapproach is simple and easily trained end-to-end on a variety of datasets.Sample generations are both varied and sharp, even many frames into the future,and compare favorably to those from existing approaches.",Stochastic Video Generation with a Learned Prior
374,,,,,,"Supervised object detection and semantic segmentation require object or evenpixel level annotations. When there exist image level labels only, it ischallenging for weakly supervised algorithms to achieve accurate predictions.The accuracy achieved by top weakly supervised algorithms is stillsignificantly lower than their fully supervised counterparts. In this paper, wepropose a novel weakly supervised curriculum learning pipeline for multi-labelobject recognition, detection and semantic segmentation. In this pipeline, wefirst obtain intermediate object localization and pixel labeling results forthe training images, and then use such results to train task-specific deepnetworks in a fully supervised manner. The entire process consists of fourstages, including object localization in the training images, filtering andfusing object instances, pixel labeling for the training images, andtask-specific network training. To obtain clean object instances in thetraining images, we propose a novel algorithm for filtering, fusing andclassifying object instances collected from multiple solution mechanisms. Inthis algorithm, we incorporate both metric learning and density-basedclustering to filter detected object instances. Experiments show that ourweakly supervised pipeline achieves state-of-the-art results in multi-labelimage classification as well as weakly supervised object detection and verycompetitive results in weakly supervised semantic segmentation on MS-COCO,PASCAL VOC 2007 and PASCAL VOC 2012.","Multi-Evidence Filtering and Fusion for Multi-Label Classification,  Object Detection and Semantic Segmentation Based on Weakly Supervised  Learning"
375,,,,,,"In the recent literature the important role of depth in deep learning hasbeen emphasized. In this paper we argue that sufficient width of a feedforwardnetwork is equally important by answering the simple question under whichconditions the decision regions of a neural network are connected. It turns outthat for a class of activation functions including leaky ReLU, neural networkshaving a pyramidal structure, that is no layer has more hidden units than theinput dimension, produce necessarily connected decision regions. This impliesthat a sufficiently wide layer is necessary to produce disconnected decisionregions. We discuss the implications of this result for the construction ofneural networks, in particular the relation to the problem of adversarialmanipulation of classifiers.",Neural Networks Should Be Wide Enough to Learn Disconnected Decision  Regions
376,,,,,,"We develop three efficient approaches for generating visual explanations from3D convolutional neural networks (3D-CNNs) for Alzheimer's diseaseclassification. One approach conducts sensitivity analysis on hierarchical 3Dimage segmentation, and the other two visualize network activations on aspatial map. Visual checks and a quantitative localization benchmark indicatethat all approaches identify important brain parts for Alzheimer's diseasediagnosis. Comparative analysis show that the sensitivity analysis basedapproach has difficulty handling loosely distributed cerebral cortex, andapproaches based on visualization of activations are constrained by theresolution of the convolutional layer. The complementarity of these methodsimproves the understanding of 3D-CNNs in Alzheimer's disease classificationfrom different perspectives.",Visual Explanations From Deep 3D Convolutional Neural Networks for  Alzheimer's Disease Classification
377,,,,,,"Deep neural networks are typically trained by optimizing a loss function withan SGD variant, in conjunction with a decaying learning rate, untilconvergence. We show that simple averaging of multiple points along thetrajectory of SGD, with a cyclical or constant learning rate, leads to bettergeneralization than conventional training. We also show that this StochasticWeight Averaging (SWA) procedure finds much broader optima than SGD, andapproximates the recent Fast Geometric Ensembling (FGE) approach with a singlemodel. Using SWA we achieve notable improvement in test accuracy overconventional SGD training on a range of state-of-the-art residual networks,PyramidNets, DenseNets, and Shake-Shake networks on CIFAR-10, CIFAR-100, andImageNet. In short, SWA is extremely easy to implement, improvesgeneralization, and has almost no computational overhead.",Averaging Weights Leads to Wider Optima and Better Generalization
378,Physics,Physics,,,,"By drawing on ideas from optimisation theory, artificial neural networks(ANN), graph embeddings and sparse representations, I develop a noveltechnique, termed SENNS (Sparse Extraction Neural NetworkS), aimed ataddressing the feature extraction problem. The proposed method uses (preferablydeep) ANNs for projecting input attribute vectors to an output space whereinpairwise distances are maximized for vectors belonging to different classes,but minimized for those belonging to the same class, while simultaneouslyenforcing sparsity on the ANN outputs. The vectors that result from theprojection can then be used as features in any classifier of choice.Mathematically, I formulate the proposed method as the minimisation of anobjective function which can be interpreted, in the ANN output space, as anegative factor of the sum of the squares of the pair-wise distances betweenoutput vectors belonging to different classes, added to a positive factor ofthe sum of squares of the pair-wise distances between output vectors belongingto the same classes, plus sparsity and weight decay terms. To derive analgorithm for minimizing the objective function via gradient descent, I use themulti-variate version of the chain rule to obtain the partial derivatives ofthe function with respect to ANN weights and biases, and find that each of therequired partial derivatives can be expressed as a sum of six terms. As itturns out, four of those six terms can be computed using the standard backpropagation algorithm; the fifth can be computed via a slight modification ofthe standard backpropagation algorithm; while the sixth one can be computed viasimple arithmetic. Finally, I propose experiments on the ARABASE Arabic corporaof digits and letters, the CMU PIE database of faces, the MNIST digitsdatabase, and other standard machine learning databases.",SENNS: Sparse Extraction Neural NetworkS for Feature Extraction
379,,,,,,"We propose a method to optimize the representation and distinguishability ofsamples from two probability distributions, by maximizing the estimated powerof a statistical test based on the maximum mean discrepancy (MMD). Thisoptimized MMD is applied to the setting of unsupervised learning by generativeadversarial networks (GAN), in which a model attempts to generate realisticsamples, and a discriminator attempts to tell these apart from data samples. Inthis context, the MMD may be used in two roles: first, as a discriminator,either directly on the samples, or on features of the samples. Second, the MMDcan be used to evaluate the performance of a generative model, by testing themodel's samples against a reference data set. In the latter role, the optimizedMMD is particularly helpful, as it gives an interpretable indication of how themodel and data distributions differ, even in cases where individual modelsamples are not easily distinguished either by eye or by classifier.",Generative Models and Model Criticism via Optimized Maximum Mean  Discrepancy
380,DV,DV,,,,"Many real world stochastic control problems suffer from the ""curse ofdimensionality"". To overcome this difficulty, we develop a deep learningapproach that directly solves high-dimensional stochastic control problemsbased on Monte-Carlo sampling. We approximate the time-dependent controls asfeedforward neural networks and stack these networks together through modeldynamics. The objective function for the control problem plays the role of theloss function for the deep neural network. We test this approach using examplesfrom the areas of optimal trading and energy storage. Our results suggest thatthe algorithm presented here achieves satisfactory accuracy and at the sametime, can handle rather high dimensional problems.",Deep Learning Approximation for Stochastic Control Problems
381,Data,,,Data,,"In de novo drug design, computational strategies are used to generate novelmolecules with good affinity to the desired biological target. In this work, weshow that recurrent neural networks can be trained as generative models formolecular structures, similar to statistical language models in naturallanguage processing. We demonstrate that the properties of the generatedmolecules correlate very well with the properties of the molecules used totrain the model. In order to enrich libraries with molecules active towards agiven biological target, we propose to fine-tune the model with small sets ofmolecules, which are known to be active against that target.  Against Staphylococcus aureus, the model reproduced 14% of 6051 hold-out testmolecules that medicinal chemists designed, whereas against Plasmodiumfalciparum (Malaria) it reproduced 28% of 1240 test molecules. When coupledwith a scoring function, our model can perform the complete de novo drug designcycle to generate large sets of novel molecules for drug discovery.",Generating Focussed Molecule Libraries for Drug Discovery with Recurrent  Neural Networks
382,Nuclear,,,Nuclear,,"Deep reinforcement learning (RL) methods generally engage in exploratorybehavior through noise injection in the action space. An alternative is to addnoise directly to the agent's parameters, which can lead to more consistentexploration and a richer set of behaviors. Methods such as evolutionarystrategies use parameter perturbations, but discard all temporal structure inthe process and require significantly more samples. Combining parameter noisewith traditional RL methods allows to combine the best of both worlds. Wedemonstrate that both off- and on-policy methods benefit from this approachthrough experimental comparison of DQN, DDPG, and TRPO on high-dimensionaldiscrete action environments as well as continuous control tasks. Our resultsshow that RL with parameter noise learns more efficiently than traditional RLwith action space noise and evolutionary strategies individually.",Parameter Space Noise for Exploration
383,,,,,,"With the development of neural networks based machine learning and theirusage in mission critical applications, voices are rising against the\textit{black box} aspect of neural networks as it becomes crucial tounderstand their limits and capabilities. With the rise of neuromorphichardware, it is even more critical to understand how a neural network, as adistributed system, tolerates the failures of its computing nodes, neurons, andits communication channels, synapses. Experimentally assessing the robustnessof neural networks involves the quixotic venture of testing all the possiblefailures, on all the possible inputs, which ultimately hits a combinatorialexplosion for the first, and the impossibility to gather all the possibleinputs for the second.  In this paper, we prove an upper bound on the expected error of the outputwhen a subset of neurons crashes. This bound involves dependencies on thenetwork parameters that can be seen as being too pessimistic in the averagecase. It involves a polynomial dependency on the Lipschitz coefficient of theneurons activation function, and an exponential dependency on the depth of thelayer where a failure occurs. We back up our theoretical results withexperiments illustrating the extent to which our prediction matches thedependencies between the network parameters and robustness. Our results showthat the robustness of neural networks to the average crash can be estimatedwithout the need to neither test the network on all failure configurations, noraccess the training set used to train the network, both of which arepractically impossible requirements.",On The Robustness of a Neural Network
384,,,,,,"In this paper we introduce ZhuSuan, a python probabilistic programminglibrary for Bayesian deep learning, which conjoins the complimentary advantagesof Bayesian methods and deep learning. ZhuSuan is built upon Tensorflow. Unlikeexisting deep learning libraries, which are mainly designed for deterministicneural networks and supervised tasks, ZhuSuan is featured for its deep rootinto Bayesian inference, thus supporting various kinds of probabilistic models,including both the traditional hierarchical Bayesian models and recent deepgenerative models. We use running examples to illustrate the probabilisticprogramming on ZhuSuan, including Bayesian logistic regression, variationalauto-encoders, deep sigmoid belief networks and Bayesian recurrent neuralnetworks.",ZhuSuan: A Library for Bayesian Deep Learning
385,,,,,,"The most data-efficient algorithms for reinforcement learning in robotics aremodel-based policy search algorithms, which alternate between learning adynamical model of the robot and optimizing a policy to maximize the expectedreturn given the model and its uncertainties. Among the few proposedapproaches, the recently introduced Black-DROPS algorithm exploits a black-boxoptimization algorithm to achieve both high data-efficiency and goodcomputation times when several cores are used; nevertheless, like allmodel-based policy search approaches, Black-DROPS does not scale to highdimensional state/action spaces. In this paper, we introduce a new modellearning procedure in Black-DROPS that leverages parameterized black-box priorsto (1) scale up to high-dimensional systems, and (2) be robust to largeinaccuracies of the prior information. We demonstrate the effectiveness of ourapproach with the ""pendubot"" swing-up task in simulation and with a physicalhexapod robot (48D state space, 18D action space) that has to walk forward asfast as possible. The results show that our new algorithm is moredata-efficient than previous model-based policy search algorithms (with andwithout priors) and that it can allow a physical 6-legged robot to learn newgaits in only 16 to 30 seconds of interaction time.",Using Parameterized Black-Box Priors to Scale Up Model-Based Policy  Search for Robotics
386,Data,,,Data,,"One of the most interesting features of Bayesian optimization for directpolicy search is that it can leverage priors (e.g., from simulation or fromprevious tasks) to accelerate learning on a robot. In this paper, we areinterested in situations for which several priors exist but we do not know inadvance which one fits best the current situation. We tackle this problem byintroducing a novel acquisition function, called Most Likely ExpectedImprovement (MLEI), that combines the likelihood of the priors and the expectedimprovement. We evaluate this new acquisition function on a transfer learningtask for a 5-DOF planar arm and on a possibly damaged, 6-legged robot that hasto learn to walk on flat ground and on stairs, with priors corresponding todifferent stairs and different kinds of damages. Our results show that MLEIeffectively identifies and exploits the priors, even when there is no obviousmatch between the current situations and the priors.",Bayesian Optimization with Automatic Prior Selection for Data-Efficient  Direct Policy Search
387,,,,,,"In this paper, we study the representational power of deep neural networks(DNN) that belong to the family of piecewise-linear (PWL) functions, based onPWL activation units such as rectifier or maxout. We investigate the complexityof such networks by studying the number of linear regions of the PWL function.Typically, a PWL function from a DNN can be seen as a large family of linearfunctions acting on millions of such regions. We directly build upon the workof Montufar et al. (2014), Montufar (2017) and Raghu et al. (2017) by refiningthe upper and lower bounds on the number of linear regions for rectified andmaxout networks. In addition to achieving tighter bounds, we also develop anovel method to perform exact enumeration or counting of the number of linearregions with a mixed-integer linear formulation that maps the input space tooutput. We use this new capability to visualize how the number of linearregions change while training DNNs.",Bounding and Counting Linear Regions of Deep Neural Networks
388,Chemistry,,,Chemistry,,"Neuromorphic hardware tends to pose limits on the connectivity of deepnetworks that one can run on them. But also generic hardware and softwareimplementations of deep learning run more efficiently for sparse networks.Several methods exist for pruning connections of a neural network after it wastrained without connectivity constraints. We present an algorithm, DEEP R, thatenables us to train directly a sparsely connected neural network. DEEP Rautomatically rewires the network during supervised training so thatconnections are there where they are most needed for the task, while its totalnumber is all the time strictly bounded. We demonstrate that DEEP R can be usedto train very sparse feedforward and recurrent neural networks on standardbenchmark tasks with just a minor loss in performance. DEEP R is based on arigorous theoretical foundation that views rewiring as stochastic sampling ofnetwork configurations from a posterior.",Deep Rewiring: Training very sparse deep networks
389,Nuclear,,,Nuclear,,"To compare entities of differing types and structural components, theartificial neural network paradigm was used to cross-compare structuralcomponents between heterogeneous documents. Trainable weighted structuralcomponents were input into machine-learned activation functions of the neurons.The model was used for matching news articles and videos, where the inputs andactivation functions respectively consisted of term vectors and cosinesimilarity measures between the weighted structural components. The model wastested with different weights, achieving as high as 59.2% accuracy for matchingvideos to news articles. A mobile application user interface for recommendingrelated videos for news articles was developed to demonstrate consumer value,including its potential usefulness for cross-selling products from unrelatedcategories.",Comparing heterogeneous entities using artificial neural networks of  trainable weighted structural components and machine-learned activation  functions
390,DV,DV,,,,"We introduce the Self-Adaptive Goal Generation - Robust Intelligent AdaptiveCuriosity (SAGG-RIAC) architecture as an intrinsi- cally motivated goalexploration mechanism which allows active learning of inverse models inhigh-dimensional redundant robots. This allows a robot to efficiently andactively learn distributions of parameterized motor skills/policies that solvea corresponding distribution of parameterized tasks/goals. The architecturemakes the robot sample actively novel parameterized tasks in the task space,based on a measure of competence progress, each of which triggers low-levelgoal-directed learning of the motor policy pa- rameters that allow to solve it.For both learning and generalization, the system leverages regressiontechniques which allow to infer the motor policy parameters corresponding to agiven novel parameterized task, and based on the previously learntcorrespondences between policy and task parameters. We present experiments withhigh-dimensional continuous sensorimotor spaces in three different roboticsetups: 1) learning the inverse kinematics in a highly-redundant robotic arm,2) learning omnidirectional locomotion with motor primitives in a quadrupedrobot, 3) an arm learning to control a fishing rod with a flexible wire. Weshow that 1) exploration in the task space can be a lot faster than explorationin the actuator space for learning inverse models in redundant robots; 2)selecting goals maximizing competence progress creates developmentaltrajectories driving the robot to progressively focus on tasks of increasingcomplexity and is statistically significantly more efficient than selectingtasks randomly, as well as more efficient than different standard active motorbabbling methods; 3) this architecture allows the robot to actively discoverwhich parts of its task space it can learn to reach and which part it cannot.",Active Learning of Inverse Models with Intrinsically Motivated Goal  Exploration in Robots
391,Nuclear,,,Nuclear,,"In this work we present a novel end-to-end framework for tracking andclassifying a robot's surroundings in complex, dynamic and only partiallyobservable real-world environments. The approach deploys a recurrent neuralnetwork to filter an input stream of raw laser measurements in order todirectly infer object locations, along with their identity in both visible andoccluded areas. To achieve this we first train the network using unsupervisedDeep Tracking, a recently proposed theoretical framework for end-to-end spaceoccupancy prediction. We show that by learning to track on a large amount ofunsupervised data, the network creates a rich internal representation of itsenvironment which we in turn exploit through the principle of inductivetransfer of knowledge to perform the task of it's semantic classification. As aresult, we show that only a small amount of labelled data suffices to steer thenetwork towards mastering this additional task. Furthermore we propose a novelrecurrent neural network architecture specifically tailored to tracking andsemantic classification in real-world robotics applications. We demonstrate thetracking and classification performance of the method on real-world datacollected at a busy road junction. Our evaluation shows that the proposedend-to-end framework compares favourably to a state-of-the-art, model-freetracking solution and that it outperforms a conventional one-shot trainingscheme for semantic classification.",End-to-End Tracking and Semantic Segmentation Using Recurrent Neural  Networks
392,Chemistry,Chemistry,,,,"This paper presents to the best of our knowledge the first end-to-end objecttracking approach which directly maps from raw sensor input to object tracks insensor space without requiring any feature engineering or system identificationin the form of plant or sensor models. Specifically, our system accepts astream of raw sensor data at one end and, in real-time, produces an estimate ofthe entire environment state at the output including even occluded objects. Weachieve this by framing the problem as a deep learning task and exploitsequence models in the form of recurrent neural networks to learn a mappingfrom sensor measurements to object tracks. In particular, we propose a learningmethod based on a form of input dropout which allows learning in anunsupervised manner, only based on raw, occluded sensor data without access toground-truth annotations. We demonstrate our approach using a synthetic datasetdesigned to mimic the task of tracking objects in 2D laser data -- as commonlyencountered in robotics applications -- and show that it learns to track manydynamic objects despite occlusions and the presence of sensor noise.",Deep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks
393,Physics,Physics,,,,"While great strides have been made in using deep learning algorithms to solvesupervised learning tasks, the problem of unsupervised learning - leveragingunlabeled examples to learn about the structure of a domain - remains adifficult unsolved challenge. Here, we explore prediction of future frames in avideo sequence as an unsupervised learning rule for learning about thestructure of the visual world. We describe a predictive neural network(""PredNet"") architecture that is inspired by the concept of ""predictive coding""from the neuroscience literature. These networks learn to predict future framesin a video sequence, with each layer in the network making local predictionsand only forwarding deviations from those predictions to subsequent networklayers. We show that these networks are able to robustly learn to predict themovement of synthetic (rendered) objects, and that in doing so, the networkslearn internal representations that are useful for decoding latent objectparameters (e.g. pose) that support object recognition with fewer trainingviews. We also show that these networks can scale to complex natural imagestreams (car-mounted camera videos), capturing key aspects of both egocentricmovement and the movement of objects in the visual scene, and therepresentation learned in this setting is useful for estimating the steeringangle. Altogether, these results suggest that prediction represents a powerfulframework for unsupervised learning, allowing for implicit learning of objectand scene structure.",Deep Predictive Coding Networks for Video Prediction and Unsupervised  Learning
394,,,,,,"This paper proposes a computationally efficient approach to detecting objectsnatively in 3D point clouds using convolutional neural networks (CNNs). Inparticular, this is achieved by leveraging a feature-centric voting scheme toimplement novel convolutional layers which explicitly exploit the sparsityencountered in the input. To this end, we examine the trade-off betweenaccuracy and speed for different architectures and additionally propose to usean L1 penalty on the filter activations to further encourage sparsity in theintermediate representations. To the best of our knowledge, this is the firstwork to propose sparse convolutional layers and L1 regularisation for efficientlarge-scale processing of 3D data. We demonstrate the efficacy of our approachon the KITTI object detection benchmark and show that Vote3Deep models with asfew as three layers outperform the previous state of the art in both laser andlaser-vision based approaches by margins of up to 40% while remaining highlycompetitive in terms of processing time.",Vote3Deep: Fast Object Detection in 3D Point Clouds Using Efficient  Convolutional Neural Networks
395,Data,,,Data,,"We propose studying GAN training dynamics as regret minimization, which is incontrast to the popular view that there is consistent minimization of adivergence between real and generated distributions. We analyze the convergenceof GAN training from this new point of view to understand why mode collapsehappens. We hypothesize the existence of undesirable local equilibria in thisnon-convex game to be responsible for mode collapse. We observe that theselocal equilibria often exhibit sharp gradients of the discriminator functionaround some real data points. We demonstrate that these degenerate localequilibria can be avoided with a gradient penalty scheme called DRAGAN. We showthat DRAGAN enables faster training, achieves improved stability with fewermode collapses, and leads to generator networks with better modelingperformance across a variety of architectures and objective functions.",On Convergence and Stability of GANs
396,,,,,,"Imitation learning is an effective approach for autonomous systems to acquirecontrol policies when an explicit reward function is unavailable, usingsupervision provided as demonstrations from an expert, typically a humanoperator. However, standard imitation learning methods assume that the agentreceives examples of observation-action tuples that could be provided, forinstance, to a supervised learning algorithm. This stands in contrast to howhumans and animals imitate: we observe another person performing some behaviorand then figure out which actions will realize that behavior, compensating forchanges in viewpoint, surroundings, and embodiment. We term this kind ofimitation learning as imitation-from-observation and propose an imitationlearning method based on video prediction with context translation and deepreinforcement learning. This lifts the assumption in imitation learning thatthe demonstration should consist of observations and actions in the sameenvironment, and enables a variety of interesting applications, includinglearning robotic skills that involve tool use simply by observing videos ofhuman tool use. Our experimental results show that our approach can performimitation-from-observation for a variety of real-world robotic tasks modeled oncommon household chores, acquiring skills such as sweeping from videos of ahuman demonstrator. Videos can be found athttps://sites.google.com/site/imitationfromobservation",Imitation from Observation: Learning to Imitate Behaviors from Raw Video  via Context Translation
397,,,,,,"Unsupervised pretraining and dropout have been well studied, especially withrespect to regularization and output consistency. However, our understandingabout the explicit convergence rates of the parameter estimates, and theirdependence on the learning (like denoising and dropout rate) and structural(like depth and layer lengths) aspects of the network is less mature. Aninteresting question in this context is to ask if the network structure could""guide"" the choices of such learning parameters. In this work, we explore thesegaps between network structure, the learning mechanisms and their interactionwith parameter convergence rates. We present a way to address these issuesbased on the backpropagation convergence rates for general nonconvex objectivesusing first-order information. We then incorporate two learning mechanisms intothis general framework -- denoising autoencoder and dropout, and subsequentlyderive the convergence rates of deep networks. Building upon these bounds, weprovide insights into the choices of learning parameters and network sizes thatachieve certain levels of convergence accuracy. The results derived heresupport existing empirical observations, and we also conduct a set ofexperiments to evaluate them.",Convergence rates for pretraining and dropout: Guiding learning  parameters using network structure
398,Physics,Physics,,,,"Deep Convolutional Neural Networks (CNN) enforces supervised information onlyat the output layer, and hidden layers are trained by back propagating theprediction error from the output layer without explicit supervision. We proposea supervised feature learning approach, Label Consistent Neural Network, whichenforces direct supervision in late hidden layers. We associate each neuron ina hidden layer with a particular class label and encourage it to be activatedfor input signals from the same class. More specifically, we introduce a labelconsistency regularization called ""discriminative representation error"" lossfor late hidden layers and combine it with classification error loss to buildour overall objective function. This label consistency constraint alleviatesthe common problem of gradient vanishing and tends to faster convergence; italso makes the features derived from late hidden layers discriminative enoughfor classification even using a simple $k$-NN classifier, since input signalsfrom the same class will have very similar representations. Experimentalresults demonstrate that our approach achieves state-of-the-art performances onseveral public benchmarks for action and object category recognition.",Learning Discriminative Features via Label Consistent Neural Network
399,,,,,,"This paper proposes an out-of-sample extension framework for a globalmanifold learning algorithm (Isomap) that uses temporal information inout-of-sample points in order to make the embedding more robust to noise andartifacts. Given a set of noise-free training data and its embedding, theproposed framework extends the embedding for a noisy time series. This isachieved by adding a spatio-temporal compactness term to the optimizationobjective of the embedding. To the best of our knowledge, this is the firstmethod for out-of-sample extension of manifold embeddings that leverages timinginformation available for the extension set. Experimental results demonstratethat our out-of-sample extension algorithm renders a more robust and accurateembedding of sequentially ordered image data in the presence of various noiseand artifacts when compared to other timing-aware embeddings. Additionally, weshow that an out-of-sample extension framework based on the proposed algorithmoutperforms the state of the art in eye-gaze estimation.",Out-of-Sample Extension for Dimensionality Reduction of Noisy Time  Series
400,Nuclear,,,Nuclear,,"Machine learning methods in general and Deep Neural Networks in particularhave shown to be vulnerable to adversarial perturbations. So far thisphenomenon has mainly been studied in the context of whole-imageclassification. In this contribution, we analyse how adversarial perturbationscan affect the task of semantic segmentation. We show how existing adversarialattackers can be transferred to this task and that it is possible to createimperceptible adversarial perturbations that lead a deep network to misclassifyalmost all pixels of a chosen class while leaving network prediction nearlyunchanged outside this class.",Adversarial Examples for Semantic Image Segmentation
401,,,,,,"Many machine learning algorithms are vulnerable to almost imperceptibleperturbations of their inputs. So far it was unclear how much risk adversarialperturbations carry for the safety of real-world machine learning applicationsbecause most methods used to generate such perturbations rely either ondetailed model information (gradient-based attacks) or on confidence scoressuch as class probabilities (score-based attacks), neither of which areavailable in most real-world scenarios. In many such cases one currently needsto retreat to transfer-based attacks which rely on cumbersome substitutemodels, need access to the training data and can be defended against. Here weemphasise the importance of attacks which solely rely on the final modeldecision. Such decision-based attacks are (1) applicable to real-worldblack-box models such as autonomous cars, (2) need less knowledge and areeasier to apply than transfer-based attacks and (3) are more robust to simpledefences than gradient- or score-based attacks. Previous attacks in thiscategory were limited to simple models or simple datasets. Here we introducethe Boundary Attack, a decision-based attack that starts from a largeadversarial perturbation and then seeks to reduce the perturbation whilestaying adversarial. The attack is conceptually simple, requires close to nohyperparameter tuning, does not rely on substitute models and is competitivewith the best gradient-based attacks in standard computer vision tasks likeImageNet. We apply the attack on two black-box algorithms from Clarifai.com.The Boundary Attack in particular and the class of decision-based attacks ingeneral open new avenues to study the robustness of machine learning models andraise new questions regarding the safety of deployed machine learning systems.An implementation of the attack is available as part of Foolbox athttps://github.com/bethgelab/foolbox .",Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box  Machine Learning Models
402,,,,,,"Effective and efficient mitigation of malware is a long-time endeavor in theinformation security community. The development of an anti-malware system thatcan counteract an unknown malware is a prolific activity that may benefitseveral sectors. We envision an intelligent anti-malware system that utilizesthe power of deep learning (DL) models. Using such models would enable thedetection of newly-released malware through mathematical generalization. Thatis, finding the relationship between a given malware $x$ and its correspondingmalware family $y$, $f: x \mapsto y$. To accomplish this feat, we used theMalimg dataset (Nataraj et al., 2011) which consists of malware images thatwere processed from malware binaries, and then we trained the following DLmodels 1 to classify each malware family: CNN-SVM (Tang, 2013), GRU-SVM(Agarap, 2017), and MLP-SVM. Empirical evidence has shown that the GRU-SVMstands out among the DL models with a predictive accuracy of ~84.92%. Thisstands to reason for the mentioned model had the relatively most sophisticatedarchitecture design among the presented models. The exploration of an even moreoptimal DL-SVM model is the next stage towards the engineering of anintelligent anti-malware system.",Towards Building an Intelligent Anti-Malware System: A Deep Learning  Approach using Support Vector Machine (SVM) for Malware Classification
403,Physics,,,Physics,,"Feature extraction has gained increasing attention in the field of machinelearning, as in order to detect patterns, extract information, or predictfuture observations from big data, the urge of informative features is crucial.The process of extracting features is highly linked to dimensionality reductionas it implies the transformation of the data from a sparse high-dimensionalspace, to higher level meaningful abstractions. This dissertation employsNeural Networks for distributed paragraph representations, and Latent DirichletAllocation to capture higher level features of paragraph vectors. AlthoughNeural Networks for distributed paragraph representations are considered thestate of the art for extracting paragraph vectors, we show that a quick topicanalysis model such as Latent Dirichlet Allocation can provide meaningfulfeatures too. We evaluate the two methods on the CMU Movie Summary Corpus, acollection of 25,203 movie plot summaries extracted from Wikipedia. Finally,for both approaches, we use K-Nearest Neighbors to discover similar movies, andplot the projected representations using T-Distributed Stochastic NeighborEmbedding to depict the context similarities. These similarities, expressed asmovie distances, can be used for movies recommendation. The recommended moviesof this approach are compared with the recommended movies from IMDB, which usea collaborative filtering recommendation approach, to show that our two modelscould constitute either an alternative or a supplementary recommendationapproach.",Feature extraction using Latent Dirichlet Allocation and Neural  Networks: A case study on movie synopses
404,Nuclear,,,Nuclear,,"During the past decade, several areas of speech and language understandinghave witnessed substantial breakthroughs from the use of data-driven models. Inthe area of dialogue systems, the trend is less obvious, and most practicalsystems are still built through significant engineering and expert knowledge.Nevertheless, several recent results suggest that data-driven approaches arefeasible and quite promising. To facilitate research in this area, we havecarried out a wide survey of publicly available datasets suitable fordata-driven learning of dialogue systems. We discuss important characteristicsof these datasets, how they can be used to learn diverse dialogue strategies,and their other potential uses. We also examine methods for transfer learningbetween datasets and the use of external knowledge. Finally, we discussappropriate choice of evaluation metrics for the learning objective.",A Survey of Available Corpora for Building Data-Driven Dialogue Systems
405,Data,Data,,,,"Word embedding maps words into a low-dimensional continuous embedding spaceby exploiting the local word collocation patterns in a small context window. Onthe other hand, topic modeling maps documents onto a low-dimensional topicspace, by utilizing the global word collocation patterns in the same document.These two types of patterns are complementary. In this paper, we propose agenerative topic embedding model to combine the two types of patterns. In ourmodel, topics are represented by embedding vectors, and are shared acrossdocuments. The probability of each word is influenced by both its local contextand its topic. A variational inference method yields the topic embeddings aswell as the topic mixing proportions for each document. Jointly they representthe document in a low-dimensional continuous space. In two documentclassification tasks, our method performs better than eight existing methods,with fewer features. In addition, we illustrate with an example that our methodcan generate coherent topics even based on only one document.",Generative Topic Embedding: a Continuous Representation of Documents  (Extended Version with Proofs)
406,DV,DV,,,,"As entity type systems become richer and more fine-grained, we expect thenumber of types assigned to a given entity to increase. However, mostfine-grained typing work has focused on datasets that exhibit a low degree oftype multiplicity. In this paper, we consider the high-multiplicity regimeinherent in data sources such as Wikipedia that have semi-open type systems. Weintroduce a set-prediction approach to this problem and show that our modeloutperforms unstructured baselines on a new Wikipedia-based fine-grained typingcorpus.",Fine-Grained Entity Typing with High-Multiplicity Assignments
407,Data,,,Data,,"As language and visual understanding by machines progresses rapidly, we areobserving an increasing interest in holistic architectures that tightlyinterlink both modalities in a joint learning and inference process. This trendhas allowed the community to progress towards more challenging and open tasksand refueled the hope at achieving the old AI dream of building machines thatcould pass a turing test in open domains. In order to steadily make progresstowards this goal, we realize that quantifying performance becomes increasinglydifficult. Therefore we ask how we can precisely define such challenges and howwe can evaluate different algorithms on this open tasks? In this paper, wesummarize and discuss such challenges as well as try to give answers whereappropriate options are available in the literature. We exemplify some of thesolutions on a recently presented dataset of question-answering task based onreal-world indoor images that establishes a visual turing challenge. Finally,we argue despite the success of unique ground-truth annotation, we likely haveto step away from carefully curated dataset and rather rely on 'socialconsensus' as the main driving force to create suitable benchmarks. Providingcoverage in this inherently ambiguous output space is an emerging challengethat we face in order to make quantifiable progress in this area.",Towards a Visual Turing Challenge
408,,,,,,"A growing field in robotics and Artificial Intelligence (AI) research ishuman-robot collaboration, whose target is to enable effective teamwork betweenhumans and robots. However, in many situations human teams are still superiorto human-robot teams, primarily because human teams can easily agree on acommon goal with language, and the individual members observe each othereffectively, leveraging their shared motor repertoire and sensorimotorresources. This paper shows that for cognitive robots it is possible, andindeed fruitful, to combine knowledge acquired from interacting with elementsof the environment (affordance exploration) with the probabilistic observationof another agent's actions.  We propose a model that unites (i) learning robot affordances and worddescriptions with (ii) statistical recognition of human gestures with visionsensors. We discuss theoretical motivations, possible implementations, and weshow initial results which highlight that, after having acquired knowledge ofits surrounding environment, a humanoid robot can generalize this knowledge tothe case when it observes another agent (human partner) performing the samemotor actions previously executed during training.","Interactive Robot Learning of Gestures, Language and Affordances"
409,,,,,,"Automatic transcriptions of consumer-generated multi-media content such as""Youtube"" videos still exhibit high word error rates. Such data typicallyoccupies a very broad domain, has been recorded in challenging conditions, withcheap hardware and a focus on the visual modality, and may have beenpost-processed or edited. In this paper, we extend our earlier work on adaptingthe acoustic model of a DNN-based speech recognition system to an RNN languagemodel and show how both can be adapted to the objects and scenes that can beautomatically detected in the video. We are working on a corpus of ""how-to""videos from the web, and the idea is that an object that can be seen (""car""),or a scene that is being detected (""kitchen"") can be used to condition bothmodels on the ""context"" of the recording, thereby reducing perplexity andimproving transcription. We achieve good improvements in both cases and compareand analyze the respective reductions in word error rate. We expect that ourresults can be used for any type of speech processing in which ""context""information is available, for example in robotics, man-machine interaction, orwhen indexing large audio-visual archives, and should ultimately help to bringtogether the ""video-to-text"" and ""speech-to-text"" communities.",Visual Features for Context-Aware Speech Recognition
410,Data,,,Data,,"In this work we propose a blackbox intervention method for visual dialogmodels, with the aim of assessing the contribution of individual linguistic orvisual components. Concretely, we conduct structured or randomizedinterventions that aim to impair an individual component of the model, andobserve changes in task performance. We reproduce a state-of-the-art visualdialog model and demonstrate that our methodology yields surprising insights,namely that both dialog and image information have minimal contributions totask performance. The intervention method presented here can be applied as asanity check for the strength and robustness of each component in visual dialogsystems.",Examining Cooperation in Visual Dialog Models
411,,,,,,"Sports channel video portals offer an exciting domain for research onmultimodal, multilingual analysis. We present methods addressing the problem ofautomatic video highlight prediction based on joint visual features and textualanalysis of the real-world audience discourse with complex slang, in bothEnglish and traditional Chinese. We present a novel dataset based on League ofLegends championships recorded from North American and Taiwanese Twitch.tvchannels (will be released for further research), and demonstrate strongresults on these using multimodal, character-level CNN-RNN model architectures.",Video Highlight Prediction Using Audience Chat Reactions
412,Physics,Physics,,,,"Modern automatic speech recognition (ASR) systems need to be robust underacoustic variability arising from environmental, speaker, channel, andrecording conditions. Ensuring such robustness to variability is a challenge inmodern day neural network-based ASR systems, especially when all types ofvariability are not seen during training. We attempt to address this problem byencouraging the neural network acoustic model to learn invariant featurerepresentations. We use ideas from recent research on image generation usingGenerative Adversarial Networks and domain adaptation ideas extendingadversarial gradient-based training. A recent work from Ganin et al. proposesto use adversarial training for image domain adaptation by using anintermediate representation from the main target classification network todeteriorate the domain classifier performance through a separate neuralnetwork. Our work focuses on investigating neural architectures which producerepresentations invariant to noise conditions for ASR. We evaluate the proposedarchitecture on the Aurora-4 task, a popular benchmark for noise robust ASR. Weshow that our method generalizes better than the standard multi-conditiontraining especially when only a few noise categories are seen during training.",Invariant Representations for Noisy Speech Recognition
413,,,,,,"This paper presents a self-supervised method for detecting the active speakerin a multi-person spoken interaction scenario. We argue that this capability isa fundamental prerequisite for any artificial cognitive system attempting toacquire language in social settings. Our methods are able to detect anarbitrary number of possibly overlapping active speakers based exclusively onvisual information about their face. Our methods do not rely on externalannotations, thus complying with cognitive development. Instead, they useinformation from the auditory modality to support learning in the visualdomain. The methods have been extensively evaluated on a large multi-personface-to-face interaction dataset. The results reach an accuracy of 80% on amulti-speaker setting. We believe this system represents an essential componentof any artificial cognitive system or robotic platform engaging in socialinteraction.",Self-Supervised Vision-Based Detection of the Active Speaker as a  Prerequisite for Socially-Aware Language Acquisition
414,Physics,Physics,,,,"In this paper, we describe a solution to tackle a common set of challenges ine-commerce, which arise from the fact that new products are continually beingadded to the catalogue. The challenges involve properly personalising thecustomer experience, forecasting demand and planning the product range. Weargue that the foundational piece to solve all of these problems is havingconsistent and detailed information about each product, information that israrely available or consistent given the multitude of suppliers and types ofproducts. We describe in detail the architecture and methodology implemented atASOS, one of the world's largest fashion e-commerce retailers, to tackle thisproblem. We then show how this quantitative understanding of the products canbe leveraged to improve recommendations in a hybrid recommender systemapproach.",Product Characterisation towards Personalisation: Learning Attributes  from Unstructured Data to Recommend Fashion Products
415,Physics,,,Physics,,"The speech code is a vehicle of language: it defines a set of forms used by acommunity to carry information. Such a code is necessary to support thelinguistic interactions that allow humans to communicate. How then may a speechcode be formed prior to the existence of linguistic interactions? Moreover, thehuman speech code is discrete and compositional, shared by all the individualsof a community but different across communities, and phoneme inventories arecharacterized by statistical regularities. How can a speech code with theseproperties form? We try to approach these questions in the paper, using the""methodology of the artificial"". We build a society of artificial agents, anddetail a mechanism that shows the formation of a discrete speech code withoutpre-supposing the existence of linguistic capacities or of coordinatedinteractions. The mechanism is based on a low-level model of sensory-motorinteractions. We show that the integration of certain very simple and nonlanguage-specific neural devices leads to the formation of a speech code thathas properties similar to the human speech code. This result relies on theself-organizing properties of a generic coupling between perception andproduction within agents, and on the interactions between agents. Theartificial system helps us to develop better intuitions on how speech mighthave appeared, by showing how self-organization might have helped naturalselection to find speech.",The Self-Organization of Speech Sounds
416,,,,,,"The F-measure or F-score is one of the most commonly used single numbermeasures in Information Retrieval, Natural Language Processing and MachineLearning, but it is based on a mistake, and the flawed assumptions render itunsuitable for use in most contexts! Fortunately, there are betteralternatives.","What the F-measure doesn't measure: Features, Flaws, Fallacies and Fixes"
417,Physics,Physics,,,,"PAQ8 is an open source lossless data compression algorithm that currentlyachieves the best compression rates on many benchmarks. This report presents adetailed description of PAQ8 from a statistical machine learning perspective.It shows that it is possible to understand some of the modules of PAQ8 and usethis understanding to improve the method. However, intuitive statisticalexplanations of the behavior of other modules remain elusive. We hope thedescription in this report will be a starting point for discussions that willincrease our understanding, lead to improvements to PAQ8, and facilitate atransfer of knowledge from PAQ8 to other machine learning methods, such arecurrent neural networks and stochastic memoizers. Finally, the reportpresents a broad range of new applications of PAQ to machine learning tasksincluding language modeling and adaptive text prediction, adaptive gameplaying, classification, and compression using features from the field of deeplearning.",A Machine Learning Perspective on Predictive Coding with PAQ
418,Chemistry,Chemistry,,,,"Recently, there has been a renewed interest in the machine learning communityfor variants of a sparse greedy approximation procedure for concaveoptimization known as {the Frank-Wolfe (FW) method}. In particular, thisprocedure has been successfully applied to train large-scale instances ofnon-linear Support Vector Machines (SVMs). Specializing FW to SVM training hasallowed to obtain efficient algorithms but also important theoretical results,including convergence analysis of training algorithms and new characterizationsof model sparsity.  In this paper, we present and analyze a novel variant of the FW method basedon a new way to perform away steps, a classic strategy used to accelerate theconvergence of the basic FW procedure. Our formulation and analysis is focusedon a general concave maximization problem on the simplex. However, thespecialization of our algorithm to quadratic forms is strongly related to someclassic methods in computational geometry, namely the Gilbert and MDMalgorithms.  On the theoretical side, we demonstrate that the method matches theguarantees in terms of convergence rate and number of iterations obtained byusing classic away steps. In particular, the method enjoys a linear rate ofconvergence, a result that has been recently proved for MDM on quadratic forms.  On the practical side, we provide experiments on several classificationdatasets, and evaluate the results using statistical tests. Experiments showthat our method is faster than the FW method with classic away steps, and workswell even in the cases in which classic away steps slow down the algorithm.Furthermore, these improvements are obtained without sacrificing the predictiveaccuracy of the obtained SVM model.",A Novel Frank-Wolfe Algorithm. Analysis and Applications to Large-Scale  SVM Training
419,Nuclear,,,Nuclear,,"Despite significant progress in object categorization, in recent years, anumber of important challenges remain, mainly, ability to learn from limitedlabeled data and ability to recognize object classes within large, potentiallyopen, set of labels. Zero-shot learning is one way of addressing thesechallenges, but it has only been shown to work with limited sized classvocabularies and typically requires separation between supervised andunsupervised classes, allowing former to inform the latter but not vice versa.We propose the notion of semi-supervised vocabulary-informed learning toalleviate the above mentioned challenges and address problems of supervised,zero-shot and open set recognition using a unified framework. Specifically, wepropose a maximum margin framework for semantic manifold-based recognition thatincorporates distance constraints from (both supervised and unsupervised)vocabulary atoms, ensuring that labeled samples are projected closest to theircorrect prototypes, in the embedding space, than to others. We show thatresulting model shows improvements in supervised, zero-shot, and large open setrecognition, with up to 310K class vocabulary on AwA and ImageNet datasets.",Semi-supervised Vocabulary-informed Learning
420,,,,,,"To cope with the high level of ambiguity faced in domains such as ComputerVision or Natural Language processing, robust prediction methods often searchfor a diverse set of high-quality candidate solutions or proposals. Instructured prediction problems, this becomes a daunting task, as the solutionspace (image labelings, sentence parses, etc.) is exponentially large. We studygreedy algorithms for finding a diverse subset of solutions instructured-output spaces by drawing new connections between submodularfunctions over combinatorial item sets and High-Order Potentials (HOPs) studiedfor graphical models. Specifically, we show via examples that when marginalgains of submodular diversity functions allow structured representations, thisenables efficient (sub-linear time) approximate maximization by reducing thegreedy augmentation step to inference in a factor graph with appropriatelyconstructed HOPs. We discuss benefits, tradeoffs, and show that ourconstructions lead to significantly better proposals.",Submodular meets Structured: Finding Diverse Subsets in  Exponentially-Large Structured Item Sets
421,,,,,,"Many problems in image processing and computer vision (e.g. colorization,style transfer) can be posed as 'manipulating' an input image into acorresponding output image given a user-specified guiding signal. A holy-grailsolution towards generic image manipulation should be able to efficiently alteran input image with any personalized signals (even signals unseen duringtraining), such as diverse paintings and arbitrary descriptive attributes.However, existing methods are either inefficient to simultaneously processmultiple signals (let alone generalize to unseen signals), or unable to handlesignals from other modalities. In this paper, we make the first attempt toaddress the zero-shot image manipulation task. We cast this problem asmanipulating an input image according to a parametric model whose keyparameters can be conditionally generated from any guiding signal (even unseenones). To this end, we propose the Zero-shot Manipulation Net (ZM-Net), afully-differentiable architecture that jointly optimizes animage-transformation network (TNet) and a parameter network (PNet). The PNetlearns to generate key transformation parameters for the TNet given any guidingsignal while the TNet performs fast zero-shot image manipulation according toboth signal-dependent parameters from the PNet and signal-invariant parametersfrom the TNet itself. Extensive experiments show that our ZM-Net can performhigh-quality image manipulation conditioned on different forms of guidingsignals (e.g. style images and attributes) in real-time (tens of millisecondsper image) even for unseen signals. Moreover, a large-scale style dataset withover 20,000 style images is also constructed to promote further research.",ZM-Net: Real-time Zero-shot Image Manipulation Network
422,Data,,,Data,,"We propose an intuitive generalization to the Generative Adversarial Networks(GANs) and its conditional variants to address the well known mode collapseproblem. Firstly, we propose a multi-agent GAN architecture incorporatingmultiple generators and one discriminator. Secondly, to enforce differentgenerators to capture diverse high probability modes, we modify discriminator'sobjective function where along with finding the real and fake samples, thediscriminator has to identify the generator that generated the fake sample.Intuitively, to succeed in this task, the discriminator must learn to pushdifferent generators towards different identifiable modes. Our framework(MAD-GAN) is generalizable in the sense that it can be easily combined withother existing variants of GANs to produce diverse samples. We performextensive experiments on synthetic and real datasets and compare MAD-GAN withdifferent variants of GAN. We show high quality diverse sample generations forthe challenging tasks such as image-to-image translation (known to learn deltadistribution) and face generation. In addition, we show that MAD-GAN is able todisentangle different modalities even when trained using highly challengingmulti-view dataset (mixture of forests, icebergs, bedrooms etc). In the end, wealso show its efficacy for the unsupervised feature representation task. In theappendix we introduce a similarity based competing objective which encouragesthe different generators to generate varied samples judged by a user definedsimilarity metric. We show extensive evaluations on a 1-D setting of mixture ofgaussians for non parametric density estimation. The theoretical proofs backthe efficacy of the framework and explains why various generators are pushedtowards distinct clusters of modes.",Multi-Agent Diverse Generative Adversarial Networks
423,,,,,,"Generative Adversarial Nets (GANs) represent an important milestone foreffective generative models, which has inspired numerous variants seeminglydifferent from each other. One of the main contributions of this paper is toreveal a unified geometric structure in GAN and its variants. Specifically, weshow that the adversarial generative model training can be decomposed intothree geometric steps: separating hyperplane search, discriminator parameterupdate away from the separating hyperplane, and the generator update along thenormal vector direction of the separating hyperplane. This geometric intuitionreveals the limitations of the existing approaches and leads us to propose anew formulation called geometric GAN using SVM separating hyperplane thatmaximizes the margin. Our theoretical analysis shows that the geometric GANconverges to a Nash equilibrium between the discriminator and generator. Inaddition, extensive numerical results show that the superior performance ofgeometric GAN.",Geometric GAN
424,,,,,,"Training deep networks is expensive and time-consuming with the trainingperiod increasing with data size and growth in model parameters. In this paper,we provide a framework for distributed training of deep networks over a clusterof CPUs in Apache Spark. The framework implements both Data Parallelism andModel Parallelism making it suitable to use for deep networks which requirehuge training data and model parameters which are too big to fit into thememory of a single machine. It can be scaled easily over a cluster of cheapcommodity hardware to attain significant speedup and obtain better resultsmaking it quite economical as compared to farm of GPUs and supercomputers. Wehave proposed a new algorithm for training of deep networks for the case whenthe network is partitioned across the machines (Model Parallelism) along withdetailed cost analysis and proof of convergence of the same. We have developedimplementations for Fully-Connected Feedforward Networks, Convolutional NeuralNetworks, Recurrent Neural Networks and Long Short-Term Memory architectures.We present the results of extensive simulations demonstrating the speedup andaccuracy obtained by our framework for different sizes of the data and modelparameters with variation in the number of worker cores/partitions; therebyshowing that our proposed framework can achieve significant speedup (upto 11Xfor CNN) and is also quite scalable.","A Data and Model-Parallel, Distributed and Scalable Framework for  Training of Deep Networks in Apache Spark"
425,,,,,,"Recently, deep neural networks have demonstrated excellent performances inrecognizing the age and gender on human face images. However, these models wereapplied in a black-box manner with no information provided about which facialfeatures are actually used for prediction and how these features depend onimage preprocessing, model initialization and architecture choice. We present astudy investigating these different effects.  In detail, our work compares four popular neural network architectures,studies the effect of pretraining, evaluates the robustness of the consideredalignment preprocessings via cross-method test set swapping and intuitivelyvisualizes the model's prediction strategies in given preprocessing conditionsusing the recent Layer-wise Relevance Propagation (LRP) algorithm. Ourevaluations on the challenging Adience benchmark show that suitable parameterinitialization leads to a holistic perception of the input, compensatingartefactual data representations. With a combination of simple preprocessingsteps, we reach state of the art performance in gender recognition.",Understanding and Comparing Deep Neural Networks for Age and Gender  Classification
426,Physics,Physics,,,,"We analyze the convergence of (stochastic) gradient descent algorithm forlearning a convolutional filter with Rectified Linear Unit (ReLU) activationfunction. Our analysis does not rely on any specific form of the inputdistribution and our proofs only use the definition of ReLU, in contrast withprevious works that are restricted to standard Gaussian input. We show that(stochastic) gradient descent with random initialization can learn theconvolutional filter in polynomial time and the convergence rate depends on thesmoothness of the input distribution and the closeness of patches. To the bestof our knowledge, this is the first recovery guarantee of gradient-basedalgorithms for convolutional filter on non-Gaussian input distributions. Ourtheory also justifies the two-stage learning rate strategy in deep neuralnetworks. While our focus is theoretical, we also present experiments thatillustrate our theoretical findings.",When is a Convolutional Filter Easy To Learn?
427,,,,,,"Sparsity inducing regularization is an important part for learningover-complete visual representations. Despite the popularity of $\ell_1$regularization, in this paper, we investigate the usage of non-convexregularizations in this problem. Our contribution consists of three parts.First, we propose the leaky capped norm regularization (LCNR), which allowsmodel weights below a certain threshold to be regularized more strongly asopposed to those above, therefore imposes strong sparsity and only introducescontrollable estimation bias. We propose a majorization-minimization algorithmto optimize the joint objective function. Second, our study over monocular 3Dshape recovery and neural networks with LCNR outperforms $\ell_1$ and othernon-convex regularizations, achieving state-of-the-art performance and fasterconvergence. Third, we prove a theoretical global convergence speed on the 3Drecovery problem. To the best of our knowledge, this is the first convergenceanalysis of the 3D recovery problem.",Learning Sparse Visual Representations with Leaky Capped Norm  Regularizers
428,,,,,,"ConvNets and Imagenet have driven the recent success of deep learning forimage classification. However, the marked slowdown in performance improvement,the recent studies on the lack of robustness of neural networks to adversarialexamples and their tendency to exhibit undesirable biases (e.g racial biases)questioned the reliability and the sustained development of these methods. Thiswork investigates these questions from the perspective of the end-user by usinghuman subject studies and explanations. We experimentally demonstrate that theaccuracy and robustness of ConvNets measured on Imagenet are underestimated. Weshow that explanations can mitigate the impact of misclassified adversarialexamples from the perspective of the end-user and we introduce a novel tool foruncovering the undesirable biases learned by a model. These contributions alsoshow that explanations are a promising tool for improving our understanding ofConvNets' predictions and for designing more reliable models","ConvNets and ImageNet Beyond Accuracy: Explanations, Bias Detection,  Adversarial Examples and Model Criticism"
429,,,,,,"We consider the problem of learning a one-hidden-layer neural network withnon-overlapping convolutional layer and ReLU activation function, i.e.,$f(\mathbf{Z}; \mathbf{w}, \mathbf{a}) = \sum_ja_j\sigma(\mathbf{w}^\top\mathbf{Z}_j)$, in which both the convolutionalweights $\mathbf{w}$ and the output weights $\mathbf{a}$ are parameters to belearned. We prove that with Gaussian input $\mathbf{Z}$, there is a spuriouslocal minimum that is not a global mininum. Surprisingly, in the presence oflocal minimum, starting from randomly initialized weights, gradient descentwith weight normalization can still be proven to recover the true parameterswith constant probability (which can be boosted to arbitrarily high accuracywith multiple restarts). We also show that with constant probability, the sameprocedure could also converge to the spurious local minimum, showing that thelocal minimum plays a non-trivial role in the dynamics of gradient descent.Furthermore, a quantitative analysis shows that the gradient descent dynamicshas two phases: it starts off slow, but converges much faster after severaliterations.",Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of  Spurious Local Minima
430,,,,,,"In many real-world scenarios, rewards extrinsic to the agent are extremelysparse, or absent altogether. In such cases, curiosity can serve as anintrinsic reward signal to enable the agent to explore its environment andlearn skills that might be useful later in its life. We formulate curiosity asthe error in an agent's ability to predict the consequence of its own actionsin a visual feature space learned by a self-supervised inverse dynamics model.Our formulation scales to high-dimensional continuous state spaces like images,bypasses the difficulties of directly predicting pixels, and, critically,ignores the aspects of the environment that cannot affect the agent. Theproposed approach is evaluated in two environments: VizDoom and Super MarioBros. Three broad settings are investigated: 1) sparse extrinsic reward, wherecuriosity allows for far fewer interactions with the environment to reach thegoal; 2) exploration with no extrinsic reward, where curiosity pushes the agentto explore more efficiently; and 3) generalization to unseen scenarios (e.g.new levels of the same game) where the knowledge gained from earlier experiencehelps the agent explore new places much faster than starting from scratch. Demovideo and code available at https://pathak22.github.io/noreward-rl/",Curiosity-driven Exploration by Self-supervised Prediction
431,Nuclear,,,Nuclear,,"Generating adversarial examples is a critical step for evaluating andimproving the robustness of learning machines. So far, most existing methodsonly work for classification and are not designed to alter the true performancemeasure of the problem at hand. We introduce a novel flexible approach namedHoudini for generating adversarial examples specifically tailored for the finalperformance measure of the task considered, be it combinatorial andnon-decomposable. We successfully apply Houdini to a range of applications suchas speech recognition, pose estimation and semantic segmentation. In all cases,the attacks based on Houdini achieve higher success rate than those based onthe traditional surrogates used to train the models while using a lessperceptible adversarial perturbation.",Houdini: Fooling Deep Structured Prediction Models
432,Nuclear,,,Nuclear,,"With the recent renaissance of deep convolution neural networks, encouragingbreakthroughs have been achieved on the supervised recognition tasks, whereeach class has sufficient training data and fully annotated training data.However, to scale the recognition to a large number of classes with few or nowtraining samples for each class remains an unsolved problem. One approach toscaling up the recognition is to develop models capable of recognizing unseencategories without any training instances, or zero-shot recognition/ learning.This article provides a comprehensive review of existing zero-shot recognitiontechniques covering various aspects ranging from representations of models, andfrom datasets and evaluation settings. We also overview related recognitiontasks including one-shot and open set recognition which can be used as naturalextensions of zero-shot recognition when limited number of class samples becomeavailable or when zero-shot recognition is implemented in a real-world setting.Importantly, we highlight the limitations of existing approaches and point outfuture research directions in this existing new research area.",Recent Advances in Zero-shot Recognition
433,,,,,,"We analyze the expressiveness and loss surface of practical deepconvolutional neural networks (CNNs) with shared weights and max poolinglayers. We show that such CNNs produce linearly independent features at a""wide"" layer which has more neurons than the number of training samples. Thiscondition holds e.g. for the VGG network. Furthermore, we provide for such wideCNNs necessary and sufficient conditions for global minima with zero trainingerror. For the case where the wide layer is followed by a fully connectedlayer, we show that almost every critical point of the empirical loss is aglobal minimum with zero training error. Our analysis suggests that both depthand width are very important in deep learning. While depth brings morerepresentational power and allows the network to learn high level features,width smoothes the optimization landscape of the loss function in the sensethat a sufficiently wide network has a well-behaved loss surface withpotentially no bad local minima.",The loss surface and expressivity of deep convolutional neural networks
434,DV,DV,,,,"This paper introduces a novel framework for combining scientific knowledge ofphysics-based models with neural networks to advance scientific discovery. Thisframework, termed as physics-guided neural network (PGNN), leverages the outputof physics-based model simulations along with observational features togenerate predictions using a neural network architecture. Further, this paperpresents a novel framework for using physics-based loss functions in thelearning objective of neural networks, to ensure that the model predictions notonly show lower errors on the training set but are also scientificallyconsistent with the known physics on the unlabeled set. We illustrate theeffectiveness of PGNN for the problem of lake temperature modeling, wherephysical relationships between the temperature, density, and depth of water areused to design a physics-based loss function. By using scientific knowledge toguide the construction and learning of neural networks, we are able to showthat the proposed framework ensures better generalizability as well asscientific consistency of results.",Physics-guided Neural Networks (PGNN): An Application in Lake  Temperature Modeling
435,,,,,,"Spectral clustering has found extensive use in many areas. Most traditionalspectral clustering algorithms work in three separate steps: similarity graphconstruction; continuous labels learning; discretizing the learned labels byk-means clustering. Such common practice has two potential flaws, which maylead to severe information loss and performance degradation. First, predefinedsimilarity graph might not be optimal for subsequent clustering. It iswell-accepted that similarity graph highly affects the clustering results. Tothis end, we propose to automatically learn similarity information from dataand simultaneously consider the constraint that the similarity matrix has exactc connected components if there are c clusters. Second, the discrete solutionmay deviate from the spectral solution since k-means method is well-known assensitive to the initialization of cluster centers. In this work, we transformthe candidate solution into a new one that better approximates the discreteone. Finally, those three subtasks are integrated into a unified framework,with each subtask iteratively boosted by using the results of the otherstowards an overall optimal solution. It is known that the performance of akernel method is largely determined by the choice of kernels. To tackle thispractical problem of how to select the most suitable kernel for a particulardata set, we further extend our model to incorporate multiple kernel learningability. Extensive experiments demonstrate the superiority of our proposedmethod as compared to existing clustering approaches.",Unified Spectral Clustering with Optimal Graph
436,Data,Data,,,,"Dropout is a simple but effective technique for learning in neural networksand other settings. A sound theoretical understanding of dropout is needed todetermine when dropout should be applied and how to use it most effectively. Inthis paper we continue the exploration of dropout as a regularizer pioneered byWager, et.al. We focus on linear classification where a convex proxy to themisclassification loss (i.e. the logistic loss used in logistic regression) isminimized. We show: (a) when the dropout-regularized criterion has a uniqueminimizer, (b) when the dropout-regularization penalty goes to infinity withthe weights, and when it remains bounded, (c) that the dropout regularizationcan be non-monotonic as individual weights increase from 0, and (d) that thedropout regularization penalty may not be convex. This last point isparticularly surprising because the combination of dropout regularization withany convex loss proxy is always a convex function.  In order to contrast dropout regularization with $L_2$ regularization, weformalize the notion of when different sources are more compatible withdifferent regularizers. We then exhibit distributions that are provably morecompatible with dropout regularization than $L_2$ regularization, and viceversa. These sources provide additional insight into how the inductive biasesof dropout and $L_2$ regularization differ. We provide some similar results for$L_1$ regularization.",On the Inductive Bias of Dropout
437,Physics,Physics,,,,"We analyze dropout in deep networks with rectified linear units and thequadratic loss. Our results expose surprising differences between the behaviorof dropout and more traditional regularizers like weight decay. For example, onsome simple data sets dropout training produces negative weights even thoughthe output is the sum of the inputs. This provides a counterpoint to thesuggestion that dropout discourages co-adaptation of weights. We also show thatthe dropout penalty can grow exponentially in the depth of the network whilethe weight-decay penalty remains essentially linear, and that dropout isinsensitive to various re-scalings of the input features, outputs, and networkweights. This last insensitivity implies that there are no isolated localminima of the dropout training criterion. Our work uncovers new properties ofdropout, extends our understanding of why dropout succeeds, and lays thefoundation for further progress.",Surprising properties of dropout in deep networks
438,DV,DV,,,,"Third-generation neural networks, or Spiking Neural Networks (SNNs), aim atharnessing the energy efficiency of spike-domain processing by building oncomputing elements that operate on, and exchange, spikes. In this paper, theproblem of training a two-layer SNN is studied for the purpose ofclassification, under a Generalized Linear Model (GLM) probabilistic neuralmodel that was previously considered within the computational neuroscienceliterature. Conventional classification rules for SNNs operate offline based onthe number of output spikes at each output neuron. In contrast, a noveltraining method is proposed here for a first-to-spike decoding rule, wherebythe SNN can perform an early classification decision once spike firing isdetected at an output neuron. Numerical results bring insights into the optimalparameter selection for the GLM neuron and on the accuracy-complexity trade-offperformance of conventional and first-to-spike decoding.",Training Probabilistic Spiking Neural Networks with First-to-spike  Decoding
439,DV,DV,,,,"Enormous successes have been made by quantum algorithms during the lastdecade. In this paper, we combine the quantum game with the problem of dataclustering, and then develop a quantum-game-based clustering algorithm, inwhich data points in a dataset are considered as players who can make decisionsand implement quantum strategies in quantum games. After each round of aquantum game, each player's expected payoff is calculated. Later, he uses alink-removing-and-rewiring (LRR) function to change his neighbors and adjustthe strength of links connecting to them in order to maximize his payoff.Further, algorithms are discussed and analyzed in two cases of strategies, twopayoff matrixes and two LRR functions. Consequently, the simulation resultshave demonstrated that data points in datasets are clustered reasonably andefficiently, and the clustering algorithms have fast rates of convergence.Moreover, the comparison with other algorithms also provides an indication ofthe effectiveness of the proposed approach.",A Novel Clustering Algorithm Based on Quantum Games
440,,,,,,"Despite the widespread practical success of deep learning methods, ourtheoretical understanding of the dynamics of learning in deep neural networksremains quite sparse. We attempt to bridge the gap between the theory andpractice of deep learning by systematically analyzing learning dynamics for therestricted case of deep linear neural networks. Despite the linearity of theirinput-output map, such networks have nonlinear gradient descent dynamics onweights that change with the addition of each new hidden layer. We show thatdeep linear networks exhibit nonlinear learning phenomena similar to those seenin simulations of nonlinear networks, including long plateaus followed by rapidtransitions to lower error solutions, and faster convergence from greedyunsupervised pretraining initial conditions than from random initialconditions. We provide an analytical description of these phenomena by findingnew exact solutions to the nonlinear dynamics of deep learning. Our theoreticalanalysis also reveals the surprising finding that as the depth of a networkapproaches infinity, learning speed can nevertheless remain finite: for aspecial class of initial conditions on the weights, very deep networks incuronly a finite, depth independent, delay in learning speed relative to shallownetworks. We show that, under certain conditions on the training data,unsupervised pretraining can find this special class of initial conditions,while scaled random Gaussian initializations cannot. We further exhibit a newclass of random orthogonal initial conditions on weights that, likeunsupervised pre-training, enjoys depth independent learning times. We furthershow that these initial conditions also lead to faithful propagation ofgradients even in deep nonlinear networks, as long as they operate in a specialregime known as the edge of chaos.",Exact solutions to the nonlinear dynamics of learning in deep linear  neural networks
441,,,,,,"In signal analysis and synthesis, linear approximation theory considers alinear decomposition of any given signal in a set of atoms, collected into aso-called dictionary. Relevant sparse representations are obtained by relaxingthe orthogonality condition of the atoms, yielding overcomplete dictionarieswith an extended number of atoms. More generally than the linear decomposition,overcomplete kernel dictionaries provide an elegant nonlinear extension bydefining the atoms through a mapping kernel function (e.g., the gaussiankernel). Models based on such kernel dictionaries are used in neural networks,gaussian processes and online learning with kernels.  The quality of an overcomplete dictionary is evaluated with a diversitymeasure the distance, the approximation, the coherence and the Babel measures.In this paper, we develop a framework to examine overcomplete kerneldictionaries with the entropy from information theory. Indeed, a higher valueof the entropy is associated to a further uniform spread of the atoms over thespace. For each of the aforementioned diversity measures, we derive lowerbounds on the entropy. Several definitions of the entropy are examined, with anextensive analysis in both the input space and the mapped feature space.",Entropy of Overcomplete Kernel Dictionaries
442,,,,,,"Measuring the morphological parameters of galaxies is a key requirement forstudying their formation and evolution. Surveys such as the Sloan Digital SkySurvey (SDSS) have resulted in the availability of very large collections ofimages, which have permitted population-wide analyses of galaxy morphology.Morphological analysis has traditionally been carried out mostly via visualinspection by trained experts, which is time-consuming and does not scale tolarge ($\gtrsim10^4$) numbers of images.  Although attempts have been made to build automated classification systems,these have not been able to achieve the desired level of accuracy. The GalaxyZoo project successfully applied a crowdsourcing strategy, inviting onlineusers to classify images by answering a series of questions. Unfortunately,even this approach does not scale well enough to keep up with the increasingavailability of galaxy images.  We present a deep neural network model for galaxy morphology classificationwhich exploits translational and rotational symmetry. It was developed in thecontext of the Galaxy Challenge, an international competition to build the bestmodel for morphology classification based on annotated images from the GalaxyZoo project.  For images with high agreement among the Galaxy Zoo participants, our modelis able to reproduce their consensus with near-perfect accuracy ($> 99\%$) formost questions. Confident model predictions are highly accurate, which makesthe model suitable for filtering large collections of images and forwardingchallenging images to experts for manual annotation. This approach greatlyreduces the experts' workload without affecting accuracy. The application ofthese algorithms to larger sets of training data will be critical for analysingresults from future surveys such as the LSST.",Rotation-invariant convolutional neural networks for galaxy morphology  prediction
443,Chemistry,Chemistry,,,,"The nonnegative matrix factorization (NMF) is widely used in signal and imageprocessing, including bio-informatics, blind source separation andhyperspectral image analysis in remote sensing. A great challenge arises whendealing with a nonlinear formulation of the NMF. Within the framework of kernelmachines, the models suggested in the literature do not allow therepresentation of the factorization matrices, which is a fallout of the curseof the pre-image. In this paper, we propose a novel kernel-based model for theNMF that does not suffer from the pre-image problem, by investigating theestimation of the factorization matrices directly in the input space. Fordifferent kernel functions, we describe two schemes for iterative algorithms:an additive update rule based on a gradient descent scheme and a multiplicativeupdate rule in the same spirit as in the Lee and Seung algorithm. Within theproposed framework, we develop several extensions to incorporate constraints,including sparseness, smoothness, and spatial regularization with atotal-variation-like penalty. The effectiveness of the proposed method isdemonstrated with the problem of unmixing hyperspectral images, usingwell-known real images and results with state-of-the-art techniques.",Kernel Nonnegative Matrix Factorization Without the Curse of the  Pre-image - Application to Unmixing Hyperspectral Images
444,,,,,,"Many machine learning frameworks, such as resource-allocating networks,kernel-based methods, Gaussian processes, and radial-basis-function networks,require a sparsification scheme in order to address the online learningparadigm. For this purpose, several online sparsification criteria have beenproposed to restrict the model definition on a subset of samples. The mostknown criterion is the (linear) approximation criterion, which discards anysample that can be well represented by the already contributing samples, anoperation with excessive computational complexity. Several computationallyefficient sparsification criteria have been introduced in the literature, suchas the distance, the coherence and the Babel criteria. In this paper, weprovide a framework that connects these sparsification criteria to the issue ofapproximating samples, by deriving theoretical bounds on the approximationerrors. Moreover, we investigate the error of approximating any feature, byproposing upper-bounds on the approximation error for each of theaforementioned sparsification criteria. Two classes of features are describedin detail, the empirical mean and the principal axes in the kernel principalcomponent analysis.",Approximation errors of online sparsification criteria
445,Chemistry,Chemistry,,,,"First steps towards a mathematical theory of deep convolutional neuralnetworks for feature extraction were made---for the continuous-time case---inMallat, 2012, and Wiatowski and B\""olcskei, 2015. This paper considers thediscrete case, introduces new convolutional neural network architectures, andproposes a mathematical framework for their analysis. Specifically, weestablish deformation and translation sensitivity results of local and globalnature, and we investigate how certain structural properties of the inputsignal are reflected in the corresponding feature vectors. Our theory appliesto general filters and general Lipschitz-continuous non-linearities and poolingoperators. Experiments on handwritten digit classification and facial landmarkdetection---including feature importance evaluation---complement thetheoretical findings.",Discrete Deep Feature Extraction: A Theory and New Architectures
446,,,,,,"We propose Neural Responding Machine (NRM), a neural network-based responsegenerator for Short-Text Conversation. NRM takes the general encoder-decoderframework: it formalizes the generation of response as a decoding process basedon the latent representation of the input text, while both encoding anddecoding are realized with recurrent neural networks (RNN). The NRM is trainedwith a large amount of one-round conversation data collected from amicroblogging service. Empirical study shows that NRM can generategrammatically correct and content-wise appropriate responses to over 75% of theinput text, outperforming state-of-the-arts in the same setting, includingretrieval-based and SMT-based models.",Neural Responding Machine for Short-Text Conversation
447,,,,,,"We propose an online, end-to-end, neural generative conversational model foropen-domain dialogue. It is trained using a unique combination of offlinetwo-phase supervised learning and online human-in-the-loop active learning.While most existing research proposes offline supervision or hand-craftedreward functions for online reinforcement, we devise a novel interactivelearning mechanism based on hamming-diverse beam search for response generationand one-character user-feedback at each step. Experiments show that our modelinherently promotes the generation of semantically relevant and interestingresponses, and can be used to train agents with customized personas, moods andconversational styles.",Deep Active Learning for Dialogue Generation
448,Nuclear,,,Nuclear,,"Teaching machines to read natural language documents remains an elusivechallenge. Machine reading systems can be tested on their ability to answerquestions posed on the contents of documents that they have seen, but until nowlarge scale training and test datasets have been missing for this type ofevaluation. In this work we define a new methodology that resolves thisbottleneck and provides large scale supervised reading comprehension data. Thisallows us to develop a class of attention based deep neural networks that learnto read real documents and answer complex questions with minimal priorknowledge of language structure.",Teaching Machines to Read and Comprehend
449,,,,,,"Deep compositional models of meaning acting on distributional representationsof words in order to produce vectors of larger text constituents are evolvingto a popular area of NLP research. We detail a compositional distributionalframework based on a rich form of word embeddings that aims at facilitating theinteractions between words in the context of a sentence. Embeddings andcomposition layers are jointly learned against a generic objective thatenhances the vectors with syntactic information from the surrounding context.Furthermore, each word is associated with a number of senses, the mostplausible of which is selected dynamically during the composition process. Weevaluate the produced vectors qualitatively and quantitatively with positiveresults. At the sentence level, the effectiveness of the framework isdemonstrated on the MSRPar task, for which we report results within thestate-of-the-art range.",Syntax-Aware Multi-Sense Word Embeddings for Deep Compositional Models  of Meaning
450,,,,,,"Matching natural language sentences is central for many applications such asinformation retrieval and question answering. Existing deep models rely on asingle sentence representation or multiple granularity representations formatching. However, such methods cannot well capture the contextualized localinformation in the matching process. To tackle this problem, we present a newdeep architecture to match two sentences with multiple positional sentencerepresentations. Specifically, each positional sentence representation is asentence representation at this position, generated by a bidirectional longshort term memory (Bi-LSTM). The matching score is finally produced byaggregating interactions between these different positional sentencerepresentations, through $k$-Max pooling and a multi-layer perceptron. Ourmodel has several advantages: (1) By using Bi-LSTM, rich context of the wholesentence is leveraged to capture the contextualized local information in eachpositional sentence representation; (2) By matching with multiple positionalsentence representations, it is flexible to aggregate different importantcontextualized local information in a sentence to support the matching; (3)Experiments on different tasks such as question answering and sentencecompletion demonstrate the superiority of our model.",A Deep Architecture for Semantic Matching with Multiple Positional  Sentence Representations
451,DV,DV,,,,"Artificial neural networks are powerful models, which have been widelyapplied into many aspects of machine translation, such as language modeling andtranslation modeling. Though notable improvements have been made in theseareas, the reordering problem still remains a challenge in statistical machinetranslations. In this paper, we present a novel neural reordering model thatdirectly models word pairs and alignment. By utilizing LSTM recurrent neuralnetworks, much longer context could be learned for reordering prediction.Experimental results on NIST OpenMT12 Arabic-English and Chinese-English1000-best rescoring task show that our LSTM neural reordering feature is robustand achieves significant improvements over various baseline systems.",LSTM Neural Reordering Feature for Statistical Machine Translation
452,Nuclear,,,Nuclear,,"Natural language inference (NLI) is a fundamentally important task in naturallanguage processing that has many applications. The recently released StanfordNatural Language Inference (SNLI) corpus has made it possible to develop andevaluate learning-centered methods such as deep neural networks for naturallanguage inference (NLI). In this paper, we propose a special long short-termmemory (LSTM) architecture for NLI. Our model builds on top of a recentlyproposed neural attention model for NLI but is based on a significantlydifferent idea. Instead of deriving sentence embeddings for the premise and thehypothesis to be used for classification, our solution uses a match-LSTM toperform word-by-word matching of the hypothesis with the premise. This LSTM isable to place more emphasis on important word-level matching results. Inparticular, we observe that this LSTM remembers important mismatches that arecritical for predicting the contradiction or the neutral relationship label. Onthe SNLI corpus, our model achieves an accuracy of 86.1%, outperforming thestate of the art.",Learning Natural Language Inference with LSTM
453,Data,Data,,,,"Recursive neural networks (RNN) and their recently proposed extensionrecursive long short term memory networks (RLSTM) are models that computerepresentations for sentences, by recursively combining word embeddingsaccording to an externally provided parse tree. Both models thus, unlikerecurrent networks, explicitly make use of the hierarchical structure of asentence. In this paper, we demonstrate that RNNs nevertheless suffer from thevanishing gradient and long distance dependency problem, and that RLSTMsgreatly improve over RNN's on these problems. We present an artificial learningtask that allows us to quantify the severity of these problems for both models.We further show that a ratio of gradients (at the root node and a focal leafnode) is highly indicative of the success of backpropagation at optimizing therelevant weights low in the tree. This paper thus provides an explanation forexisting, superior results of RLSTMs on tasks such as sentiment analysis, andsuggests that the benefits of including hierarchical structure and of includingLSTM-style gating are complementary.",Quantifying the vanishing gradient and long distance dependency problem  in recursive neural networks and recursive LSTMs
454,Data,,,Data,,"Without discourse connectives, classifying implicit discourse relations is achallenging task and a bottleneck for building a practical discourse parser.Previous research usually makes use of one kind of discourse framework such asPDTB or RST to improve the classification performance on discourse relations.Actually, under different discourse annotation frameworks, there exist multiplecorpora which have internal connections. To exploit the combination ofdifferent discourse corpora, we design related discourse classification tasksspecific to a corpus, and propose a novel Convolutional Neural Network embeddedmulti-task learning system to synthesize these tasks by learning both uniqueand shared representations for each task. The experimental results on the PDTBimplicit discourse relation classification task demonstrate that our modelachieves significant gains over baseline systems.",Implicit Discourse Relation Classification via Multi-Task Neural  Networks
455,,,,,,"Neural network based approaches for sentence relation modeling automaticallygenerate hidden matching features from raw sentence pairs. However, the qualityof matching feature representation may not be satisfied due to complex semanticrelations such as entailment or contradiction. To address this challenge, wepropose a new deep neural network architecture that jointly leveragepre-trained word embedding and auxiliary character embedding to learn sentencemeanings. The two kinds of word sequence representations as inputs intomulti-layer bidirectional LSTM to learn enhanced sentence representation. Afterthat, we construct matching features followed by another temporal CNN to learnhigh-level hidden matching feature representations. Experimental resultsdemonstrate that our approach consistently outperforms the existing methods onstandard evaluation datasets.",Enhancing Sentence Relation Modeling with Auxiliary Character-level  Embedding
456,,,,,,"Previous studies in Open Information Extraction (Open IE) are mainly based onextraction patterns. They manually define patterns or automatically learn themfrom a large corpus. However, these approaches are limited when grasping thecontext of a sentence, and they fail to capture implicit relations. In thispaper, we address this problem with the following methods. First, we exploitlong short-term memory (LSTM) networks to extract higher-level features alongthe shortest dependency paths, connecting headwords of relations and arguments.The path-level features from LSTM networks provide useful clues regardingcontextual information and the validity of arguments. Second, we constructedsamples to train LSTM networks without the need for manual labeling. Inparticular, feedback negative sampling picks highly negative samples amongnon-positive samples through a model trained with positive samples. Theexperimental results show that our approach produces more precise and abundantextractions than state-of-the-art open IE systems. To the best of ourknowledge, this is the first work to apply deep learning to Open IE.",Automatic Open Knowledge Acquisition via Long Short-Term Memory Networks  with Feedback Negative Sampling
457,Physics,,,Physics,,"With the rapid growth of knowledge bases (KBs) on the web, how to take fulladvantage of them becomes increasingly important. Knowledge base-based questionanswering (KB-QA) is one of the most promising approaches to access thesubstantial knowledge. Meantime, as the neural network-based (NN-based) methodsdevelop, NN-based KB-QA has already achieved impressive results. However,previous work did not put emphasis on question representation, and the questionis converted into a fixed vector regardless of its candidate answers. Thissimple representation strategy is unable to express the proper information ofthe question. Hence, we present a neural attention-based model to represent thequestions dynamically according to the different focuses of various candidateanswer aspects. In addition, we leverage the global knowledge inside theunderlying KB, aiming at integrating the rich KB information into therepresentation of the answers. And it also alleviates the out of vocabulary(OOV) problem, which helps the attention model to represent the question moreprecisely. The experimental results on WEBQUESTIONS demonstrate theeffectiveness of the proposed approach.",Question Answering over Knowledge Base with Neural Attention Combining  Global Knowledge Information
458,Data,,,Data,,"The ability to reason with natural language is a fundamental prerequisite formany NLP tasks such as information extraction, machine translation and questionanswering. To quantify this ability, systems are commonly tested whether theycan recognize textual entailment, i.e., whether one sentence can be inferredfrom another one. However, in most NLP applications only single sourcesentences instead of sentence pairs are available. Hence, we propose a new taskthat measures how well a model can generate an entailed sentence from a sourcesentence. We take entailment-pairs of the Stanford Natural Language Inferencecorpus and train an LSTM with attention. On a manually annotated test set wefound that 82% of generated sentences are correct, an improvement of 10.3% overan LSTM baseline. A qualitative analysis shows that this model is not onlycapable of shortening input sentences, but also inferring new statements viaparaphrasing and phrase entailment. We then apply this model recursively toinput-output pairs, thereby generating natural language inference chains thatcan be used to automatically construct an entailment graph from sourcesentences. Finally, by swapping source and target sentences we can also train amodel that given an input sentence invents additional information to generate anew sentence.",Generating Natural Language Inference Chains
459,Data,Data,,,,"Recurrent neural networks such as the GRU and LSTM found wide adoption innatural language processing and achieve state-of-the-art results for manytasks. These models are characterized by a memory state that can be written toand read from by applying gated composition operations to the current input andthe previous state. However, they only cover a small subset of potentiallyuseful compositions. We propose Multi-Function Recurrent Units (MuFuRUs) thatallow for arbitrary differentiable functions as composition operations.Furthermore, MuFuRUs allow for an input- and state-dependent choice of thesecomposition operations that is learned. Our experiments demonstrate that theadditional functionality helps in different sequence modeling tasks, includingthe evaluation of propositional logic formulae, language modeling and sentimentanalysis.",MuFuRU: The Multi-Function Recurrent Unit
460,Chemistry,,,Chemistry,,"Recurrent neural networks, and in particular long short-term memory (LSTM)networks, are a remarkably effective tool for sequence modeling that learn adense black-box hidden representation of their sequential input. Researchersinterested in better understanding these models have studied the changes inhidden state representations over time and noticed some interpretable patternsbut also significant noise. In this work, we present LSTMVIS, a visual analysistool for recurrent neural networks with a focus on understanding these hiddenstate dynamics. The tool allows users to select a hypothesis input range tofocus on local state changes, to match these states changes to similar patternsin a large data set, and to align these results with structural annotationsfrom their domain. We show several use cases of the tool for analyzing specifichidden state properties on dataset containing nesting, phrase structure, andchord progressions, and demonstrate how the tool can be used to isolatepatterns for further statistical analysis. We characterize the domain, thedifferent stakeholders, and their goals and tasks.",LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in  Recurrent Neural Networks
461,Nuclear,Nuclear,,,,"Neural Machine Translation (NMT), like many other deep learning domains,typically suffers from over-parameterization, resulting in large storage sizes.This paper examines three simple magnitude-based pruning schemes to compressNMT models, namely class-blind, class-uniform, and class-distribution, whichdiffer in terms of how pruning thresholds are computed for the differentclasses of weights in the NMT architecture. We demonstrate the efficacy ofweight pruning as a compression technique for a state-of-the-art NMT system. Weshow that an NMT model with over 200 million parameters can be pruned by 40%with very little performance loss as measured on the WMT'14 English-Germantranslation task. This sheds light on the distribution of redundancy in the NMTarchitecture. Our main result is that with retraining, we can recover and evensurpass the original performance with an 80%-pruned model.",Compression of Neural Machine Translation Models via Pruning
462,Physics,Physics,,,,"Natural Language Inference is an important task for Natural LanguageUnderstanding. It is concerned with classifying the logical relation betweentwo sentences. In this paper, we propose several text generative neuralnetworks for generating text hypothesis, which allows construction of newNatural Language Inference datasets. To evaluate the models, we propose a newmetric -- the accuracy of the classifier trained on the generated dataset. Theaccuracy obtained by our best generative model is only 2.7% lower than theaccuracy of the classifier trained on the original, human crafted dataset.Furthermore, the best generated dataset combined with the original datasetachieves the highest accuracy. The best model learns a mapping embedding foreach training example. By comparing various metrics we show that datasets thatobtain higher ROUGE or METEOR scores do not necessarily yield higherclassification accuracies. We also provide analysis of what are thecharacteristics of a good dataset including the distinguishability of thegenerated datasets from the original one.",Constructing a Natural Language Inference Dataset using Generative  Neural Networks
463,Chemistry,,,Chemistry,,"While question answering (QA) with neural network, i.e. neural QA, hasachieved promising results in recent years, lacking of large scale real-word QAdataset is still a challenge for developing and evaluating neural QA system. Toalleviate this problem, we propose a large scale human annotated real-world QAdataset WebQA with more than 42k questions and 556k evidences. As existingneural QA methods resolve QA either as sequence generation orclassification/ranking problem, they face challenges of expensive softmaxcomputation, unseen answers handling or separate candidate answer generationcomponent. In this work, we cast neural QA as a sequence labeling problem andpropose an end-to-end sequence labeling model, which overcomes all the abovechallenges. Experimental results on WebQA show that our model outperforms thebaselines significantly with an F1 score of 74.69% with word-based input, andthe performance drops only 3.72 F1 points with more challenging character-basedinput.",Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain  Factoid Question Answering
464,,,,,,"We present Tweet2Vec, a novel method for generating general-purpose vectorrepresentation of tweets. The model learns tweet embeddings usingcharacter-level CNN-LSTM encoder-decoder. We trained our model on 3 million,randomly selected English-language tweets. The model was evaluated using twomethods: tweet semantic similarity and tweet sentiment categorization,outperforming the previous state-of-the-art in both tasks. The evaluationsdemonstrate the power of the tweet embeddings generated by our model forvarious tweet categorization tasks. The vector representations generated by ourmodel are generic, and hence can be applied to a variety of tasks. Though themodel presented in this paper is trained on English-language tweets, the methodpresented can be used to learn tweet embeddings for different languages.",Tweet2Vec: Learning Tweet Embeddings Using Character-level CNN-LSTM  Encoder-Decoder
465,,,,,,"We introduce an online neural sequence to sequence model that learns toalternate between encoding and decoding segments of the input as it is read. Byindependently tracking the encoding and decoding representations our algorithmpermits exact polynomial marginalization of the latent segmentation duringtraining, and during decoding beam search is employed to find the bestalignment path together with the predicted output sequence. Our model tacklesthe bottleneck of vanilla encoder-decoders that have to read and memorize theentire input sequence in their fixed-length hidden states before producing anyoutput. It is different from previous attentive models in that, instead oftreating the attention weights as output of a deterministic function, our modelassigns attention weights to a sequential latent variable which can bemarginalized out and permits online generation. Experiments on abstractivesentence summarization and morphological inflection show significantperformance gains over the baseline encoder-decoders.",Online Segment to Segment Neural Transduction
466,,,,,,We present a novel semi-supervised approach for sequence transduction andapply it to semantic parsing. The unsupervised component is based on agenerative model in which latent sentences generate the unpaired logical forms.We apply this method to a number of semantic parsing tasks focusing on domainswith limited access to labelled training data and extend those datasets withsynthetically generated logical forms.,Semantic Parsing with Semi-Supervised Sequential Autoencoders
467,,,,,,"This paper presents a deep learning architecture for the semantic decodercomponent of a Statistical Spoken Dialogue System. In a slot-filling dialogue,the semantic decoder predicts the dialogue act and a set of slot-value pairsfrom a set of n-best hypotheses returned by the Automatic Speech Recognition.Most current models for spoken language understanding assume (i) word-alignedsemantic annotations as in sequence taggers and (ii) delexicalisation, or amapping of input words to domain-specific concepts using heuristics that try tocapture morphological variation but that do not scale to other domains nor tolanguage variation (e.g., morphology, synonyms, paraphrasing ). In this workthe semantic decoder is trained using unaligned semantic annotations and ituses distributed semantic representation learning to overcome the limitationsof explicit delexicalisation. The proposed architecture uses a convolutionalneural network for the sentence representation and a long-short term memorynetwork for the context representation. Results are presented for the publiclyavailable DSTC2 corpus and an In-car corpus which is similar to DSTC2 but has asignificantly higher word error rate (WER).",Exploiting Sentence and Context Representations in Deep Neural Models  for Spoken Language Understanding
468,,,,,,"We formulate sequence to sequence transduction as a noisy channel decodingproblem and use recurrent neural networks to parameterise the source andchannel models. Unlike direct models which can suffer from explaining-awayeffects during training, noisy channel models must produce outputs that explaintheir inputs, and their component models can be trained with not only pairedtraining samples but also unpaired samples from the marginal outputdistribution. Using a latent variable to control how much of the conditioningsequence the channel model needs to read in order to generate a subsequentsymbol, we obtain a tractable and effective beam search decoder. Experimentalresults on abstractive sentence summarisation, morphological inflection, andmachine translation show that noisy channel models outperform direct models,and that they significantly benefit from increased amounts of unpaired outputdata that direct models cannot easily use.",The Neural Noisy Channel
469,Physics,,,Physics,,"Researchers have recently started investigating deep neural networks fordialogue applications. In particular, generative sequence-to-sequence (Seq2Seq)models have shown promising results for unstructured tasks, such as word-leveldialogue response generation. The hope is that such models will be able toleverage massive amounts of data to learn meaningful natural languagerepresentations and response generation strategies, while requiring a minimumamount of domain knowledge and hand-crafting. An important challenge is todevelop models that can effectively incorporate dialogue context and generatemeaningful and diverse responses. In support of this goal, we review recentlyproposed models based on generative encoder-decoder neural networkarchitectures, and show that these models have better ability to incorporatelong-term dialogue history, to model uncertainty and ambiguity in dialogue, andto generate responses with high-level compositional structure.",Generative Deep Neural Networks for Dialogue: A Short Review
470,,,,,,"To enhance developer productivity, all modern integrated developmentenvironments (IDEs) include code suggestion functionality that proposes likelynext tokens at the cursor. While current IDEs work well for statically-typedlanguages, their reliance on type annotations means that they do not providethe same level of support for dynamic programming languages as forstatically-typed languages. Moreover, suggestion engines in modern IDEs do notpropose expressions or multi-statement idiomatic code. Recent work has shownthat language models can improve code suggestion systems by learning fromsoftware repositories. This paper introduces a neural language model with asparse pointer network aimed at capturing very long-range dependencies. Werelease a large-scale code suggestion corpus of 41M lines of Python codecrawled from GitHub. On this corpus, we found standard neural language modelsto perform well at suggesting local phenomena, but struggle to refer toidentifiers that are introduced many tokens in the past. By augmenting a neurallanguage model with a pointer network specialized in referring to predefinedclasses of identifiers, we obtain a much lower perplexity and a 5 percentagepoints increase in accuracy for code suggestion compared to an LSTM baseline.In fact, this increase in code suggestion accuracy is due to a 13 times moreaccurate prediction of identifiers. Furthermore, a qualitative analysis showsthis model indeed captures interesting long-range dependencies, like referringto a class member defined over 60 tokens in the past.",Learning Python Code Suggestion with a Sparse Pointer Network
471,,,,,,"We describe an open-source toolkit for neural machine translation (NMT). Thetoolkit prioritizes efficiency, modularity, and extensibility with the goal ofsupporting NMT research into model architectures, feature representations, andsource modalities, while maintaining competitive performance and reasonabletraining requirements. The toolkit consists of modeling and translationsupport, as well as detailed pedagogical documentation about the underlyingtechniques.",OpenNMT: Open-Source Toolkit for Neural Machine Translation
472,DV,DV,,,,"Recent development of large-scale question answering (QA) datasets triggereda substantial amount of research into end-to-end neural architectures for QA.Increasingly complex systems have been conceived without comparison to simplerneural baseline systems that would justify their complexity. In this work, wepropose a simple heuristic that guides the development of neural baselinesystems for the extractive QA task. We find that there are two ingredientsnecessary for building a high-performing neural QA system: first, the awarenessof question words while processing the context and second, a compositionfunction that goes beyond simple bag-of-words modeling, such as recurrentneural networks. Our results show that FastQA, a system that meets these tworequirements, can achieve very competitive performance compared with existingmodels. We argue that this surprising finding puts results of previous systemsand the complexity of recent QA datasets into perspective.",Making Neural QA as Simple as Possible but not Simpler
473,DV,DV,,,,"This paper surveys the current state of the art in Natural LanguageGeneration (NLG), defined as the task of generating text or speech fromnon-linguistic input. A survey of NLG is timely in view of the changes that thefield has undergone over the past decade or so, especially in relation to new(usually data-driven) methods, as well as new applications of NLG technology.This survey therefore aims to (a) give an up-to-date synthesis of research onthe core tasks in NLG and the architectures adopted in which such tasks areorganised; (b) highlight a number of relatively recent research topics thathave arisen partly as a result of growing synergies between NLG and other areasof artificial intelligence; (c) draw attention to the challenges in NLGevaluation, relating them to similar challenges faced in other areas of NaturalLanguage Processing, with an emphasis on different evaluation methods and therelationships between them.","Survey of the State of the Art in Natural Language Generation: Core  tasks, applications and evaluation"
474,,,,,,"Sentence simplification reduces semantic complexity to benefit people withlanguage impairments. Previous simplification studies on the sentence level andword level have achieved promising results but also meet great challenges. Forsentence-level studies, sentences after simplification are fluent but sometimesare not really simplified. For word-level studies, words are simplified butalso have potential grammar errors due to different usages of words before andafter simplification. In this paper, we propose a two-step simplificationframework by combining both the word-level and the sentence-levelsimplifications, making use of their corresponding advantages. Based on thetwo-step framework, we implement a novel constrained neural generation model tosimplify sentences given simplified words. The final results on Wikipedia andSimple Wikipedia aligned datasets indicate that our method yields betterperformance than various baselines.",A Constrained Sequence-to-Sequence Neural Model for Sentence  Simplification
475,Physics,Physics,,,,"Relation detection is a core component for many NLP applications includingKnowledge Base Question Answering (KBQA). In this paper, we propose ahierarchical recurrent neural network enhanced by residual learning thatdetects KB relations given an input question. Our method uses deep residualbidirectional LSTMs to compare questions and relation names via differenthierarchies of abstraction. Additionally, we propose a simple KBQA system thatintegrates entity linking and our proposed relation detector to enable oneenhance another. Experimental results evidence that our approach achieves notonly outstanding relation detection performance, but more importantly, it helpsour KBQA system to achieve state-of-the-art accuracy for both single-relation(SimpleQuestions) and multi-relation (WebQSP) QA benchmarks.",Improved Neural Relation Detection for Knowledge Base Question Answering
476,,,,,,"This paper addresses the problem of automatic speech recognition (ASR) errordetection and their use for improving spoken language understanding (SLU)systems. In this study, the SLU task consists in automatically extracting, fromASR transcriptions , semantic concepts and concept/values pairs in a e.gtouristic information system. An approach is proposed for enriching the set ofsemantic labels with error specific labels and by using a recently proposedneural approach based on word embeddings to compute well calibrated ASRconfidence measures. Experimental results are reported showing that it ispossible to decrease significantly the Concept/Value Error Rate with a state ofthe art system, outperforming previously published results performance on thesame experimental data. It also shown that combining an SLU approach based onconditional random fields with a neural encoder/decoder attention basedarchitecture , it is possible to effectively identifying confidence islands anduncertain semantic output segments useful for deciding appropriate errorhandling actions by the dialogue manager strategy .",ASR error management for improving spoken language understanding
477,DV,DV,,,,"Common-sense or background knowledge is required to understand naturallanguage, but in most neural natural language understanding (NLU) systems, therequisite background knowledge is indirectly acquired from static corpora. Wedevelop a new reading architecture for the dynamic integration of explicitbackground knowledge in NLU models. A new task-agnostic reading module providesrefined word representations to a task-specific NLU architecture by processingbackground knowledge in the form of free-text statements, together with thetask-specific inputs. Strong performance on the tasks of document questionanswering (DQA) and recognizing textual entailment (RTE) demonstrate theeffectiveness and flexibility of our approach. Analysis shows that our modelslearn to exploit knowledge selectively and in a semantically appropriate way.",Dynamic Integration of Background Knowledge in Neural NLU Systems
478,Chemistry,Chemistry,,,,"We study the skip-thought model with neighborhood information as weaksupervision. More specifically, we propose a skip-thought neighbor model toconsider the adjacent sentences as a neighborhood. We train our skip-thoughtneighbor model on a large corpus with continuous sentences, and then evaluatethe trained model on 7 tasks, which include semantic relatedness, paraphrasedetection, and classification benchmarks. Both quantitative comparison andqualitative investigation are conducted. We empirically show that, ourskip-thought neighbor model performs as well as the skip-thought model onevaluation tasks. In addition, we found that, incorporating an autoencoder pathin our model didn't aid our model to perform better, while it hurts theperformance of the skip-thought model.",Rethinking Skip-thought: A Neighborhood based Approach
479,,,,,,"Factoid question answering (QA) has recently benefited from the developmentof deep learning (DL) systems. Neural network models outperform traditionalapproaches in domains where large datasets exist, such as SQuAD (ca. 100,000questions) for Wikipedia articles. However, these systems have not yet beenapplied to QA in more specific domains, such as biomedicine, because datasetsare generally too small to train a DL system from scratch. For example, theBioASQ dataset for biomedical QA comprises less then 900 factoid (singleanswer) and list (multiple answers) QA instances. In this work, we adapt aneural QA system trained on a large open-domain dataset (SQuAD, source) to abiomedical dataset (BioASQ, target) by employing various transfer learningtechniques. Our network architecture is based on a state-of-the-art QA system,extended with biomedical word embeddings and a novel mechanism to answer listquestions. In contrast to existing biomedical QA systems, our system does notrely on domain-specific ontologies, parsers or entity taggers, which areexpensive to create. Despite this fact, our systems achieve state-of-the-artresults on factoid questions and competitive results on list questions.",Neural Domain Adaptation for Biomedical Question Answering
480,,,,,,"We propose a two-stage neural model to tackle question generation fromdocuments. Our model first estimates the probability that word sequences in adocument compose ""interesting"" answers using a neural model trained on aquestion-answering corpus. We thus take a data-driven approach tointerestingness. Predicted key phrases then act as target answers thatcondition a sequence-to-sequence question generation model with a copymechanism. Empirically, our neural key phrase detection model significantlyoutperforms an entity-tagging baseline system and existing rule-basedapproaches. We demonstrate that the question generator formulates good qualitynatural language questions from extracted key phrases, and a human studyindicates that our system's generated question-answer pairs are competitivewith those of an earlier approach. We foresee our system being used in aneducational setting to assess reading comprehension and also as a dataaugmentation technique for semi-supervised learning.",Neural Models for Key Phrase Detection and Question Generation
481,Data,Data,,,,"This paper describes our submission to the 2017 BioASQ challenge. Weparticipated in Task B, Phase B which is concerned with biomedical questionanswering (QA). We focus on factoid and list question, using an extractive QAmodel, that is, we restrict our system to output substrings of the providedtext snippets. At the core of our system, we use FastQA, a state-of-the-artneural QA system. We extended it with biomedical word embeddings and changedits answer layer to be able to answer list questions in addition to factoidquestions. We pre-trained the model on a large-scale open-domain QA dataset,SQuAD, and then fine-tuned the parameters on the BioASQ training set. With ourapproach, we achieve state-of-the-art results on factoid questions andcompetitive results on list questions.",Neural Question Answering at BioASQ 5B
482,,,,,,"While natural languages are compositional, how state-of-the-art neural modelsachieve compositionality is still unclear. We propose a deep network, which notonly achieves competitive accuracy for text classification, but also exhibitscompositional behavior. That is, while creating hierarchical representations ofa piece of text, such as a sentence, the lower layers of the network distributetheir layer-specific attention weights to individual words. In contrast, thehigher layers compose meaningful phrases and clauses, whose lengths increase asthe networks get deeper until fully composing the sentence.",A Deep Network with Visual Text Composition Behavior
483,,,,,,"There exist two main approaches to automatically extract affectiveorientation: lexicon-based and corpus-based. In this work, we argue that thesetwo methods are compatible and show that combining them can improve theaccuracy of emotion classifiers. In particular, we introduce a novel variant ofthe Label Propagation algorithm that is tailored to distributed wordrepresentations, we apply batch gradient descent to accelerate the optimizationof label propagation and to make the optimization feasible for large graphs,and we propose a reproducible method for emotion lexicon expansion. We concludethat label propagation can expand an emotion lexicon in a meaningful way andthat the expanded emotion lexicon can be leveraged to improve the accuracy ofan emotion classifier.",Semi-supervised emotion lexicon expansion with label propagation and  specialized word embeddings
484,Physics,Physics,,,,"Many genres of natural language text are narratively structured, a testamentto our predilection for organizing our experiences as narratives. There isbroad consensus that understanding a narrative requires identifying andtracking the goals and desires of the characters and their narrative outcomes.However, to date, there has been limited work on computational models for thisproblem. We introduce a new dataset, DesireDB, which includes gold-standardlabels for identifying statements of desire, textual evidence for desirefulfillment, and annotations for whether the stated desire is fulfilled giventhe evidence in the narrative context. We report experiments on tracking desirefulfillment using different methods, and show that LSTM Skip-Thought modelachieves F-measure of 0.7 on our corpus.",Modelling Protagonist Goals and Desires in First-Person Narrative
485,Physics,,,Physics,,"Neural network-based systems can now learn to locate the referents of wordsand phrases in images, answer questions about visual scenes, and even executesymbolic instructions as first-person actors in partially-observable worlds. Toachieve this so-called grounded language learning, models must overcome certainwell-studied learning challenges that are also fundamental to infants learningtheir first words. While it is notable that models with no meaningful priorknowledge overcome these learning obstacles, AI researchers and practitionerscurrently lack a clear understanding of exactly how they do so. Here we addressthis question as a way of achieving a clearer general understanding of groundedlanguage learning, both to inform future research and to improve confidence inmodel predictions. For maximum control and generality, we focus on a simpleneural network-based language learning agent trained via policy-gradientmethods to interpret synthetic linguistic instructions in a simulated 3D world.We apply experimental paradigms from developmental psychology to this agent,exploring the conditions under which established human biases and learningeffects emerge. We further propose a novel way to visualise and analysesemantic representation in grounded language learning agents that yields aplausible computational account of the observed effects.",Understanding Grounded Language Learning Agents
486,Physics,,,Physics,,"This paper presents the design of the machine learning architecture thatunderlies the Alexa Skills Kit (ASK) a large scale Spoken LanguageUnderstanding (SLU) Software Development Kit (SDK) that enables developers toextend the capabilities of Amazon's virtual assistant, Alexa. At Amazon, theinfrastructure powers over 25,000 skills deployed through the ASK, as well asAWS's Amazon Lex SLU Service. The ASK emphasizes flexibility, predictabilityand a rapid iteration cycle for third party developers. It imposes inductivebiases that allow it to learn robust SLU models from extremely small and sparsedatasets and, in doing so, removes significant barriers to entry for softwaredevelopers and dialogue systems researchers.",Just ASK: Building an Architecture for Extensible Self-Service Spoken  Language Understanding
487,,,,,,"Reading comprehension (RC)---in contrast to information retrieval---requiresintegrating information and reasoning about events, entities, and theirrelations across a full document. Question answering is conventionally used toassess RC ability, in both artificial agents and children learning to read.However, existing RC datasets and tasks are dominated by questions that can besolved by selecting answers using superficial information (e.g., local contextsimilarity or global term frequency); they thus fail to test for the essentialintegrative aspect of RC. To encourage progress on deeper comprehension oflanguage, we present a new dataset and set of tasks in which the reader mustanswer questions about stories by reading entire books or movie scripts. Thesetasks are designed so that successfully answering their questions requiresunderstanding the underlying narrative rather than relying on shallow patternmatching or salience. We show that although humans solve the tasks easily,standard RC models struggle on the tasks presented here. We provide an analysisof the dataset and the challenges it presents.",The NarrativeQA Reading Comprehension Challenge
488,Chemistry,Chemistry,,,,"We propose Cognitive Databases, an approach for transparently enablingArtificial Intelligence (AI) capabilities in relational databases. A novelaspect of our design is to first view the structured data source as meaningfulunstructured text, and then use the text to build an unsupervised neuralnetwork model using a Natural Language Processing (NLP) technique called wordembedding. This model captures the hidden inter-/intra-column relationshipsbetween database tokens of different types. For each database token, the modelincludes a vector that encodes contextual semantic relationships. We seamlesslyintegrate the word embedding model into existing SQL query infrastructure anduse it to enable a new class of SQL-based analytics queries called cognitiveintelligence (CI) queries. CI queries use the model vectors to enable complexqueries such as semantic matching, inductive reasoning queries such asanalogies, predictive queries using entities not present in a database, and,more generally, using knowledge from external sources. We demonstrate uniquecapabilities of Cognitive Databases using an Apache Spark based prototype toexecute inductive reasoning CI queries over a multi-modal database containingtext and images. We believe our first-of-a-kind system exemplifies using AIfunctionality to endow relational databases with capabilities that werepreviously very hard to realize in practice.",Cognitive Database: A Step towards Endowing Relational Databases with  Artificial Intelligence Capabilities
489,Physics,Physics,,,,"Reinforcement learning (RL) is a promising approach to solve dialogue policyoptimisation. Traditional RL algorithms, however, fail to scale to largedomains due to the curse of dimensionality. We propose a novel DialogueManagement architecture, based on Feudal RL, which decomposes the decision intotwo steps; a first step where a master policy selects a subset of primitiveactions, and a second step where a primitive action is chosen from the selectedsubset. The structural information included in the domain ontology is used toabstract the dialogue state space, taking the decisions at each step usingdifferent parts of the abstracted state. This, combined with an informationsharing mechanism between slots, increases the scalability to large domains. Weshow that an implementation of this approach, based on Deep-Q Networks,significantly outperforms previous state of the art in several dialogue domainsand environments, without the need of any additional reward signal.",Feudal Reinforcement Learning for Dialogue Management in Large Domains
490,,,,,,"Many of the leading approaches in language modeling introduce novel, complexand specialized architectures. We take existing state-of-the-art word levellanguage models based on LSTMs and QRNNs and extend them to both largervocabularies as well as character-level granularity. When properly tuned, LSTMsand QRNNs achieve state-of-the-art results on character-level (Penn Treebank,enwik8) and word-level (WikiText-103) datasets, respectively. Results areobtained in only 12 hours (WikiText-103) to 2 days (enwik8) using a singlemodern GPU.",An Analysis of Neural Language Modeling at Multiple Scales
491,Physics,Physics,,,,"We propose a spatial diffuseness feature for deep neural network (DNN)-basedautomatic speech recognition to improve recognition accuracy in reverberant andnoisy environments. The feature is computed in real-time from multiplemicrophone signals without requiring knowledge or estimation of the directionof arrival, and represents the relative amount of diffuse noise in each timeand frequency bin. It is shown that using the diffuseness feature as anadditional input to a DNN-based acoustic model leads to a reduced word errorrate for the REVERB challenge corpus, both compared to logmelspec featuresextracted from noisy signals, and features enhanced by spectral subtraction.",Spatial Diffuseness Features for DNN-Based Speech Recognition in Noisy  and Reverberant Environments
492,,,,,,"We describe a simple neural language model that relies only oncharacter-level inputs. Predictions are still made at the word-level. Our modelemploys a convolutional neural network (CNN) and a highway network overcharacters, whose output is given to a long short-term memory (LSTM) recurrentneural network language model (RNN-LM). On the English Penn Treebank the modelis on par with the existing state-of-the-art despite having 60% fewerparameters. On languages with rich morphology (Arabic, Czech, French, German,Spanish, Russian), the model outperforms word-level/morpheme-level LSTMbaselines, again with fewer parameters. The results suggest that on manylanguages, character inputs are sufficient for language modeling. Analysis ofword representations obtained from the character composition part of the modelreveals that the model is able to encode, from characters only, both semanticand orthographic information.",Character-Aware Neural Language Models
493,Nuclear,Nuclear,,,,"The quality of machine translation is rapidly evolving. Today one can findseveral machine translation systems on the web that provide reasonabletranslations, although the systems are not perfect. In some specific domains,the quality may decrease. A recently proposed approach to this domain is neuralmachine translation. It aims at building a jointly-tuned single neural networkthat maximizes translation performance, a very different approach fromtraditional statistical machine translation. Recently proposed neural machinetranslation models often belong to the encoder-decoder family in which a sourcesentence is encoded into a fixed length vector that is, in turn, decoded togenerate a translation. The present research examines the effects of differenttraining methods on a Polish-English Machine Translation system used formedical data. The European Medicines Agency parallel text corpus was used asthe basis for training of neural and statistical network-based translationsystems. The main machine translation evaluation metrics have also been used inanalysis of the systems. A comparison and implementation of a real-time medicaltranslator is the main focus of our experiments.",Neural-based machine translation for medical text domain. Based on  European Medicines Agency leaflet texts
494,,,,,,"Recently a variety of LSTM-based conditional language models (LM) have beenapplied across a range of language generation tasks. In this work we studyvarious model architectures and different ways to represent and aggregate thesource information in an end-to-end neural dialogue system framework. A methodcalled snapshot learning is also proposed to facilitate learning fromsupervised sequential signals by applying a companion cross-entropy objectivefunction to the conditioning vector. The experimental and analytical resultsdemonstrate firstly that competition occurs between the conditioning vector andthe LM, and the differing architectures provide different trade-offs betweenthe two. Secondly, the discriminative power and transparency of theconditioning vector is key to providing both model interpretability and betterperformance. Thirdly, snapshot learning leads to consistent performanceimprovements independent of which architecture is used.",Conditional Generation and Snapshot Learning in Neural Dialogue Systems
495,Nuclear,,,Nuclear,,"In an end-to-end dialog system, the aim of dialog state tracking is toaccurately estimate a compact representation of the current dialog status froma sequence of noisy observations produced by the speech recognition and thenatural language understanding modules. This paper introduces a novel method ofdialog state tracking based on the general paradigm of machine reading andproposes to solve it using an End-to-End Memory Network, MemN2N, amemory-enhanced neural network architecture. We evaluate the proposed approachon the second Dialog State Tracking Challenge (DSTC-2) dataset. The corpus hasbeen converted for the occasion in order to frame the hidden state variableinference as a question-answering task based on a sequence of utterancesextracted from a dialog. We show that the proposed tracker gives encouragingresults. Then, we propose to extend the DSTC-2 dataset with specific reasoningcapabilities requirement like counting, list maintenance, yes-no questionanswering and indefinite knowledge management. Finally, we present encouragingresults using our proposed MemN2N based tracking model.","Dialog state tracking, a machine reading approach using Memory Network"
496,,,,,,"In accessibility tests for digital preservation, over time we experiencedrifts of localized and labelled content in statistical models of evolvingsemantics represented as a vector field. This articulates the need to detect,measure, interpret and model outcomes of knowledge dynamics. To this end weemploy a high-performance machine learning algorithm for the training ofextremely large emergent self-organizing maps for exploratory data analysis.The working hypothesis we present here is that the dynamics of semantic driftscan be modeled on a relaxed version of Newtonian mechanics called socialmechanics. By using term distances as a measure of semantic relatedness vs.their PageRank values indicating social importance and applied as variable`term mass', gravitation as a metaphor to express changes in the semanticcontent of a vector field lends a new perspective for experimentation. From`term gravitation' over time, one can compute its generating potential whosefluctuations manifest modifications in pairwise term similarity vs. socialimportance, thereby updating Osgood's semantic differential. The datasetexamined is the public catalog metadata of Tate Galleries, London.",A Physical Metaphor to Study Semantic Drift
497,Nuclear,,,Nuclear,,"Systems based on artificial neural networks (ANNs) have achievedstate-of-the-art results in many natural language processing tasks. AlthoughANNs do not require manually engineered features, ANNs have manyhyperparameters to be optimized. The choice of hyperparameters significantlyimpacts models' performances. However, the ANN hyperparameters are typicallychosen by manual, grid, or random search, which either requires expertexperiences or is computationally expensive. Recent approaches based onBayesian optimization using Gaussian processes (GPs) is a more systematic wayto automatically pinpoint optimal or near-optimal machine learninghyperparameters. Using a previously published ANN model yieldingstate-of-the-art results for dialog act classification, we demonstrate thatoptimizing hyperparameters using GP further improves the results, and reducesthe computational time by a factor of 4 compared to a random search. Thereforeit is a useful technique for tuning ANN models to yield the best performancesfor natural language processing tasks.",Optimizing Neural Network Hyperparameters with Gaussian Processes for  Dialog Act Classification
498,Nuclear,Nuclear,,,,"Speech Translation has always been about giving source text or audio inputand waiting for system to give translated output in desired form. In thispaper, we present the Acoustic Dialect Decoder (ADD) - a voice to voiceear-piece translation device. We introduce and survey the recent advances madein the field of Speech Engineering, to employ in the ADD, particularly focusingon the three major processing steps of Recognition, Translation and Synthesis.We tackle the problem of machine understanding of natural language by designinga recognition unit for source audio to text, a translation unit for sourcelanguage text to target language text, and a synthesis unit for target languagetext to target language speech. Speech from the surroundings will be recordedby the recognition unit present on the ear-piece and translation will start assoon as one sentence is successfully read. This way, we hope to give translatedoutput as and when input is being read. The recognition unit will use HiddenMarkov Models (HMMs) Based Tool-Kit (HTK), hybrid RNN systems with gated memorycells, and the synthesis unit, HMM based speech synthesis system HTS. Thissystem will initially be built as an English to Tamil translation device.",A Survey of Voice Translation Methodologies - Acoustic Dialect Decoder
499,Chemistry,,,Chemistry,,"Multi-hop inference is necessary for machine learning systems to successfullysolve tasks such as Recognising Textual Entailment and Machine Reading. In thiswork, we demonstrate the effectiveness of adaptive computation for learning thenumber of inference steps required for examples of different complexity andthat learning the correct number of inference steps is difficult. We introducethe first model involving Adaptive Computation Time which provides a smallperformance benefit on top of a similar model without an adaptive component aswell as enabling considerable insight into the reasoning process of the model.",Learning to Reason With Adaptive Computation
